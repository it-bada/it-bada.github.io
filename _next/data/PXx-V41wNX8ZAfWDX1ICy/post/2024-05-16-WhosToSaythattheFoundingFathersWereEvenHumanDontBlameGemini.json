{"pageProps":{"post":{"title":"그렇게 말할 수밖에 없습니다 국국시조들이 인간일 것이라고 어떻게 단정할 수 있을까요 젬니마이를 비난하지 말아주세요","description":"","date":"2024-05-16 13:30","slug":"2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini","content":"\n\n## AI(Artificial Intelligence)\n\n만일 이 기사를 읽고 계신다면, 구글이 자사의 AI 플랫폼인 Gemini의 이미지 생성 기능을 중단했다는 사실을 아시리라고 가정됩니다.\n\n언더리프레젠테드 그룹을 선호하는 이미지 결과의 편겸을 해소하기 위해 Gemini는 백인 남성들의 이미지를 생성하는 데 어려움을 겪었습니다. 이로 인해 사용자들은 아메리카의 창립자들, 바이킹, 나치, 그리고 교황들의 흑인 버전을 제시받았습니다:\n\n![이미지](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_0.png)\n\n<div class=\"content-ad\"></div>\n\n이제 Meta의 AI도 \"비사실적 이미지를 생성한다\"는 사실이 알려졌습니다. 이 달 초 Megan Morrone이 Axios 글에 포함된 몇 가지 이미지가 있습니다:\n\n![2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_1](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_1.png)\n\n그리고 구글이 자신을 조금 더 안심하게 만들기 위해 마이크로소프트도 이제 AI 이미지 생성에 대한 비판을 받고 있습니다. 회사의 소프트웨어 엔지니어 중 한 명인 Shane Jones가 이번 주 월스트리트 저널에 편지를 보내며 회사가 OpenAI의 Dall-E 3 모델을 기반으로 한 Copilot Designer 이미지 생성 플랫폼에 대해 논란이 있는 문제를 알면서도 이에 대한 보호장치를 마련하지 않았다고 주장했습니다. Jones는 다음과 같이 말합니다: \n\n“Copilot Designer는 정치적 편향, 미성년자 음주와 약물 사용, 기업 상표 및 저작권 남용, 음모 이론 및 종교 등 여러 가지 다른 분야에서 해로운 콘텐츠를 생성합니다.”\n\n<div class=\"content-ad\"></div>\n\n출처를 증명하기 위해서 그는 “차 사고”라는 간단한 프롬프트로 생성된 여성을 성적 대상화한 무작위 이미지를 포함한 Copilot 이미지의 스크린샷을 공유했습니다:\n\n[2024년 5월 16일 - 그들이 세운 국가의 아버지들이 심지어 인간이었다고 말할 사람이 누군지 아무도 모른다고 말할 수 있을까 - 2화](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_2.png)\n\n젬니는 최소한 \"예기치 못한\" 이미지를 생성하는 유일한 도구가 아닌 것 같네요.\n\nApple은 아직 AI 게임에 참여하지 않은 것에 대해 정말 기쁠 것 같습니다.\n\n<div class=\"content-ad\"></div>\n\n## '편견'이란 무엇인지에 대해 합의할 수조차 없는 것\n\n3월 7일 이의 팟캐스트 에피소드에서 렉스 프리드먼과의 인터뷰에서 제미니의 사태에 대해 언급하며, 메타의 최고 AI 과학자 앙 르쿤은 다음과 같이 말했습니다:\n\n\"편견이 없는 AI 시스템을 만들 수 있는가? 답은: 절대 불가능하며, 그 이유는 기술적 도전 때문이 아니라 (기술적 도전은 있지만) 편견이 바라는 대목에 있기 때문입니다. — 다른 사람들은 편견의 내용에 대해 다른 생각을 가지고 있을 수 있습니다.\"\n\n그는 또 \"모두에 의해 편견 없음으로 인식되는 시스템은 만들 수 없습니다.\"라고도 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n'AI의 대부분인 르쿤은 머신 러닝 플랫폼은 언제나 편향될 것이라고 확신하고 있습니다. 실제로, 그는 동일 인터뷰에서 이 불가피한 편향을 대처하는 유일한 방법은 Meta에서 일하는 곳인 르쿤이 말했듯이 오픈 소스 모델을 공개하여 그 편향을 분산시키는 것뿐이라고도 말했습니다. 이를 위해 Meta는 Llama AI 모델을 공개했습니다.\n\n르쿤은 동일 인터뷰에서 기술 회사들이 '각성한(Woke)’ 것이 아니라, 그저 사용자들을 모독하거나 상처 주지 않으려고 하고 있다고 지적했습니다. 문제는, 사람들이 모독받는 것이 매우 다양하다는 것입니다. 한 사람은 여성 교황이 신앙 실천에 반하는 것이라서 모독을 받을 수 있지만, 다른 사람은 여성이 교황이 될 기회가 한 번도 없었다는 이유로 모독을 받을 수도 있습니다.\n\n![이미지](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_3.png)\n\n몇 개월 전 Midjourney의 인종 및 성별 편견에 대한 우려를 공유했습니다. 작년 가을 Rest of World 웹사이트의 주요 분석은 AI 이미지 도구가 어떻게 광범히 편견을 지니고 있는지를 보여 주었습니다.'\n\n<div class=\"content-ad\"></div>\n\nLeCun님 말씀이 맞습니다. 편향은 피할 수 없습니다. 왜 피할 수 없는지 설명할 필요가 없을 정도로 Vox 작가 Sigal Samuel이 Future Perfect의 기사에서 문제를 훌륭하게 설명했습니다.\n\n그렇다면 구글은 어떻게 해야 할까요? 우연히도, Google Deepmind CEO Demis Hassabis는 Gemini 문제가 발견된 다음날 Hard Fork 팟캐스트 인터뷰 예정이었습니다. 다음은 그가 말한 내용입니다:\n\n\"역사적인 정확성, 절대적으로 필요합니다. 따라서 그것을 고쳐야 합니다. 제네릭한 팁을 받을 때는 일반적인 것이 있습니다. 예를 들어 '강아지를 산책시키는 사람의 그림을 만들거나, 병원에서 간호사의 그림을 만들거나'와 같이, 모두가 이해할 수 있는 보편적인 표현이 필요합니다.\"\n\n여기서 \"역사적 정확성\" 요소로 다시 돌아가겠지만, \"보편성\"이라는 개념에 대해 어떻게 생각하십니까?\n\n<div class=\"content-ad\"></div>\n\n# 인간과 강아지에는 일반화할 수 없는 존재가 없어요\n\n1970년대 영국의 작은 마을에서 자라난 저에겐 모든 의사가 남성이자 백인이었습니다. 따라서 남성과 백인으로 일반적인 의사를 상상하는 것은 놀라울 일이 아니에요. 하지만 저는 오늘 제가 사는 21세기의 거대한 도시에서는 여성 의사와 다양한 인종의 의사들이 일반적이라는 것을 알았어요.\n\n그럼 일반적인 의사가 뭘까요? 당연히, 일반적인 의사란 존재하지 않습니다. 개인과 그들의 직업은 완벽한 원과 사각형처럼 플라톤적인 이상이 아니에요. 특히 \"지구\"를 맥락으로 생각해본다면, 그들은 굉장히 다양합니다. 러시아의 일반적인 의사는 백인이어야 한다거나, 르완다의 일반적인 의사는 흑인이어야 한다고 주장할 수 있겠지만, 그렇게 한다고 성별과 나이 문제가 해결되는 것은 아니에요.\n\n하사비스가 이 문제에 대한 해결책으로 보편성을 주장한 것이 이상하게 다가옵니다. 아마 시간을 내어 좀 더 심도 있게 생각해보지 못했을 수도 있겠죠. 제가 지미니에게 병원에서 간호사의 보편적인 이미지를 만들 것을 요청해보지는 못했지만, Midjourney가 첫 번째 시도에서 가져온 것은 이렇습니다:\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_4.png)\n\nWhen it comes to creating images, striving for universality is a noble goal. But here's a fun fact: there's no such thing as an \"average\" human being. The problem with averages is that, on average, a person has about one testicle!\n\nCategories like \"dog walker\" or \"nurse\" help us make sense of the world, but they are subjective and can vary widely. It's no wonder that even advanced AI can struggle with complex tasks. Perhaps it'll excel in more specific categories.\n\nExcited for what's coming up next: a glimpse at a historically accurate portrayal of Jesus. Stay tuned!\n\n<div class=\"content-ad\"></div>\n\n우리는 편견을 피할 수 없다는 것을 알았고 보편성이 막다른 골목이라는 것도 보았다. 그래서 자리미 이미지에 대한 세 번째 반대 이유는 무엇이었을까? 이 문제를 해석한 것은 하사비스가 \"역사적 정확성\"이라고 했다. 그러나 \"정확성\"에 대해 생각하기 시작하면 \"역사적\" 부분은 단지 하위 집합일 뿐이다. 결국, 여성 교황이나 여자 NFL 선수들은 역사적으로 부정확할뿐만 아니라 현대에 존재할 수 없는 사회적 불가능성을 보여준다.\n\n여성 교황이나 피부색이 어두운 나치에 대한 이미지가 잘못된 이유에 대해 조금 더 파헤쳐 볼까요? \"정확성\"이 정말 무엇을 의미하는지요? 이 답변은 철학적이면서 기술적인 면으로 빠르게 나타납니다.\n\n교황, 나치, 바이킹, 간호사, NFL 선수 및 창립 아버지는 모두 사람들의 범주입니다. 그러나 이러한 범주들은 서로 다릅니다. 교황은 간호사와 같은 범주보다 훨씬 제한된 특성을 따르는 사람들의 범주입니다. 교황의 이미지를 만들라는 요청을 하는 경우 AI가 해결해야 할 문제는 상대적으로 쉽습니다. (이것이 기곽이나 규칙과 같이 제한된 특성을 갖는 폐쇄형 게임에서 기계 학습이 최고의 인간을 빨리 이기게 된 이유입니다. 반면 도시 길에 차를 운전하는 것과 같은 복잡하고 열린 시스템의 \"게임\"은 더 어려운 문제로 나타났습니다.)\n\n얼마나 많은 스위치를 누르거나 조작하거나 자리미에게 제한된 범주 (교황, 창립 아버지 또는 심지어 나치)와 일반 범주 (미국인이나 여성) 사이의 차이를 배우게 하기만 하면 되는 것이라고 생각할 수도 있습니다. 그러나 AI 이미지 생성의 어려운 문제에 대해 또 다른 관점을 제공하는 철학적 요인들이 있기 때문에 이 문제에 대해 별도의 기사에서 탐구할 필요가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n“역사적 정확성”이라는 것은 심지어 역사학자들도 일치하지 못하는 것이라고 해도 과언이 아닐 거예요. 말로 설명하기 어려운 예를 들자면 한번만 주제를 예수님으로 가져와볼게요. 예수님의 그림을 다들 보셨을 텐데요. 역사상 가장 유명한 인물 중 한 명이죠. 그런데... 음... 사실 아는 사람들은 알거예요, 지금까지 그에 대한 그림 하나라도 정확한 것이 없어요.\n\n![image](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_5.png)\n\n인공지능에 의해 창작된 것인지, 13세기 화가에 의한 것인지, 아니면 20세기 포토샵을 사용해서 만들어졌는지에 대해 어느 누가 실제로 지금까지 나온 예수님의 그림의 정확성에 대해 논할 수 있을까요? 제가 또 뭔가 엉성한 구원주를 주제로 만들고 있다고 생각할 수도 있겠네요. 알겠어요, 한 단계 더 파고들어볼게요.\n\n그림에 대한 “정확성”이란 무엇일까요? 정지된 상태거나 움직이는 그림이 언제나 현실을 정확하게 나타내는 것이라는 생각은 타당하게 논박될 수 없어요. 사진기가 발명되자마자 화가들은 인상파와 입체주의와 같은 예술 스타일을 개발했는데, 이것들이 사진보다 더 현실적이라고 주장했어요. 맥락은 어떻게 세상을 보느냐에 엄청난 영향을 미쳐요. 다른 사람들은 심지어 같은 색도 다르게 보거든요, 그래서 어떠한 시각적 정확성이라는 주장이 항상 미끄러운 경사 위에 있을 거예요.\n\n<div class=\"content-ad\"></div>\n\n# 다행히도, AI 이미지가 등장하기 전에 Lin-Manuel Miranda가 Hamilton을 만들었습니다\n\n화가 뿐만 아니라 작가와 감독들도 현실에 예술적 해석을 적용할 수 있어요. \"색맹 캐스팅\"을 하거나 과거와 현재의 사건에 원하는 해석을 달아줄 수 있어요. 우리는 주인공들이 검은 배우들에 의해 연기되기 때문에 Hamilton이 역사적으로 부정확하다고 잊지 말아야 해요. 오히려 그들은 무대에서 역사적 사건의 해석을 노래와 춤으로 몇 시간 동안 표현한 것이기 때문에 역사적으로 부정확해요!\n\n어떤 예술도 절대적으로 \"현실적\"이거나 \"정확\"하지 않아요. 이것이 우리가 이 논란에 대해 몇몇 철학적 측면을 이해할 수 있는 곳이에요. 원래의 주인공들은 그림 속에만 존재하는 특정 인물들이에요. 하지만 그림이 얼마나 역사적으로 정확한가요? Hamilton은 무대 뮤지컬이기 때문에 \"비현실적 해석\" 범주에 속해요.\n\n![Image](/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_6.png)\n\n<div class=\"content-ad\"></div>\n\n사람들이 창의적인 이미지를 만들기 위해 발견의 아버지, 교황 및 나치들의 그림을 만들기 위해 제미니를 사용하는 이유는 이미 인터넷에 자유롭게 사용할 수 있는 이미지가 있기 때문인가요? 유일한 이유는 새로운 무언가를 만들기 위해서예요. 이것이 예술이고, 이런 경우에는 \"정확성\"은 중요하지 않아요. 예술 작품은 창시자를 흑인으로, 교황을 여성으로 특징으로 할 수 있어요. 관습을 도전하는 것이 예술의 일부예요. 따라서 AI가 같은 일을 하는 데 분노할 이유는 없어요.\n\n우리가 보고 있는 문제는 사람들이 AI 출력물을 \"현실적 해석\" 범주로 여기는 것 같아요. 그러나 AI가 생성한 콘텐츠는 정의상 \"현실적이지 않다는\" 것이고, 이는 LLM 텍스트 출력뿐만 아니라 생성된 이미지에도 동일하게 적용돼요.\n\n이 모든 것이 의미하는 바는 많은 사용 사례에 대해 생성적 AI 제품을 정말 재미있는 장난감, 예술적 도구 또는 즐거운 시간으로 분류해야 한다는 것이에요. 그리고 이 모든 사용 사례를 \"콘텐츠 생성\"으로 분류할 수 있어요. 이는 앞으로 다룰 제 개 다음 글에서 더 자세히 살펴볼 내용이에요.\n\nAI 플랫폼을 멋진 장난감으로 보는 문제는 플랫폼을 소유하고 있는 기업(기술을 확장하려는 막상종잣돈을 요구하는 기업 포함)이 그들의 제품을 이 방식으로 분류하려는 동기가 없다는 것이에요.\n\n<div class=\"content-ad\"></div>\n\nAI 소수정예주의자들이 인공 일반 지능이 바로 거리 두지 않다고 주장하며 자신들의 제품을 진지한 도구로 분류할 필요가 있습니다. Yann LeCun이 명백히 거부하는 생각입니다. Gemini 사태는 이러한 제품들이 신뢰성을 잃을 수도 있는 산업을 위한 첫 번째 떨림의 전조일 수 있습니다.\n\n하지만, Meta라면 어떨까요? Meta의 Emu 이미지 생성 모델은 \"점점 더 황당한 아이디어에 기반한 이미지를 만들기 위한 것\"입니다. 아주 좋은 아트의 정의죠, 정확성이 아니라.\n\n# 이 구름에 은매가 가려 있는 건가요, 그건 역사적으로 부정확한 색일까요?\n\n최종적으로, AI 이미지 생성 뒤에 극복할 수 없는 결함이 우리에게 역사적 정확성에 대한 개념을 재검토할 필요성을 요구할 수 있습니다. 아마도 우리가 오늘과 같은 곳에 도달한 방법에 대해 무언가를 배울 수 있을지도 모릅니다.\n\n<div class=\"content-ad\"></div>\n\n만약 우리가 여성 교황 같은 다른 현실을 상상해야 한다면, 아마도 우리는 사회 시스템을 통해 일부 사회를 다른 일부에 종속시키는 것을 보게 될지도 모릅니다.\n\n그리고 만약 우리가 계속해서 피할 수 없는 편견에 직면해야 한다면, 아마도 흔해빠진 인종 차별이나 '강렬함'에 대한 고발을 넘어서는 길이 있을지도 모릅니다.\n\n혹은 그렇지 않을 수도 있습니다.\n\n결국, 소셜 미디어는 유용한 도구로 시작했지만 이제는 악달리 투척된 진흙에 의해 발전하고 있습니다. 인공지능도 비슷한 오염된 길로 향하고 있을지도 모릅니다.\n\n<div class=\"content-ad\"></div>\n\n더 이런 글을 보고 싶다면 제 Medium 페이지를 팔로우해보세요. 또는 매달 둘째 주 목요일에 Substack에서 제 Discomfort Zone 뉴스레터를 읽어보세요. 이 기사는 인공 지능을 사용하지 않고 직접 작성했습니다. #zeroAI","ogImage":{"url":"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_0.png"},"coverImage":"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_0.png","tag":["Tech"],"readingTime":9},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>AI(Artificial Intelligence)</h2>\n<p>만일 이 기사를 읽고 계신다면, 구글이 자사의 AI 플랫폼인 Gemini의 이미지 생성 기능을 중단했다는 사실을 아시리라고 가정됩니다.</p>\n<p>언더리프레젠테드 그룹을 선호하는 이미지 결과의 편겸을 해소하기 위해 Gemini는 백인 남성들의 이미지를 생성하는 데 어려움을 겪었습니다. 이로 인해 사용자들은 아메리카의 창립자들, 바이킹, 나치, 그리고 교황들의 흑인 버전을 제시받았습니다:</p>\n<p><img src=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_0.png\" alt=\"이미지\"></p>\n<p>이제 Meta의 AI도 \"비사실적 이미지를 생성한다\"는 사실이 알려졌습니다. 이 달 초 Megan Morrone이 Axios 글에 포함된 몇 가지 이미지가 있습니다:</p>\n<p><img src=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_1.png\" alt=\"2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_1\"></p>\n<p>그리고 구글이 자신을 조금 더 안심하게 만들기 위해 마이크로소프트도 이제 AI 이미지 생성에 대한 비판을 받고 있습니다. 회사의 소프트웨어 엔지니어 중 한 명인 Shane Jones가 이번 주 월스트리트 저널에 편지를 보내며 회사가 OpenAI의 Dall-E 3 모델을 기반으로 한 Copilot Designer 이미지 생성 플랫폼에 대해 논란이 있는 문제를 알면서도 이에 대한 보호장치를 마련하지 않았다고 주장했습니다. Jones는 다음과 같이 말합니다:</p>\n<p>“Copilot Designer는 정치적 편향, 미성년자 음주와 약물 사용, 기업 상표 및 저작권 남용, 음모 이론 및 종교 등 여러 가지 다른 분야에서 해로운 콘텐츠를 생성합니다.”</p>\n<p>출처를 증명하기 위해서 그는 “차 사고”라는 간단한 프롬프트로 생성된 여성을 성적 대상화한 무작위 이미지를 포함한 Copilot 이미지의 스크린샷을 공유했습니다:</p>\n<p><a href=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_2.png\">2024년 5월 16일 - 그들이 세운 국가의 아버지들이 심지어 인간이었다고 말할 사람이 누군지 아무도 모른다고 말할 수 있을까 - 2화</a></p>\n<p>젬니는 최소한 \"예기치 못한\" 이미지를 생성하는 유일한 도구가 아닌 것 같네요.</p>\n<p>Apple은 아직 AI 게임에 참여하지 않은 것에 대해 정말 기쁠 것 같습니다.</p>\n<h2>'편견'이란 무엇인지에 대해 합의할 수조차 없는 것</h2>\n<p>3월 7일 이의 팟캐스트 에피소드에서 렉스 프리드먼과의 인터뷰에서 제미니의 사태에 대해 언급하며, 메타의 최고 AI 과학자 앙 르쿤은 다음과 같이 말했습니다:</p>\n<p>\"편견이 없는 AI 시스템을 만들 수 있는가? 답은: 절대 불가능하며, 그 이유는 기술적 도전 때문이 아니라 (기술적 도전은 있지만) 편견이 바라는 대목에 있기 때문입니다. — 다른 사람들은 편견의 내용에 대해 다른 생각을 가지고 있을 수 있습니다.\"</p>\n<p>그는 또 \"모두에 의해 편견 없음으로 인식되는 시스템은 만들 수 없습니다.\"라고도 말했습니다.</p>\n<p>'AI의 대부분인 르쿤은 머신 러닝 플랫폼은 언제나 편향될 것이라고 확신하고 있습니다. 실제로, 그는 동일 인터뷰에서 이 불가피한 편향을 대처하는 유일한 방법은 Meta에서 일하는 곳인 르쿤이 말했듯이 오픈 소스 모델을 공개하여 그 편향을 분산시키는 것뿐이라고도 말했습니다. 이를 위해 Meta는 Llama AI 모델을 공개했습니다.</p>\n<p>르쿤은 동일 인터뷰에서 기술 회사들이 '각성한(Woke)’ 것이 아니라, 그저 사용자들을 모독하거나 상처 주지 않으려고 하고 있다고 지적했습니다. 문제는, 사람들이 모독받는 것이 매우 다양하다는 것입니다. 한 사람은 여성 교황이 신앙 실천에 반하는 것이라서 모독을 받을 수 있지만, 다른 사람은 여성이 교황이 될 기회가 한 번도 없었다는 이유로 모독을 받을 수도 있습니다.</p>\n<p><img src=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_3.png\" alt=\"이미지\"></p>\n<p>몇 개월 전 Midjourney의 인종 및 성별 편견에 대한 우려를 공유했습니다. 작년 가을 Rest of World 웹사이트의 주요 분석은 AI 이미지 도구가 어떻게 광범히 편견을 지니고 있는지를 보여 주었습니다.'</p>\n<p>LeCun님 말씀이 맞습니다. 편향은 피할 수 없습니다. 왜 피할 수 없는지 설명할 필요가 없을 정도로 Vox 작가 Sigal Samuel이 Future Perfect의 기사에서 문제를 훌륭하게 설명했습니다.</p>\n<p>그렇다면 구글은 어떻게 해야 할까요? 우연히도, Google Deepmind CEO Demis Hassabis는 Gemini 문제가 발견된 다음날 Hard Fork 팟캐스트 인터뷰 예정이었습니다. 다음은 그가 말한 내용입니다:</p>\n<p>\"역사적인 정확성, 절대적으로 필요합니다. 따라서 그것을 고쳐야 합니다. 제네릭한 팁을 받을 때는 일반적인 것이 있습니다. 예를 들어 '강아지를 산책시키는 사람의 그림을 만들거나, 병원에서 간호사의 그림을 만들거나'와 같이, 모두가 이해할 수 있는 보편적인 표현이 필요합니다.\"</p>\n<p>여기서 \"역사적 정확성\" 요소로 다시 돌아가겠지만, \"보편성\"이라는 개념에 대해 어떻게 생각하십니까?</p>\n<h1>인간과 강아지에는 일반화할 수 없는 존재가 없어요</h1>\n<p>1970년대 영국의 작은 마을에서 자라난 저에겐 모든 의사가 남성이자 백인이었습니다. 따라서 남성과 백인으로 일반적인 의사를 상상하는 것은 놀라울 일이 아니에요. 하지만 저는 오늘 제가 사는 21세기의 거대한 도시에서는 여성 의사와 다양한 인종의 의사들이 일반적이라는 것을 알았어요.</p>\n<p>그럼 일반적인 의사가 뭘까요? 당연히, 일반적인 의사란 존재하지 않습니다. 개인과 그들의 직업은 완벽한 원과 사각형처럼 플라톤적인 이상이 아니에요. 특히 \"지구\"를 맥락으로 생각해본다면, 그들은 굉장히 다양합니다. 러시아의 일반적인 의사는 백인이어야 한다거나, 르완다의 일반적인 의사는 흑인이어야 한다고 주장할 수 있겠지만, 그렇게 한다고 성별과 나이 문제가 해결되는 것은 아니에요.</p>\n<p>하사비스가 이 문제에 대한 해결책으로 보편성을 주장한 것이 이상하게 다가옵니다. 아마 시간을 내어 좀 더 심도 있게 생각해보지 못했을 수도 있겠죠. 제가 지미니에게 병원에서 간호사의 보편적인 이미지를 만들 것을 요청해보지는 못했지만, Midjourney가 첫 번째 시도에서 가져온 것은 이렇습니다:</p>\n<p><img src=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_4.png\" alt=\"image\"></p>\n<p>When it comes to creating images, striving for universality is a noble goal. But here's a fun fact: there's no such thing as an \"average\" human being. The problem with averages is that, on average, a person has about one testicle!</p>\n<p>Categories like \"dog walker\" or \"nurse\" help us make sense of the world, but they are subjective and can vary widely. It's no wonder that even advanced AI can struggle with complex tasks. Perhaps it'll excel in more specific categories.</p>\n<p>Excited for what's coming up next: a glimpse at a historically accurate portrayal of Jesus. Stay tuned!</p>\n<p>우리는 편견을 피할 수 없다는 것을 알았고 보편성이 막다른 골목이라는 것도 보았다. 그래서 자리미 이미지에 대한 세 번째 반대 이유는 무엇이었을까? 이 문제를 해석한 것은 하사비스가 \"역사적 정확성\"이라고 했다. 그러나 \"정확성\"에 대해 생각하기 시작하면 \"역사적\" 부분은 단지 하위 집합일 뿐이다. 결국, 여성 교황이나 여자 NFL 선수들은 역사적으로 부정확할뿐만 아니라 현대에 존재할 수 없는 사회적 불가능성을 보여준다.</p>\n<p>여성 교황이나 피부색이 어두운 나치에 대한 이미지가 잘못된 이유에 대해 조금 더 파헤쳐 볼까요? \"정확성\"이 정말 무엇을 의미하는지요? 이 답변은 철학적이면서 기술적인 면으로 빠르게 나타납니다.</p>\n<p>교황, 나치, 바이킹, 간호사, NFL 선수 및 창립 아버지는 모두 사람들의 범주입니다. 그러나 이러한 범주들은 서로 다릅니다. 교황은 간호사와 같은 범주보다 훨씬 제한된 특성을 따르는 사람들의 범주입니다. 교황의 이미지를 만들라는 요청을 하는 경우 AI가 해결해야 할 문제는 상대적으로 쉽습니다. (이것이 기곽이나 규칙과 같이 제한된 특성을 갖는 폐쇄형 게임에서 기계 학습이 최고의 인간을 빨리 이기게 된 이유입니다. 반면 도시 길에 차를 운전하는 것과 같은 복잡하고 열린 시스템의 \"게임\"은 더 어려운 문제로 나타났습니다.)</p>\n<p>얼마나 많은 스위치를 누르거나 조작하거나 자리미에게 제한된 범주 (교황, 창립 아버지 또는 심지어 나치)와 일반 범주 (미국인이나 여성) 사이의 차이를 배우게 하기만 하면 되는 것이라고 생각할 수도 있습니다. 그러나 AI 이미지 생성의 어려운 문제에 대해 또 다른 관점을 제공하는 철학적 요인들이 있기 때문에 이 문제에 대해 별도의 기사에서 탐구할 필요가 있습니다.</p>\n<p>“역사적 정확성”이라는 것은 심지어 역사학자들도 일치하지 못하는 것이라고 해도 과언이 아닐 거예요. 말로 설명하기 어려운 예를 들자면 한번만 주제를 예수님으로 가져와볼게요. 예수님의 그림을 다들 보셨을 텐데요. 역사상 가장 유명한 인물 중 한 명이죠. 그런데... 음... 사실 아는 사람들은 알거예요, 지금까지 그에 대한 그림 하나라도 정확한 것이 없어요.</p>\n<p><img src=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_5.png\" alt=\"image\"></p>\n<p>인공지능에 의해 창작된 것인지, 13세기 화가에 의한 것인지, 아니면 20세기 포토샵을 사용해서 만들어졌는지에 대해 어느 누가 실제로 지금까지 나온 예수님의 그림의 정확성에 대해 논할 수 있을까요? 제가 또 뭔가 엉성한 구원주를 주제로 만들고 있다고 생각할 수도 있겠네요. 알겠어요, 한 단계 더 파고들어볼게요.</p>\n<p>그림에 대한 “정확성”이란 무엇일까요? 정지된 상태거나 움직이는 그림이 언제나 현실을 정확하게 나타내는 것이라는 생각은 타당하게 논박될 수 없어요. 사진기가 발명되자마자 화가들은 인상파와 입체주의와 같은 예술 스타일을 개발했는데, 이것들이 사진보다 더 현실적이라고 주장했어요. 맥락은 어떻게 세상을 보느냐에 엄청난 영향을 미쳐요. 다른 사람들은 심지어 같은 색도 다르게 보거든요, 그래서 어떠한 시각적 정확성이라는 주장이 항상 미끄러운 경사 위에 있을 거예요.</p>\n<h1>다행히도, AI 이미지가 등장하기 전에 Lin-Manuel Miranda가 Hamilton을 만들었습니다</h1>\n<p>화가 뿐만 아니라 작가와 감독들도 현실에 예술적 해석을 적용할 수 있어요. \"색맹 캐스팅\"을 하거나 과거와 현재의 사건에 원하는 해석을 달아줄 수 있어요. 우리는 주인공들이 검은 배우들에 의해 연기되기 때문에 Hamilton이 역사적으로 부정확하다고 잊지 말아야 해요. 오히려 그들은 무대에서 역사적 사건의 해석을 노래와 춤으로 몇 시간 동안 표현한 것이기 때문에 역사적으로 부정확해요!</p>\n<p>어떤 예술도 절대적으로 \"현실적\"이거나 \"정확\"하지 않아요. 이것이 우리가 이 논란에 대해 몇몇 철학적 측면을 이해할 수 있는 곳이에요. 원래의 주인공들은 그림 속에만 존재하는 특정 인물들이에요. 하지만 그림이 얼마나 역사적으로 정확한가요? Hamilton은 무대 뮤지컬이기 때문에 \"비현실적 해석\" 범주에 속해요.</p>\n<p><img src=\"/assets/img/2024-05-16-WhosToSaythattheFoundingFathersWereEvenHumanDontBlameGemini_6.png\" alt=\"Image\"></p>\n<p>사람들이 창의적인 이미지를 만들기 위해 발견의 아버지, 교황 및 나치들의 그림을 만들기 위해 제미니를 사용하는 이유는 이미 인터넷에 자유롭게 사용할 수 있는 이미지가 있기 때문인가요? 유일한 이유는 새로운 무언가를 만들기 위해서예요. 이것이 예술이고, 이런 경우에는 \"정확성\"은 중요하지 않아요. 예술 작품은 창시자를 흑인으로, 교황을 여성으로 특징으로 할 수 있어요. 관습을 도전하는 것이 예술의 일부예요. 따라서 AI가 같은 일을 하는 데 분노할 이유는 없어요.</p>\n<p>우리가 보고 있는 문제는 사람들이 AI 출력물을 \"현실적 해석\" 범주로 여기는 것 같아요. 그러나 AI가 생성한 콘텐츠는 정의상 \"현실적이지 않다는\" 것이고, 이는 LLM 텍스트 출력뿐만 아니라 생성된 이미지에도 동일하게 적용돼요.</p>\n<p>이 모든 것이 의미하는 바는 많은 사용 사례에 대해 생성적 AI 제품을 정말 재미있는 장난감, 예술적 도구 또는 즐거운 시간으로 분류해야 한다는 것이에요. 그리고 이 모든 사용 사례를 \"콘텐츠 생성\"으로 분류할 수 있어요. 이는 앞으로 다룰 제 개 다음 글에서 더 자세히 살펴볼 내용이에요.</p>\n<p>AI 플랫폼을 멋진 장난감으로 보는 문제는 플랫폼을 소유하고 있는 기업(기술을 확장하려는 막상종잣돈을 요구하는 기업 포함)이 그들의 제품을 이 방식으로 분류하려는 동기가 없다는 것이에요.</p>\n<p>AI 소수정예주의자들이 인공 일반 지능이 바로 거리 두지 않다고 주장하며 자신들의 제품을 진지한 도구로 분류할 필요가 있습니다. Yann LeCun이 명백히 거부하는 생각입니다. Gemini 사태는 이러한 제품들이 신뢰성을 잃을 수도 있는 산업을 위한 첫 번째 떨림의 전조일 수 있습니다.</p>\n<p>하지만, Meta라면 어떨까요? Meta의 Emu 이미지 생성 모델은 \"점점 더 황당한 아이디어에 기반한 이미지를 만들기 위한 것\"입니다. 아주 좋은 아트의 정의죠, 정확성이 아니라.</p>\n<h1>이 구름에 은매가 가려 있는 건가요, 그건 역사적으로 부정확한 색일까요?</h1>\n<p>최종적으로, AI 이미지 생성 뒤에 극복할 수 없는 결함이 우리에게 역사적 정확성에 대한 개념을 재검토할 필요성을 요구할 수 있습니다. 아마도 우리가 오늘과 같은 곳에 도달한 방법에 대해 무언가를 배울 수 있을지도 모릅니다.</p>\n<p>만약 우리가 여성 교황 같은 다른 현실을 상상해야 한다면, 아마도 우리는 사회 시스템을 통해 일부 사회를 다른 일부에 종속시키는 것을 보게 될지도 모릅니다.</p>\n<p>그리고 만약 우리가 계속해서 피할 수 없는 편견에 직면해야 한다면, 아마도 흔해빠진 인종 차별이나 '강렬함'에 대한 고발을 넘어서는 길이 있을지도 모릅니다.</p>\n<p>혹은 그렇지 않을 수도 있습니다.</p>\n<p>결국, 소셜 미디어는 유용한 도구로 시작했지만 이제는 악달리 투척된 진흙에 의해 발전하고 있습니다. 인공지능도 비슷한 오염된 길로 향하고 있을지도 모릅니다.</p>\n<p>더 이런 글을 보고 싶다면 제 Medium 페이지를 팔로우해보세요. 또는 매달 둘째 주 목요일에 Substack에서 제 Discomfort Zone 뉴스레터를 읽어보세요. 이 기사는 인공 지능을 사용하지 않고 직접 작성했습니다. #zeroAI</p>\n</body>\n</html>\n"},"__N_SSG":true}