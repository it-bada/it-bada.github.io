{"pageProps":{"post":{"title":"사람들이 AI의 변혁적 힘에 대해 오해하는 것들","description":"","date":"2024-07-01 20:36","slug":"2024-07-01-WhatEveryoneGetsWrongabouttheTransformativePowerofAI","content":"\n\n## AI가 사회를 변화시킬 것이지만, 지금까지의 변화는 예상과는 다를 수 있음을 사회는 보여주고 있습니다. 그 변화가 제어되지 않으면 지불해야 할 비용이 과도할 수도 있습니다.\n\n![image](/assets/img/2024-07-01-WhatEveryoneGetsWrongabouttheTransformativePowerofAI_0.png)\n\n한 달 전 존 스튜어트가 AI로 인해 사람들이 일자리를 잃는다는 세그먼트를 했었죠. 그는 그에 반대했습니다. 사실 그의 말은 반대했지만, 깊은 곳에서는 그것을 지지하고 있고, 당신도 마찬가지입니다. 아니면 아직 모르고 있을 뿐일지도 모르겠네요.\n\n현재의 최첨단 기술, AI의 대규모 언어 모델에 대해 TV에서 이야기할 수 있는 것 자체가 이전 기술이 일자리를 없애 버렸기 때문입니다. 대부분의 일자리, 거의 모든 일자리가 사라졌습니다. 인류 역사의 대부분에서 80-90%의 사람들은 농부였습니다. 그들 중 소수는 대장간, 재봉사 등 핵심 직업을 가졌습니다. 하지만 그들이 가지지 않았던 것은 TV 개성, TV 임원 또는 심지어 TV였습니다.\n\n<div class=\"content-ad\"></div>\n\n수백 년 전에 태어났더라면, 아마 농부가 되었을 겁니다. 또한 확실히 감염으로 사망했을 겁니다. 그러나 과학 기술 발전 덕분에 더 적은 농부가 필요했고, 그 결과로 역학 및 기술 혁신을 통해 역병과 같은 감염의 치료법을 발견, 제조 및 보급할 수 있는 의사와 과학자가 나타났습니다. 과학 기술 혁신은 과학 기술 혁신을 낳습니다. 생성적 AI는 그저 현재의 최신 기술입니다 (우리가 다른 앞날 본기술들을 가지고 있기 때문에 제일뿐).\n\n하지만, 모든 것이 순조롭게 이루어진다는 것은 아닙니다. 많은 기술 CEO들이 AI의 큰 긍정적 영향에 대해 이야기하지만, 안타깝게도 시간이 필요할 겁니다. 자동차를 생각해 보십시오; 1886년에 독일에서 칼 벤츠가 자동차를 특허했습니다. 미국에 자동차가 등장한 것은 대략 15년 후인데 그때까지 미국에는 8,000대밖에 없었습니다. 1910년까지 빠르게 성장하여 500,000대에 이르렀습니다. 그런데도 그것은 25년이 걸리게되고 실제로 미국 인구의 약 절반 이상만이 자동차를 소유했습니다. 처음으로 정지 신호등이 사용된 건 1915년 이후였습니다 (물론 중요한 교차로에 신호등은 조금 더 일찍 설치되었습니다). 포인트는, 사람들과 기업들이 자동차를 광범위하게 도입하기 전에 수십 년이 걸렸으며, 이는 견공적 규정과 사회적 규범을 찾는 시간을 주었습니다.\n\n다른 한편으로, 소셜 미디어는 2008년 Facebook이 실질적으로 성장하기 시작할 때까지 거의 사용되지 않았습니다. 얼마 지나지 않아 몇 백만 명의 사용자가 4년 만에 10억 명으로 증가했습니다. 이후 소셜 미디어는 사이버 괴롭힘, 자존감 문제, 신체 이미지 문제, 우울증 및 많은 다른 정신 건강 문제를 야기했습니다. 미리 정찰된 위험과 부정적 영향에 대한 데이터가 애매하게 거론되었습니다. 반면 자동차의 경우, 사람들은 일찍부터 위험을 보았고 정찰적인 예방 조치를 취할 수 있었으며, 정찰적 예방 조치를 취하기 전에 사람들을 위한 정지 신호 또는 운전 면허를 요구하듯이 상쇄적인 조치를 취할 수 있었습니다. 우리가 모든 것을 올바르게 이해한 것이라고 말하기에는 이르지 못했습니다. 1980년대까지는 그렇지 않았습니다. 극단 운전 반대운동을 이끈 Candy Lightner와 같은 사람들 때문에 우리는 술취한 운전에 맞섰고 바로세웠습니다.\n\n핵무기는 1945년으로 거슬러 올라갑니다. 20세기 대부분의 시기에는 미국, 러시아, 영국, 프랑스, 중국이 무기에 접근할 수 있었지만, 나중에 인도가 이 클럽에 가입했습니다. 이 무기는 세계에 건전한 위험을 초래했습니다. 그러나 사용할 권한을 가진 사람들은 규제를 갖추고 있었습니다. 그들의 정부는 일반적으로 잠재적인 부정적 결과, 적어도 그들에게는 그리 심오하지 않을 것이지만, 세계를 이해하고 사용을 소극적하게 해왔습니다. 북한이 덜 성숙한 지배력을 가지고 있다는 우려도 있습니다. 그러나 사실은 김정은이 핵탄두를 사용하면 핵보복을 유인할 것을 알고, 이는 그의 사후 전망을 (그가 생존하더라도) 훨씬 악화시킬 것임을 알고 있기 때문에 이를 자제하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n테러조직이 그것을 얻었다면 어떨까요? 김정은은 죽거나 나라가 파괴되는 걸 원하지 않아요. 전투에서의 죽음이 현재 상황보다 나은 것이라고 믿는 사람들은 어떻게 될까요? 그들은 자신이 순교자로 죽는 것이 긍정적 결과라고 생각하기 때문에 핵미사일을 발사할 것입니다. 이것은 게임 이론 101입니다. 시장에 더 빨리 도착하면 차량을 이용하여 비용을 절약할 수 있습니다. 시장으로 향하는 도중 다른 사람의 닭을 가끔 치기도 하지만(법에 저촉되는 것이 없다고 가정하면서), 왜 하지 않을까요? 여러분에게 이익이 있고, 부정적인 결과는 다른 누군가에게 남기는 것입니다.\n\n이 같은 논리는 AI에도 적용됩니다. 어떤 사람이든 더 긍정적인 결과를 창출할 것으로 생각되는 도구를 사용할 것입니다. 결국 목적이 수단을 정당화한다고 생각한다면 소셜 미디어에 가짜 정보를 공유하거나 AI를 사용해 만든 정보도 정당화됩니다. 이에 동의하지 않더라도, AI와 다른 도구 사용에 있어서 선하고 도덕적일 것을 바라더라도 결과에 완전히 동의할 수 있나요? 뉴욕시에 아는 여성 대부분은 소셜 모임에서 찍은 내 사진을 게시하기 전에 확인하고 승인해야 합니다. 그들은 악의를 품는 것이 아니라 소셜 미디어에 멋있게 보이려고 하는 것뿐입니다. 하지만 이런 행동으로 인해 모든 사람들이 이를 하게 되면 온라인 사진이 평균 이상으로 보이도록 바이어스가 생기고(머리, 메이크업, 드레스, 조명, 각도가 모두 조화를 이룰 때 그들이 사진을 승인합니다), 이는 10대 소녀들의 몸에 대한 이미지 문제를 유발합니다. 누구도 10대 소녀를 해치려고 했던 것이 아니지만, 예상치 못한 외부성이었습니다. 여기에는 더 많은 예시가 있습니다.\n\nAI는 핵무기는 아니지만 해를 끼칠 수 있는 도구입니다. 수십 년이 걸리던 이전 기술과는 다르게 AI 도입은 더 빠르게 진행되고 있습니다. 제품의 안전 경고를 아무도 읽지 않는다고 지적하고 싶지만, 아직 AI에 대해 완전히 이해하지 못해 안전 경고조차 완전하지 못합니다. 만약 1900년에 50%의 미국인이 세 달 동안 자동차에 접근할 수 있었다면(돈과 연료 인프라를 포함하여), 어떤 규정이 필요한지 알아내기 전에 얼마나 많은 사망자와 문제가 발생했을까요?\n\n스타플릿의 주요 지침은 기술 때문에 자신들을 해칠 위험이 있는 성장이 덜 한 종족을 보호하기 위해 시행되었습니다. 외부 기술만이 일으키는 위협이 아니라는 것은 명확하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n이 문제는 실제로 인공지능이 주된 주제가 아닙니다. 이는 우리가 이해하기에 속도가 빠른 충분히 영향력 있는 기술에 대한 이야기입니다. 세 가지 요인이 작용합니다. 첫 번째는 채택 속도로, 기술이 얼마나 빨리 적용되는지를 나타냅니다. 두 번째는 영향 반경입니다: (영향의 규모) x (영향을 받는 사람 수) x (영향 지속 기간). (영향 반경이 물리적인 거리가 아닌 개념적인 공간에서의 거리임을 기억하세요.)\n\n세 번째는 학습 곡선으로, 영향을 얼마나 빨리 이해할 수 있는지를 의미합니다. 영향을 이해하든 그렇지 않든 (학습 곡선 상 어디에 있는지에 관계없이) 영향은 실제로 발생합니다. 사람들은 소셜 미디어로부터 신체 이미지 문제로 고통받았지만, 아직 그 사실을 알지 못했습니다.\n\n영향 반경이 작으면 기술을 시험해보고 위험을 제한할 수 있습니다. 스페이스 셔틀은 훌륭한 기술이었지만, 위험을 수반했습니다. 챌린저와 콜롬비아의 파괴로 일부 우주 비행사 (그리고 돈)를 잃었습니다. 삶의 손실을 경시하려는 의도는 아니지만, 손실은 최소였고 그 위험을 이해하는 한정된 인원에 의해 진행되었습니다.\n\n채택 속도가 영향 반경을 초과할 때, 특히 학습 곡선 상승 속도보다 빨라질 때, 우리는 과도한 위험에 직면합니다; 우리는 효과를 이해하기보다 더 빨리 만들어냅니다. 이는 재앙의 요소가 됩니다. 집에서 일어날 때 빠르게 움직이고 물건을 부수는 것은 괜찮습니다. 그러나 1200파운드의 자동차를 40마일(모델 T의 전형적인 속도)로 길을 달릴 때 이 철학을 정당화하기는 어렵습니다. 이런 상황이 동네의 절반 이상이 함께 행동할 때 상황은 훨씬 어려워집니다. 불행히도, 인공지능도 소셜 미디아와 같이 독립적인 집안에서 제한돼있지 않아서, 그 위험이 오로지 당신에게만 영향을 미치는 것이 아닙니다.\n\n<div class=\"content-ad\"></div>\n\nWhen X-rays were first discovered, they seemed like something out of a sci-fi film. Back in the 1920s, shoe stores even used fluoroscopes to help customers see how well shoes fit by showing X-ray images of their feet in the shoes. Unfortunately, at the time, not many people were aware of the health risks posed by radiation. It wasn't until years later, after many had been exposed unnecessarily, that we truly understood the long-term effects. By then, countless individuals had suffered from overexposure to radiation.\n\nIn contrast, the telephone quickly gained popularity in the US during the first half of the 20th century. Fortunately, the phone itself didn't pose serious health risks, limiting its impact zone. (Although, a real concern back then was neighbors eavesdropping on party-lines without understanding how they functioned!)\n\nReflecting on the industrial revolution, it's evident that rapid innovations often led to environmental damage. Land was strip-mined, mountains deforested, and water and air polluted. The infamous 1969 Cuyahoga River fire is a stark example—yes, a river was actually on fire due to pollution. Shockingly, this river had caught fire multiple times, but not much was done about it. As David Newton noted in his book \"Chemistry of the Environment\" (p. 6), such environmental harm was once viewed as a sign of progress. How much societal harm are we willing to accept for advancement?\n\nArtificial Intelligence (AI) offers incredible transformations, but we must proceed cautiously until we grasp its risks fully. The existence of risks shouldn't deter us from using AI; after all, cars also come with risks, yet we prioritize the benefits. The difference lies in our understanding of cars and their risks, which evolved alongside their widespread use. AI remains less understood. Yes, we should start using it to uncover risks, but we shouldn't hand over the keys to 500,000 inexperienced drivers overnight. It's simpler to relax precautions later than to impose them afterward (particularly when profitable corporations influence politics to resist regulations, as seen with the military-industrial complex, tobacco, oil, and Big Tech).\n\n<div class=\"content-ad\"></div>\n\n혁신에는 찬성하지만 신중히 진행해야 한다고 생각해요. 인더스트리얼 혁명 초기에 환경에 어떤 피해를 줄 수 있는지 제한을 두었더라면 어땠을까요? 전쟁 중에는 자원이 제한되어 있지만 사회는 혁신합니다. 월스트리트를 규제하면 파티가 끝났다고 불평하지만 새로운 방법으로 수익을 창출하는 혁신을 합니다. 규제는 혁신을 막지 않고 때로는 오히려 영감을 줍니다. 인더스트리얼 혁명을 풀어놓고 오늘날 대가를 치르고 있습니다. 최근에는 소셜 미디어가 사회를 \"변형\"시켰지만 항상 긍정적이지는 않았어요. 같은 실수를 반복하지 말고 AI가 무제한으로 혁신하게 해둔 채 나중에 규제하는 것은 좋지 않아요. 지니는 쉽게 병자에 넣을 수 없습니다. 우리는 과거의 실수를 반복하지 않기 위해 역사를 연구합니다. 이번 시험에서 우리의 실력을 확인해봅시다.\n\n이 글은 https://www.thecareertoolkitbook.com에서 원문이 게시되었습니다.\n\n마크 A. 허쉬버그는 CTO이자 MIT 강사, 연설가이자 The Career Toolkit: Essential Skills for Success That No One Taught You 저자, Brain Bump 앱의 창작자입니다.\n\n<div class=\"content-ad\"></div>\n\n이 컬럼은 직업에 관한 것이에요. 또한 그는 Medium에서 미디어에 관해 @cognoscomedia로 글을 씁니다. ","ogImage":{"url":"/assets/img/2024-07-01-WhatEveryoneGetsWrongabouttheTransformativePowerofAI_0.png"},"coverImage":"/assets/img/2024-07-01-WhatEveryoneGetsWrongabouttheTransformativePowerofAI_0.png","tag":["Tech"],"readingTime":8},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>AI가 사회를 변화시킬 것이지만, 지금까지의 변화는 예상과는 다를 수 있음을 사회는 보여주고 있습니다. 그 변화가 제어되지 않으면 지불해야 할 비용이 과도할 수도 있습니다.</h2>\n<p><img src=\"/assets/img/2024-07-01-WhatEveryoneGetsWrongabouttheTransformativePowerofAI_0.png\" alt=\"image\"></p>\n<p>한 달 전 존 스튜어트가 AI로 인해 사람들이 일자리를 잃는다는 세그먼트를 했었죠. 그는 그에 반대했습니다. 사실 그의 말은 반대했지만, 깊은 곳에서는 그것을 지지하고 있고, 당신도 마찬가지입니다. 아니면 아직 모르고 있을 뿐일지도 모르겠네요.</p>\n<p>현재의 최첨단 기술, AI의 대규모 언어 모델에 대해 TV에서 이야기할 수 있는 것 자체가 이전 기술이 일자리를 없애 버렸기 때문입니다. 대부분의 일자리, 거의 모든 일자리가 사라졌습니다. 인류 역사의 대부분에서 80-90%의 사람들은 농부였습니다. 그들 중 소수는 대장간, 재봉사 등 핵심 직업을 가졌습니다. 하지만 그들이 가지지 않았던 것은 TV 개성, TV 임원 또는 심지어 TV였습니다.</p>\n<div class=\"content-ad\"></div>\n<p>수백 년 전에 태어났더라면, 아마 농부가 되었을 겁니다. 또한 확실히 감염으로 사망했을 겁니다. 그러나 과학 기술 발전 덕분에 더 적은 농부가 필요했고, 그 결과로 역학 및 기술 혁신을 통해 역병과 같은 감염의 치료법을 발견, 제조 및 보급할 수 있는 의사와 과학자가 나타났습니다. 과학 기술 혁신은 과학 기술 혁신을 낳습니다. 생성적 AI는 그저 현재의 최신 기술입니다 (우리가 다른 앞날 본기술들을 가지고 있기 때문에 제일뿐).</p>\n<p>하지만, 모든 것이 순조롭게 이루어진다는 것은 아닙니다. 많은 기술 CEO들이 AI의 큰 긍정적 영향에 대해 이야기하지만, 안타깝게도 시간이 필요할 겁니다. 자동차를 생각해 보십시오; 1886년에 독일에서 칼 벤츠가 자동차를 특허했습니다. 미국에 자동차가 등장한 것은 대략 15년 후인데 그때까지 미국에는 8,000대밖에 없었습니다. 1910년까지 빠르게 성장하여 500,000대에 이르렀습니다. 그런데도 그것은 25년이 걸리게되고 실제로 미국 인구의 약 절반 이상만이 자동차를 소유했습니다. 처음으로 정지 신호등이 사용된 건 1915년 이후였습니다 (물론 중요한 교차로에 신호등은 조금 더 일찍 설치되었습니다). 포인트는, 사람들과 기업들이 자동차를 광범위하게 도입하기 전에 수십 년이 걸렸으며, 이는 견공적 규정과 사회적 규범을 찾는 시간을 주었습니다.</p>\n<p>다른 한편으로, 소셜 미디어는 2008년 Facebook이 실질적으로 성장하기 시작할 때까지 거의 사용되지 않았습니다. 얼마 지나지 않아 몇 백만 명의 사용자가 4년 만에 10억 명으로 증가했습니다. 이후 소셜 미디어는 사이버 괴롭힘, 자존감 문제, 신체 이미지 문제, 우울증 및 많은 다른 정신 건강 문제를 야기했습니다. 미리 정찰된 위험과 부정적 영향에 대한 데이터가 애매하게 거론되었습니다. 반면 자동차의 경우, 사람들은 일찍부터 위험을 보았고 정찰적인 예방 조치를 취할 수 있었으며, 정찰적 예방 조치를 취하기 전에 사람들을 위한 정지 신호 또는 운전 면허를 요구하듯이 상쇄적인 조치를 취할 수 있었습니다. 우리가 모든 것을 올바르게 이해한 것이라고 말하기에는 이르지 못했습니다. 1980년대까지는 그렇지 않았습니다. 극단 운전 반대운동을 이끈 Candy Lightner와 같은 사람들 때문에 우리는 술취한 운전에 맞섰고 바로세웠습니다.</p>\n<p>핵무기는 1945년으로 거슬러 올라갑니다. 20세기 대부분의 시기에는 미국, 러시아, 영국, 프랑스, 중국이 무기에 접근할 수 있었지만, 나중에 인도가 이 클럽에 가입했습니다. 이 무기는 세계에 건전한 위험을 초래했습니다. 그러나 사용할 권한을 가진 사람들은 규제를 갖추고 있었습니다. 그들의 정부는 일반적으로 잠재적인 부정적 결과, 적어도 그들에게는 그리 심오하지 않을 것이지만, 세계를 이해하고 사용을 소극적하게 해왔습니다. 북한이 덜 성숙한 지배력을 가지고 있다는 우려도 있습니다. 그러나 사실은 김정은이 핵탄두를 사용하면 핵보복을 유인할 것을 알고, 이는 그의 사후 전망을 (그가 생존하더라도) 훨씬 악화시킬 것임을 알고 있기 때문에 이를 자제하고 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>테러조직이 그것을 얻었다면 어떨까요? 김정은은 죽거나 나라가 파괴되는 걸 원하지 않아요. 전투에서의 죽음이 현재 상황보다 나은 것이라고 믿는 사람들은 어떻게 될까요? 그들은 자신이 순교자로 죽는 것이 긍정적 결과라고 생각하기 때문에 핵미사일을 발사할 것입니다. 이것은 게임 이론 101입니다. 시장에 더 빨리 도착하면 차량을 이용하여 비용을 절약할 수 있습니다. 시장으로 향하는 도중 다른 사람의 닭을 가끔 치기도 하지만(법에 저촉되는 것이 없다고 가정하면서), 왜 하지 않을까요? 여러분에게 이익이 있고, 부정적인 결과는 다른 누군가에게 남기는 것입니다.</p>\n<p>이 같은 논리는 AI에도 적용됩니다. 어떤 사람이든 더 긍정적인 결과를 창출할 것으로 생각되는 도구를 사용할 것입니다. 결국 목적이 수단을 정당화한다고 생각한다면 소셜 미디어에 가짜 정보를 공유하거나 AI를 사용해 만든 정보도 정당화됩니다. 이에 동의하지 않더라도, AI와 다른 도구 사용에 있어서 선하고 도덕적일 것을 바라더라도 결과에 완전히 동의할 수 있나요? 뉴욕시에 아는 여성 대부분은 소셜 모임에서 찍은 내 사진을 게시하기 전에 확인하고 승인해야 합니다. 그들은 악의를 품는 것이 아니라 소셜 미디어에 멋있게 보이려고 하는 것뿐입니다. 하지만 이런 행동으로 인해 모든 사람들이 이를 하게 되면 온라인 사진이 평균 이상으로 보이도록 바이어스가 생기고(머리, 메이크업, 드레스, 조명, 각도가 모두 조화를 이룰 때 그들이 사진을 승인합니다), 이는 10대 소녀들의 몸에 대한 이미지 문제를 유발합니다. 누구도 10대 소녀를 해치려고 했던 것이 아니지만, 예상치 못한 외부성이었습니다. 여기에는 더 많은 예시가 있습니다.</p>\n<p>AI는 핵무기는 아니지만 해를 끼칠 수 있는 도구입니다. 수십 년이 걸리던 이전 기술과는 다르게 AI 도입은 더 빠르게 진행되고 있습니다. 제품의 안전 경고를 아무도 읽지 않는다고 지적하고 싶지만, 아직 AI에 대해 완전히 이해하지 못해 안전 경고조차 완전하지 못합니다. 만약 1900년에 50%의 미국인이 세 달 동안 자동차에 접근할 수 있었다면(돈과 연료 인프라를 포함하여), 어떤 규정이 필요한지 알아내기 전에 얼마나 많은 사망자와 문제가 발생했을까요?</p>\n<p>스타플릿의 주요 지침은 기술 때문에 자신들을 해칠 위험이 있는 성장이 덜 한 종족을 보호하기 위해 시행되었습니다. 외부 기술만이 일으키는 위협이 아니라는 것은 명확하지 않습니다.</p>\n<div class=\"content-ad\"></div>\n<p>이 문제는 실제로 인공지능이 주된 주제가 아닙니다. 이는 우리가 이해하기에 속도가 빠른 충분히 영향력 있는 기술에 대한 이야기입니다. 세 가지 요인이 작용합니다. 첫 번째는 채택 속도로, 기술이 얼마나 빨리 적용되는지를 나타냅니다. 두 번째는 영향 반경입니다: (영향의 규모) x (영향을 받는 사람 수) x (영향 지속 기간). (영향 반경이 물리적인 거리가 아닌 개념적인 공간에서의 거리임을 기억하세요.)</p>\n<p>세 번째는 학습 곡선으로, 영향을 얼마나 빨리 이해할 수 있는지를 의미합니다. 영향을 이해하든 그렇지 않든 (학습 곡선 상 어디에 있는지에 관계없이) 영향은 실제로 발생합니다. 사람들은 소셜 미디어로부터 신체 이미지 문제로 고통받았지만, 아직 그 사실을 알지 못했습니다.</p>\n<p>영향 반경이 작으면 기술을 시험해보고 위험을 제한할 수 있습니다. 스페이스 셔틀은 훌륭한 기술이었지만, 위험을 수반했습니다. 챌린저와 콜롬비아의 파괴로 일부 우주 비행사 (그리고 돈)를 잃었습니다. 삶의 손실을 경시하려는 의도는 아니지만, 손실은 최소였고 그 위험을 이해하는 한정된 인원에 의해 진행되었습니다.</p>\n<p>채택 속도가 영향 반경을 초과할 때, 특히 학습 곡선 상승 속도보다 빨라질 때, 우리는 과도한 위험에 직면합니다; 우리는 효과를 이해하기보다 더 빨리 만들어냅니다. 이는 재앙의 요소가 됩니다. 집에서 일어날 때 빠르게 움직이고 물건을 부수는 것은 괜찮습니다. 그러나 1200파운드의 자동차를 40마일(모델 T의 전형적인 속도)로 길을 달릴 때 이 철학을 정당화하기는 어렵습니다. 이런 상황이 동네의 절반 이상이 함께 행동할 때 상황은 훨씬 어려워집니다. 불행히도, 인공지능도 소셜 미디아와 같이 독립적인 집안에서 제한돼있지 않아서, 그 위험이 오로지 당신에게만 영향을 미치는 것이 아닙니다.</p>\n<div class=\"content-ad\"></div>\n<p>When X-rays were first discovered, they seemed like something out of a sci-fi film. Back in the 1920s, shoe stores even used fluoroscopes to help customers see how well shoes fit by showing X-ray images of their feet in the shoes. Unfortunately, at the time, not many people were aware of the health risks posed by radiation. It wasn't until years later, after many had been exposed unnecessarily, that we truly understood the long-term effects. By then, countless individuals had suffered from overexposure to radiation.</p>\n<p>In contrast, the telephone quickly gained popularity in the US during the first half of the 20th century. Fortunately, the phone itself didn't pose serious health risks, limiting its impact zone. (Although, a real concern back then was neighbors eavesdropping on party-lines without understanding how they functioned!)</p>\n<p>Reflecting on the industrial revolution, it's evident that rapid innovations often led to environmental damage. Land was strip-mined, mountains deforested, and water and air polluted. The infamous 1969 Cuyahoga River fire is a stark example—yes, a river was actually on fire due to pollution. Shockingly, this river had caught fire multiple times, but not much was done about it. As David Newton noted in his book \"Chemistry of the Environment\" (p. 6), such environmental harm was once viewed as a sign of progress. How much societal harm are we willing to accept for advancement?</p>\n<p>Artificial Intelligence (AI) offers incredible transformations, but we must proceed cautiously until we grasp its risks fully. The existence of risks shouldn't deter us from using AI; after all, cars also come with risks, yet we prioritize the benefits. The difference lies in our understanding of cars and their risks, which evolved alongside their widespread use. AI remains less understood. Yes, we should start using it to uncover risks, but we shouldn't hand over the keys to 500,000 inexperienced drivers overnight. It's simpler to relax precautions later than to impose them afterward (particularly when profitable corporations influence politics to resist regulations, as seen with the military-industrial complex, tobacco, oil, and Big Tech).</p>\n<div class=\"content-ad\"></div>\n<p>혁신에는 찬성하지만 신중히 진행해야 한다고 생각해요. 인더스트리얼 혁명 초기에 환경에 어떤 피해를 줄 수 있는지 제한을 두었더라면 어땠을까요? 전쟁 중에는 자원이 제한되어 있지만 사회는 혁신합니다. 월스트리트를 규제하면 파티가 끝났다고 불평하지만 새로운 방법으로 수익을 창출하는 혁신을 합니다. 규제는 혁신을 막지 않고 때로는 오히려 영감을 줍니다. 인더스트리얼 혁명을 풀어놓고 오늘날 대가를 치르고 있습니다. 최근에는 소셜 미디어가 사회를 \"변형\"시켰지만 항상 긍정적이지는 않았어요. 같은 실수를 반복하지 말고 AI가 무제한으로 혁신하게 해둔 채 나중에 규제하는 것은 좋지 않아요. 지니는 쉽게 병자에 넣을 수 없습니다. 우리는 과거의 실수를 반복하지 않기 위해 역사를 연구합니다. 이번 시험에서 우리의 실력을 확인해봅시다.</p>\n<p>이 글은 <a href=\"https://www.thecareertoolkitbook.com%EC%97%90%EC%84%9C\" rel=\"nofollow\" target=\"_blank\">https://www.thecareertoolkitbook.com에서</a> 원문이 게시되었습니다.</p>\n<p>마크 A. 허쉬버그는 CTO이자 MIT 강사, 연설가이자 The Career Toolkit: Essential Skills for Success That No One Taught You 저자, Brain Bump 앱의 창작자입니다.</p>\n<div class=\"content-ad\"></div>\n<p>이 컬럼은 직업에 관한 것이에요. 또한 그는 Medium에서 미디어에 관해 @cognoscomedia로 글을 씁니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}