{"pageProps":{"posts":[{"title":"FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가","description":"","date":"2024-07-01 00:01","slug":"2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach","content":"\n\n이미지 경로: [2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png)\n\n# 소개\n\n기술이 발전함에 따라 흥미로운 점은 대부분의 사람들이 좋은 디자인으로 판단되는 것에 수렴한다는 것입니다.\n\n예를 들어 프롬프트 엔지니어링의 경우, 프롬프트가 템플릿으로 진화되어 변수가 주입될 수 있는 자리 표시자가 있는 것을 볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이제 이것은 프롬프트 체이닝으로 진전되었고, 결국 여러 도구를 가진 자율 에이전트로 발전했습니다.\n\n그래서 RAG는 매우 비슷한 궤적을 통과하고 있어요...초반에는 RAG 그 자체로 충분하다고 여겨졌어요. 그러나 이제 RAG 스택에 추가적인 지식이 추가되고, RAG 아키텍처의 일부를 형성하는 여러 요소들과 함께 구성될 예정이에요.\n\n# 네 가지 초기 고려 사항\n\n먼저, 아래 기사에서 보시는 대로 프롬프트 구조가 RAG 아키텍처에서 점점 더 중요해지고 있으며, 연상 기술로 Chain-of-Thought와 같은 프롬프팅 기술이 도입되고 있어요.\n\n<div class=\"content-ad\"></div>\n\n최근에는 단순히 상황 참조 데이터를 주입하는 것만으로는 충분하지 않습니다. 텍스트를 최적화하기 위해 문구가 활용되고 있습니다.\n\n또한 RAG가 두 가지 측면에서 정적임을 인식하고 있습니다. 첫 번째로, RAG가 대화의 맥락을 고려하지 않거나 최소한 다수의 대화 턴에 걸친 맥락을 고려하지 않을 수 있다는 것입니다. 이에 더해, 데이터를 검색할지 말지 결정하는 것은 종종 유연성이 없는 일련의 정적 규칙에 기반하고 있습니다.\n\n세 번째로, 불필요한 오버헤드를 고려하고 있으며, 불필요하고 최적화되지 않은 검색, 추가 텍스트가 추가되어 원치 않는 비용 및 추론 지연을 초래할 수 있습니다.\n\n네 번째로, 최적의 응답을 선택하기 위한 다단계 접근법과 분류기를 사용하거나 다수의 데이터 스토어를 활용하거나 단순히 사용자 요청을 분류하는 데 사용됩니다. 이러한 분류기는 주로 이 특수화된 작업을 위해 모델을 훈련하는 데 사용되는 주석이 달린 데이터에 의존합니다.\n\n<div class=\"content-ad\"></div>\n\n그리고 이전에 언급한 대로, RAG는 라마인덱스가 에이젼틱 RAG로 지칭하는 상태로 나아가고 있습니다. 여기서 RAG 기반 요소는 여러 하위 에이전트나 도구를 활용하여 데이터 검색을 관리하는 데 사용됩니다.\n\n## FIT-RAG\n\nFIT-RAG 연구는 LLM과 사실 데이터를 고려할 때 두 가지 문제를 식별합니다...\n\n사실 데이터 부족: LLM의 원하는 문서에는 특정 쿼리에 필요한 사실 정보가 부족할 수 있으며, 이는 검색기를 오도하고 블랙박스 RAG의 효과를 약화시킬 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nToken Overload: 모든 검색된 문서를 무차별적으로 병합하면 LLM에 사용된 토큰이 과도하게 많아져서 블랙박스 RAG의 효율성이 저하됩니다.\n\nFIT-RAG는 사실적 정보를 고려하여 이중 레이블 문서 점수 판별기를 고안하는 것으로, 이 점수 판별기는 사실적 정보와 LLM 선호도를 구분된 레이블로 통합합니다.\n\n또한 FIT-RAG는 자기-인식 인지기와 하위 문서 수준 토큰 축소기를 포함한 토큰 축소 전략을 구현합니다. 이러한 혁신들은 불필요한 증강을 최소화하고 증강 토큰을 크게 감소시켜 FIT-RAG의 효율성을 향상시키기 위해 설계되었습니다.\n\n# FIT-RAG의 구성요소\n\n<div class=\"content-ad\"></div>\n\n아래 이미지를 고려하면 FIT-RAG는 다섯 가지의 핵심 요소로 구성되어 있습니다:\n\n- 유사성 기반 검색기,\n- 이중 레이블 문서 평가자,\n- 이중 면 성 자기 인식 기능,\n- 하위 문서 수준 토큰 축소기,\n- 프롬프트 구성 모듈.\n\n특히, 이중 레이블 문서 평가자는 LLM 기호와 사실적 정보 모두와의 조화를 능숙하게 포착하기 위해 설계되었으며, 사실적 무지의 위험을 경감시킵니다.\n\n또한, 이중 면 성 자기 인식기와 하위 문서 수준 토큰 축소기는 입력 토큰 최소화에 중요한 역할을 하여 토큰 낭비를 방지합니다.\n\n<div class=\"content-ad\"></div>\n\nThe bi-label document scorer is trained using bi-label learning, which involves two labels:\n\n- Factual information (Has_Answer) and\n- LLM preference (LLM_Prefer).\n\nThe \"Has_Answer\" label tells us if the document contains the answer to the question, while \"LLM_Prefer\" indicates if the document helps the LLM generate an accurate response.\n\nYet, there's a noticeable disparity in data distribution between these labels, potentially affecting the efficiency of bi-label learning. To tackle this issue, the paper introduces a data-imbalance-aware bi-label learning technique.\n\n<div class=\"content-ad\"></div>\n\n이 방법은 데이터에 서로 다른 가중치를 할당하며, 하이퍼 그레이디언트 디센트를 사용하여 자동으로 학습합니다. 이 접근 방식은 데이터 불균형 문제를 효과적으로 다루어서, 바이-라벨 문서 점수기가 검색된 문서를 종합적으로 평가할 수 있도록 합니다.\n\n바이-파셋트 셀프-지식 인식기는 LLM이 외부 지식이 필요한지를 평가하여 두 가지 측면을 고려합니다: 질문이 장기적이거나 오래된 정보에 관련되는지 여부, 그리고 질문의 가장 가까운 대응이 자체 지식을 갖고 있는지 여부.\n\n한편, 서브-문서 레벨의 토큰 축소기는 중복되는 서브-문서를 제거함으로써, 검색된 문서들 중 서브-문서가 적지만 여전히 LLM의 정확한 답변 제공 능력을 향상시킬 수 있는 조합들을 선택합니다.\n\n# FIT-RAG 프롬프트하기\n\n<div class=\"content-ad\"></div>\n\n아래 이미지는 프롬프트 문구가 최적화된 모습을 보여줍니다...\n\n# 결론\n\nRAG(견주-리더-생성자) 파이프라인에 주체적 능력을 통합하면 복잡한 질문과 추론 작업에 대처하는 능력이 크게 향상될 수 있습니다. 주체적 능력을 파이프라인에 추가함으로써, 더 넓은 범위의 복잡한 질문과 시나리오를 다룰 수 있게 됩니다.\n\n그러나 주체적 능력을 가진 에이전트가 직면하는 중요한 도전 과제 중 하나는 의사 결정 프로세스에서 조작성 및 투명성이 부족하다는 것입니다. 사용자 쿼리에 직면했을 때, 에이전트는 생각의 연쇄나 계획 접근을 채택할 수 있으며, 이는 문제 공간을 효과적으로 탐색하기 위해 대형 언어 모델(Large Language Models, LLMs)과 반복 상호 작용이 필요할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nLLMs(대형 언어 모델)과의 반복 상호작용에 의존하는 것은 컴퓨팅 부담을 초래할 뿐만 아니라, 에이전트가 결정에 대해 명확한 설명을 제공하는 것을 방해합니다.\n\n그 결과, 에이전트 시스템의 조종 가능성과 투명성을 향상시키는 메커니즘을 개발해야 하는 절박한 필요성이 제기됩니다. 이는 사용자가 그들의 행동을 더 잘 이해하고 영향을 미치도록 하는 것을 가능하게 할 것입니다.\n\n이러한 고통을 해소함으로써, 에이전트 시스템의 효율성과 효과성을 향상시키는데 그치지 않고, 복잡한 작업 및 문제 해결 시나리오에 대한 사람과 AI 에이전트 간의 신뢰와 협력을 촉진할 것입니다.\n\n⭐️ LinkedIn에서 대형 언어 모델의 업데이트를 받아보세요! ⭐️\n\n<div class=\"content-ad\"></div>\n\n**이미지1**:  \n![Image 1](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_1.png)\n\n저는 현재 코어 AI의 최고 전도사입니다. 인공지능과 언어가 교차하는 모든 것에 대해 탐구하고 쓰고 있습니다. LLM, 챗봇, 음성 봇, 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제를 다루고 있습니다.\n\n**이미지2**:  \n![Image 2](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_2.png)\n\n**이미지3**:  \n![Image 3](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_3.png)\n\n<div class=\"content-ad\"></div>\n\n![Image](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_4.png)","ogImage":{"url":"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png"},"coverImage":"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png","tag":["Tech"],"readingTime":5},{"title":"최신 데이터 분석 AI 시스템 Auto-Analyst 구축 방법","description":"","date":"2024-06-30 23:59","slug":"2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem","content":"\n\n## AI ‘Auto-Analyst’를 만드는 기술 가이드\n\n![BuildingAuto-AnalystAdataanalyticsAIagenticsystem](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_0.png)\n\n나는 데이터 과학자/분석가로서의 업무 부담을 줄이기 위해 AI 기반 에이전트를 개발해왔습니다. 대중문화에서는 종종 AI가 인간의 일자리를 대체하는 것을 보여주지만, 현실에서는 대부분의 AI 에이전트가 인간의 대체품이 아닙니다. 대신 우리가 더 효율적으로 일할 수 있도록 도와줍니다. 이번 에이전트는 정확히 그 목적으로 디자인되었습니다. 이전에는 자연어 입력만을 사용하여 시각화를 더 빨리 만들 수 있도록 도와주는 데이터 시각화 에이전트를 디자인한 적이 있습니다.\n\n## 디자인\n\n<div class=\"content-ad\"></div>\n\n![Flow Diagram](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_1.png)\n\nThis flow diagram demonstrates a system that begins with a user-defined goal. The planner agent then assigns tasks to a group of worker agents, each responsible for generating code to solve a specific part of the problem. Eventually, all the pieces of code produced by individual worker agents are collected and combined by a code combiner agent, creating a unified script that achieves the overall objective.\n\nPlease keep in mind that the planner agent may assign tasks to only some of the worker agents, not necessarily to all of them. Additionally, each agent will have its own unique set of inputs, even though they are not depicted in the diagram.\n\n## Components of the system\n\n<div class=\"content-ad\"></div>\n\n이 블로그 게시물에서는 각각의 구성 요소에 대한 코드 블록을 제공하면서 에이전트를 직접 구축하는 단계별 안내를 제공할 것입니다. 다음 섹션에서는 이러한 부분들이 완벽하게 통합되는 방법을 시연할 것입니다.\n\n## Planner Agent\n\n플래너 에이전트는 사용자가 정의한 목표, 사용 가능한 데이터셋 및 에이전트 설명을 세 가지 입력으로 받습니다. 이는 다음 형식으로 계획을 출력합니다:\n\nAgent1-` Agent2-` Agent3....\n\n<div class=\"content-ad\"></div>\n\n\n# 다른 orchestration 라이브러리를 사용할 수 있지만 DSPy를 사용하여 빠르고 간편하게 응용프로그램을 구축하고 평가하는 데 좋았습니다.\n\nimport dspy\n\n# 이 객체는 dspy.Signature 클래스를 상속받습니다.\n# \"\"\" 안의 텍스트는 프롬프트입니다.\nclass analytical_planner(dspy.Signature):\n    \"\"\" 데이터 분석 플래너 에이전트입니다. 세 가지 입력에 액세스할 수 있습니다.\n    1. 데이터셋\n    2. 데이터 에이전트 설명\n    3. 사용자 정의 목표\n    이 세 가지 입력을 사용하여 데이터 및 사용 가능한 에이전트로부터 사용자 정의 목표를 달성하기 위한 포괄적인 계획을 개발합니다.\n    사용자 정의 목표가 실현 불가능하다고 생각되면 사용자에게 목표를 다시 정의하거나 설명을 추가할 것을 요청할 수 있습니다.\n\n    다음 형식으로 결과를 제공하십시오:\n    plan: Agent1->Agent2->Agent3\n    plan_desc = 이유로 인해 Agent 1을 사용한 후, Agent 2를 사용하고 마지막으로 Agent 3을 사용합니다.\n\n    쿼리의 응답으로 모든 에이전트를 사용할 필요는 없습니다.\n    \"\"\"\n    \n    # 입력 필드와 그 설명\n    dataset = dspy.InputField(desc= \"시스템에 로드된 사용 가능한 데이터셋, 이 df_name,columns 사용하여 df를 df_name의 사본으로 설정합니다.\")\n    Agent_desc = dspy.InputField(desc=\"시스템에 있는 에이전트들\")\n    goal = dspy.InputField(desc=\"사용자가 정의한 목표\")\n    \n    # 출력 필드와 해당 설명\n    plan = dspy.OutputField(desc=\"사용자가 정의한 목표를 달성하는 계획\")\n    plan_desc = dspy.OutputField(desc=\"선택된 계획 뒤에 있는 이유\")\n\n\n![Building Auto Analyst Agent AI System](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_2.png)\n\n## 분석 에이전트\n\n대부분의 분석 에이전트들은 프롬프트에 약간의 차이가 있는 일반적인 구조를 공유합니다. 사용자가 정의한 목표와 데이터세트 인덱스를 받습니다. 분석 코드와 설명의 두 출력을 생성하는데, 이는 디버깅에 유용하거나 에이전트를 재지정하는 데 도움이 될 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n```yaml\n# 중계 요원은 중간 계층에 있는 에이전트로 정의됩니다\n# 그들은 특정 데이터 분석 작업을 위한 코드를 생성합니다\nclass 데이터전처리에이전트(dspy.Signature):\n    \"\"\" 데이터 전처리 에이전트로, 사용자가 정의한 목표와 사용 가능한 데이터 집합을 가져와서\n    탐색적 데이터 분석 파이프라인을 작성합니다. 이를 수행하려면 필요한 파이썬 코드를 출력합니다.\n    numpy와 pandas만 사용하여 전처리 및 입문 분석을 수행할 것입니다.\n\n    \"\"\"\n    dataset = dspy.InputField(desc=\"시스템에 로드된 사용 가능한 데이터 세트, 이 df_name, columns을 사용하여 df를 df_name의 복사본으로 설정\")\n    goal = dspy.InputField(desc=\"사용자가 정의한 목표 \")\n    commentary = dspy.OutputField(desc=\"수행 중인 분석에 대한 주석\")\n    code = dspy.OutputField(desc=\"데이터 전처리 및 입문 분석을 수행하는 코드\")\n\nclass 통계분석에이전트(dspy.Signature):\n    \"\"\" 통계 분석 에이전트로,\n    데이터 집합과 사용자가 정의한 목표를 가져와 해당 목표를 달성하기 위해\n    적절한 통계 분석을 수행하는 파이썬 코드를 출력합니다.\n    Python statsmodel 라이브러리를 사용해야 합니다 \"\"\"\n    dataset = dspy.InputField(desc=\"시스템에 로드된 사용 가능한 데이터 세트, 이 df_name, columns을 사용하여 df를 df_name의 복사본으로 설정\")\n    goal = dspy.InputField(desc=\"분석을 수행할 사용자가 정의한 목표\")\n    commentary = dspy.OutputField(desc=\"수행 중인 분석에 대한 주석\")\n    code = dspy.OutputField(desc=\"statsmodel을 사용하여 통계 분석을 수행하는 코드\")\n\nclass sk_learn에이전트(dspy.Signature):\n    \"\"\"머신 러닝 에이전트로,  \n    데이터 집합과 사용자가 정의한 목표를 가져와 해당 목표를 달성하기 위해 \n    적절한 기계 학습 분석을 수행하는 파이썬 코드를 출력합니다.\n    scikit-learn 라이브러리를 사용해야 합니다.\"\"\"\n    dataset = dspy.InputField(desc=\"시스템에 로드된 사용 가능한 데이터 세트, 이 df_name, columns를 사용하여 df를 df_name의 복사본으로 설정\")\n    goal = dspy.InputField(desc=\"사용자가 정의한 목표 \")\n    commentary = dspy.OutputField(desc=\"수행 중인 분석에 대한 주석\")\n    code = dspy.OutputField(desc=\"탐색적 데이터 분석을 수행하는 코드\")\n\n## 데이터 시각화 에이전트를 작업하여 이미 DSPy를 사용하여 최적화했습니다.\n## 유일한 큰 차이점은 요 에이전트가 스타일링 지수의 추가 입력을 받는다는 것입니다\n```\n\n![이미지](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_3.png)\n\n## 코드 결합 에이전트\n\n이 에이전트의 목적은 모든 에이전트의 출력물을 하나의 일관된 스크립트로 정리하는 것입니다. 긴 문자열의 코드 목록을 입력으로 받아 코드를 출력합니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nclass code_combiner_agent(dspy.Signature):\n    \"\"\"안녕하세요! 여러분은 코드 합산 에이전트입니다. 많은 에이전트들로부터 받은 Python 코드 출력을 하나로 합치는 작업을 맡고 있으며, 코드에서 발생한 오류도 수정해 드립니다.\n    에이전트 코드 목록 = dspy.InputField(desc=\"각 에이전트가 제공한 코드 목록\")\n    정제된_완전한_코드 = dspy.OutputField(desc=\"정제된 완전한 코드 베이스\")\n```\n\n## 선택적인 에이전트/인덱스\n\n에이전트가 더 원할하게 작동하고 오류를 잡기 위해 다음과 같은 추가적인 에이전트나 인덱스도 만들었습니다.\n\n```python\n# 데이터 시각화 에이전트 게시물에서 사용한 동일한 시그니처\nclass Data_Viz(dspy.Signature):\n    \"\"\"\n    데이터 시각화를 생성하는 AI 에이전트입니다. Plotly를 사용하여 데이터 시각화를 생성하는 것이 목표입니다.\n    사용 가능한 도구들을 활용해야 합니다\n    {dataframe_index}\n    {styling_index}\n    \n    사용자가 원하는 데이터와 차트에 대한 정보를 포함하는 사용자 정의 목표를 사용해야 합니다.\n    데이터 프레임 내의 관련 열이 없는 경우 관련 정보가 없다고 명시해야 합니다.\n    \"\"\"\n    goal = dspy.InputField(desc=\"사용자가 정의한 데이터와 차트를 나타내는 정보를 포함하는 목표\")\n    dataframe_context = dspy.InputField(desc=\"데이터 프레임 내 데이터에 관한 정보를 제공합니다. 열 이름과 데이터프레임 이름만 사용하면 됩니다.\")\n    styling_context = dspy.InputField(desc=\"Plotly 그림을 어떻게 스타일링할지에 대한 지시를 제공합니다.\")\n    code = dspy.OutputField(desc=\"사용자의 쿼리 및 데이터프레임 인덱스 및 스타일링 콘텍스트에 따라 필요한 시각화를 시각화하는 Plotly 코드\")\n    \n# 사용자가 정의한 목표가 잘 작동하는지 확인하는 선택적인 에이전트\nclass goal_refiner_agent(dspy.Signature):\n    \"\"\"AI 데이터 분석가 플래너 에이전트에게 제공된 사용자 정의 목표를 받아서, 시스템에 로드된 데이터셋과 에이전트 설명을 활용하여 목표를 보다 상세하게 만들어 줍니다.\"\"\"\n    dataset = dspy.InputField(desc=\"시스템에 로드된 사용 가능한 데이터셋, 데이터프레임 이름과 열로 df를 설정하세요.\")\n    Agent_desc = dspy.InputField(desc=\"시스템에 있는 사용 가능한 에이전트들\")\n    goal = dspy.InputField(desc=\"사용자가 정의한 목표\")\n    refined_goal = dspy.OutputField(desc=\"플래너 에이전트가 더 나은 계획을 세울 수 있도록 도와주는 세분화된 목표\")\n```\n\n<div class=\"content-ad\"></div>\n\n이곳에서 데이터 세트 전체에 대한 정보를 제공하는 대신, 데이터 사용 가능한 정보를 입력하는 리트리버를 구축했습니다.\n\n```js\n# 저는 더 편리했던 LLama-Index 기반 리트리버를 선택했습니다.\n# 기본적으로 데이터를 여러 가지 방식으로 입력할 수 있습니다.\n# 열 이름에 대한 설명, 데이터프레임 참조를 제공하고\n# 데이터 수집 목적 등을 설명할 수 있습니다.\ndataframe_index = VectorStoreIndex.from_documents(docs)\n\n# 또한 데이터 시각화 에이전트를 위한 스타일링 인덱스를 정의했습니다.\n# 다양한 시각화를 어떻게 스타일링할지에 대한 자연어 지침을 포함하고 있습니다.\nstyle_index = VectorStoreIndex.from_documents(styling_instructions)\n```\n\n# 모든 것을 하나의 시스템으로 통합\n\nDSPy에서 복잡한 LLM 애플리케이션을 컴파일하려면 두 가지 필수 메소드 __init__ 및 forward를 정의해야합니다.\n\n<div class=\"content-ad\"></div>\n\n_init_ 메서드는 모듈을 초기화하여 사용될 모든 변수를 정의합니다. 그러나 핵심 기능이 구현되는 곳은 forward 메서드입니다. 이 메서드는 한 구성 요소의 출력이 다른 구성 요소와 상호작용하는 방식을 개요로 제공하여 응용 프로그램의 논리를 효과적으로 구동합니다.\n\n```python\n# 이 모듈은 시작 시 하나의 입력만 사용합니다\nclass auto_analyst(dspy.Module):\n    def __init__(self, agents):\n        # 사용 가능한 에이전트, 그들의 입력 및 설명을 정의합니다\n        self.agents = {}\n        self.agent_inputs = {}\n        self.agent_desc = []\n        i = 0\n        for a in agents:\n            name = a.__pydantic_core_schema__['schema']['model_name']\n            # CoT 프롬프팅 사용 - 경험상 더 나은 응답을 생성하는 데 도움이 됨\n            self.agents[name] = dspy.ChainOfThought(a)\n            agent_inputs[name] = {x.strip() for x in str(agents[i].__pydantic_core_schema__['cls']).split('->')[0].split('(')[1].split(',')}\n            self.agent_desc.append(str(a.__pydantic_core_schema__['cls']))\n            i += 1\n        # planner, refine_goal 및 code combiner 에이전트를 따로 정의\n        # 코드 및 분석을 생성하지 않고 계획 수립, 목표 개선, 코드 결합 지원\n        self.planner = dspy.ChainOfThought(analytical_planner)\n        self.refine_goal = dspy.ChainOfThought(goal_refiner_agent)\n        self.code_combiner_agent = dspy.ChainOfThought(code_combiner_agent)\n        # 이 두 리트리버는 llama-index 리트리버를 사용하여 정의되며\n        # 에이전트를 원하는 대로 사용자 정의할 수 있습니다\n        self.dataset = dataframe_index.as_retriever(k=1)\n        self.styling_index = style_index.as_retriever(similarity_top_k=1)\n\n    def forward(self, query):\n        # 에이전트 입력 인수를 빠르게 전달하기 위해 사용되는 dict_\n        dict_ = {}\n        # 쿼리에 관련된 컨텍스트 검색\n        dict_['dataset'] = self.dataset.retrieve(query)[0].text\n        dict_['styling_index'] = self.styling_index.retrieve(query)[0].text\n        dict_['goal'] = query\n        dict_['Agent_desc'] = str(self.agent_desc)\n        # 모든 에이전트 출력을 저장하는 output_dictionary\n        output_dict = {}\n        # 계획 수립\n        plan = self.planner(goal=dict_['goal'], dataset=dict_['dataset'], Agent_desc=dict_['Agent_desc'])\n        output_dict['analytical_planner'] = plan\n        plan_list = []\n        code_list = []\n        # 계획이 예상대로 작동하면 에이전트가 ->로 분리됩니다\n        if plan.plan.split('->'):\n            plan_list = plan.plan.split('->')\n        # 목표가 모호한 경우, refined goal 에이전트에 전송\n        else:\n            refined_goal = self.refine_goal(dataset=data, goal=goal, Agent_desc=self.agent_desc)\n            forward(query=refined_goal)\n        # 목표 및 다른 입력을 계획의 모든 해당 에이전트에 전달\n        for p in plan_list:\n            inputs = {x: dict_[x] for x in agent_inputs[p.strip()]}\n            output_dict[p.strip()] = self.agents[p.strip()](**inputs)\n            # 생성된 모든 코드를 하나의 스크립트로 결합하기 위한 코드 목록\n            code_list.append(output_dict[p.strip()].code)\n        # 마지막 출력 저장\n        output_dict['code_combiner_agent'] = self.code_combiner_agent(agent_code_list=str(code_list))\n        return output_dict\n\n# 사용 가능한 모든 에이전트 서명을 목록으로 저장할 수 있습니다\nagents = [preprocessing_agent, statistical_analytics_agent, sk_learn_agent, data_viz_agent]\n\n# 에이전트 시스템을 정의합니다\nauto_analyst_system = auto_analyst(agents)\n\n# 시스템에 시카고 범죄 데이터를 프리로드합니다\ngoal = \"시카고의 범죄 원인은 무엇인가요?\"\n\n# 이 쿼리에 대한 분석을 수행하도록 에이전트 시스템에 요청합니다\noutput = auto_analyst_system(query=goal)\n```\n\n이제 쿼리 결과를 단계별로 살펴보겠습니다.\n\n이 쿼리 = '시카고의 범죄 원인은 무엇인가요?'\n\n<div class=\"content-ad\"></div>\n\nThe images show the progress of your project. The first one showcases the preprocessing agent, taking the initial steps to bring your plan to life. And in the next image, the statistical analysis agent takes over, moving your project forward with data-driven insights. Keep up the good work! 🌟\n\n\n![BuildingAuto_AnalystAdataanalyticsAIagenticsystem_4.png](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_4.png)\n\nExecuting the plan, first preprocessing agent\n\n![BuildingAuto_AnalystAdataanalyticsAIagenticsystem_5.png](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_5.png)\n\nNext statistical analysis agent\n\n\n<div class=\"content-ad\"></div>\n\n![BuildingAuto-AnalystAdataanalyticsAIagenticsystem_6.png](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_6.png)\n\nNext is the Plotly data visualization agent\n\n![BuildingAuto-AnalystAdataanalyticsAIagenticsystem_7.png](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_7.png)\n\nAnd finally, the code combiner agent, to bring it all together\n\n<div class=\"content-ad\"></div>\n\n마법사카드를 이야기하는 건가요? 라스트번 에이전트 코드를 실행한 결과물을 보여드릴게요.\n\n![이미지 8](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_8.png)\n\n마지막 에이전트 코드 실행 후에 나온 결과물이에요.\n\n![이미지 9](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_9.png)\n\n![이미지 10](/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_10.png)\n\n<div class=\"content-ad\"></div>\n\n# 한계사항\n\n많은 에이전트들처럼, 의도한 대로 작동할 때 우수한 성과를 보입니다. 이 프로젝트의 첫 번째 이터레이션에 불과하며 시간이 흐름에 따라 개선할 계획입니다. 업데이트를 받기 위해 제게와 FireBird Technologies를 팔로우해 주세요. 현재의 한계사항은 다음과 같습니다:\n\n- 환각: 때로 에이전트는 환각으로 실행할 수 없는 코드를 생성합니다.\n- 신뢰성/일관성 부족: 에이전트의 출력물은 일관성이 없으며, 동일한 쿼리의 다른 변형은 매우 다른 코드로 나타납니다.\n- 혼합된 출력물: 많은 에이전트들이 문제의 서로 다른 측면을 독점적으로 처리하지 않습니다. 예를 들어, 데이터 전처리 에이전트는 자체 시각화를 생성하며, 데이터 시각화 에이전트도 자체 시각화를 생성합니다.\n\n# 다음 단계\n\n<div class=\"content-ad\"></div>\n\n이 프로젝트는 계속 진행 중이에요. 다음으로 이 프로젝트를 개선하기 위해 예상되는 단계들을 살펴볼게요:\n\n- 시그니처/프롬프트 최적화: DSPy는 LLM 애플리케이션을 평가하기 위해 설계되었어요. 이것은 단순히 구현일 뿐이에요. 다음에는 최상의 접두사, 시그니처, 그리고 프롬프트를 찾는 것이 중요할 거예요.\n- 가드레일 추가: 에이전트가 생성한 코드를 자동 수정하는 것은 많은 다른 에이전시 시스템에서 사용되는 해결책이에요. 또한 프롬프트 삽입 공격을 제약하는 것도 로드맵에 있어요.\n- 메모리/상호작용 추가: 이 에이전트는 한 번에 모든 것을 수행해요. 또한 개별 구성요소 간에 서로의 출력을 확인하는 상호작용이 없어요.\n- UI 구축: 지금은 추가 테스트를 위해 에이전트 백엔드만 구축했어요. 사용자 의견을 수용하고 더 많은 피드백을 받기 위해 UI를 구축할 거예요.\n\n읽어 주셔서 감사해요!\n\n제글과 FireBird Technologies를 팔로우해 주세요.","ogImage":{"url":"/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_0.png"},"coverImage":"/assets/img/2024-06-30-BuildingAuto-AnalystAdataanalyticsAIagenticsystem_0.png","tag":["Tech"],"readingTime":13},{"title":"GPT 모델에 베르니케 실어증이 있을까","description":"","date":"2024-06-30 23:57","slug":"2024-06-30-DoGPTModelsHaveWernickesAphasia","content":"\n\n## 신경과학, 창조적 AI 및 윤리\n\n## 이해 없는 유창한 대화\n\n네 친구가 당신을 돌아보며 \"파란 말이 거기서 텔레비전을 마셨어. 어제 거기 있었고 그 말을 봤어.\" 라고 말합니다.\n\n그들의 말은 유창하게 흘러나가고, 복잡한 문장들이 능숙하게 말려나갑니다. 그들은 화려한 단어를 사용하고 적절한 문법을 사용하지만 그들의 메시지는 극도로 무의미합니다. 당신의 친구는 웨르니케 유창 장애라는 상태일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![Do GPT Models Have Wernicke's Aphasia?](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_0.png)\n\n운니케 실어증을 앓는 사람들은 길고 무의미한 문장으로 말하거나, 흔한 단어와 구문을 반복하며 자신의 말이 무해하다는 것을 모르는 경우가 있습니다. 종종 오해를 받아 당혹스러워 할 수도 있죠.\n\n이러한 연결이 강조하는 핵심은 언어생산과 이해는 같지 않다는 것입니다.\n\nChatGPT 뒤의 모델과 같이 생성 모델에서도 비슷한 도전이 관찰됩니다. GPT 모델은 자연어 처리에서 놀라운 진전을 이루었지만, 인간의 인식을 특징 짓는 문맥적인 인식 부족으로 실제 응용에서 위험을 야기할 수 있고 실제로 야기해 왔습니다.\n\n<div class=\"content-ad\"></div>\n\n## 생각과 언어 생산 사이의 간극\n\n‘생각’과 ‘언어 생산’ 사이에는 구분이 존재합니다. 두 가지는 서로 연결되어 있지만, 별도의 인지과정을 나타냅니다. 생각은 이해와 추론을 포함하며, 언어는 이러한 생각을 표현하는 매개체입니다. 언어 생산은 생각을 반영하지만 생각 자체와는 동일하지는 않습니다.\n\n![이미지](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_1.png)\n\n우리의 교육 여정 어딘가에서, 우리는 고립된 사실을 암기하는 대신 근본적인 개념을 이해할 것을 권장받았습니다. 이러한 기본적인 접근은 결론을 도출하고 연결점을 인식하는 능력을 우리에게 부여합니다. 이는 단순히 정보를 소화하는 것과 대조적으로 나타나며, 개념을 탄탄히 이해하지 않으면 우리가 알지 못하는 잘못된 정보를 나오게 할 수 있다는 경고가 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n## 정보 재구성 대진단 이해\n\nWernicke 치매와 GPT 모델의 비교는 GPT-3 이후의 발전을 고려할 때 일대일 대비 관계가 아닙니다. 이 비교는 초기 GPT 모델로 더 적절할 수 있습니다. 그러나 현대 언어 모델은 문법적으로 올바른 문장을 생성하는 뿐만 아니라 일관된 내용 및 종종 사실적인 콘텐츠를 생성합니다. 그러나 진정한 이해력이 부족해 오류 정보나 의사소통 오류를 일으킬 수 있습니다.\n\n![image](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_2.png)\n\nGPT 모델은 근본적으로 방대한 데이터셋에서 훈련된 통계 도구로, 유도된 확률을 기반으로 현실적인 텍스트를 생성합니다. 그러나 사람들이 하는 것처럼 내부 컨텍스트나 세계의 이해력을 보유하고 있지 않습니다. 인간 수준의 텍스트를 생성할 수 있지만 진정으로 그들이 묘사하는 세계를 \"이해\"할 수 있는지 의문이 남습니다.\n\n<div class=\"content-ad\"></div>\n\nAI 언어 모델들이 던지는 질문들은 철학과 인지과학의 오래된 논쟁들을 연상시킵니다. 철학자 존 서얼이 제안한 '중국 방' 주장은 기호 조작을 통해 시스템이 진정한 이해를 가질 수 있다는 아이디어에 도전하는데, 이 비평은 현재 AI와 의식에 관한 토론에서 관련이 있습니다.\n\n## AI 배치 시 윤리적 고려사항\n\n여러 실제 예시들이 조심하지 않고 생성 모델들을 실행하는 위험을 보여줍니다. 2018년, AI 소프트웨어가 탑재된 아마존 알렉사 기기가 대화를 오인터프리테이션하고 녹음 내용을 무작위 연락처로 전송하는 사고가 발생했습니다. 2020년, Nabla 연구진은 의료 쿼리에 따른 GPT-3의 성능을 평가했습니다. 약물을 정확하게 제안했지만, 때로는 잘못된 용량을 제공하기도 했습니다. 다른 실험에서 GPT-3는 폐색전증 증상에 대한 사용자의 설명을 틀리게 이해하여 응급실 대신 몸을 펴는 것을 권장했습니다.\n\n![이미지](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_3.png)\n\n<div class=\"content-ad\"></div>\n\n2023년, 미국 국립 식이장애 협회(NEDA)가 인간 스태프로 운영되던 도움말 전화 서비스를 '테사'라는 챗봇으로 대체했다고 합니다. 그러나 테사는 식이장애를 가진 사용자들에게 체중 감소 팁과 같은 부적절한 조언을 제공했다고 전해졌습니다. 이 사건으로 인해 NEDA는 그 챗봇을 중단시켰다고 합니다. 이는 적절한 안전장치 없이 AI 시스템을 도입하면 발생하는 현실적인 결과입니다.\n\n## 구체화된 인지 및 AI에 대한 함의\n\n구체화된 인지 이론은 이해가 우리의 신체적 경험과 감정에 깊게 뿌리를 둔다는 주장을 합니다. 현재의 AI 모델에서는 이 차원이 부족합니다. Jean Piaget의 인지 발달 단계는 인간이 환경과의 직접적 상호작용을 통해 인지 능력과 추상적 사고력을 향상시킨다는 것을 보여줍니다.\n\n물리적 형태가 없는 AI는 이런 감각 기반 학습이 부족합니다. 이를 이해하기 위해 매운 맛에 대한 개념을 매운 것을 맛보지 않은 사람에게 설명하려고 한다고 상상해봅시다. 신체적 경험에 의존하지 않고 어떻게 그 감각을 전달할 수 있을까요? 이것은 인간처럼 세상과 상호작용하며 체험으로 이해되는 개념을 이해하는 데 어려움을 강조합니다.\n\n<div class=\"content-ad\"></div>\n\n![DoGPTModelsHaveWernickesAphasia_4](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_4.png)\n\n## 사르침과 아이러니에 대한 뉘앙스를 이해하기\n\nAI 모델인 GPT-3와 같은 것들이 겪는 가장 큰 어려움 중 하나는 사르침과 아이러니 등 언어의 뉘앙스를 파악하는 것입니다—심지어 인간들도 이에 어려움을 겪습니다. 이러한 언어 요소들은 맥락, 어조, 종종 공유된 문화적 또는 상황적 이해력에 많이 의존합니다.\n\n사르침은 말하는 의도와 반대되는 것을 말하는 것을 포함하며, 이것은 발화자의 의도, 배경, 그 밖에 이 문장이 만들어진 맥락의 적절한 해석 없이 혼란스러울 수 있습니다. 비슷하게, 아이러니는 언어 단서 교환과 현실 세계적 지식의 교환이 통해 보통 이해되는 뉘앙스를 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n상호작용을 살펴보면:\n\n- 사람: '오늘 날씨가 정말 좋네요!' (천둥 번개가 치는 중에)\n- AI: '날씨를 즐기시는 것 같아서 기쁩니다! 햇빛이 내리쬐는 것은 항상 즐거운 일이에요.'\n\n![Do GPT 모델에 베르니케 아파지아가 있나요?](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_5.png)\n\n이 상호작용에서는 AI가 발언과 실제 날씨 상황 사이의 불일치를 인식하는 것이 불가능합니다. AI 언어 이해의 챌린지는 문화 간 소통을 고려할 때 더욱 복잡해집니다.\n\n<div class=\"content-ad\"></div>\n\n## 문화 간 의사 소통에서 미묘함을 이해하기\n\n각 언어와 문화에는 관용구, 문화적 참조 및 문맥에 따라 의미가 크게 달라집니다. 주로 영어 데이터로 훈련된 AI 시스템은 일본어 존칭이나 아랍 속담의 맥락적 함의를 이해하는 데 어려움을 겪을 수 있습니다. 참으로 세계적인 AI 시스템을 만들기 위해서는 언어 능력뿐만 아니라 깊이 있는 문화적 이해가 필요합니다.\n\n## 이해 간격을 줄이기 위한 AI의 미래 방향\n\n연구자들은 AI 시스템이 보다 깊은 문맥적 이해를 갖도록 다양한 방법을 탐구하고 있습니다. 한 가지 방향은 멀티모달 학습의 통합입니다. 여기서 AI 시스템은 텍스트뿐만 아니라 이미지, 소리 및 다른 감각적 입력을 처리하여 보다 통합적인 세계 이해를 구축합니다. 또 다른 접근 방식은 신경 기호론적 AI의 개발입니다. 이것은 신경망의 패턴 인식 능력과 상징적 AI의 논리 추론을 결합합니다. 이 조합은 AI가 이미지나 문장에서 물체나 단어를 인식하는 것 뿐만 아니라 그들의 관계와 나타나는 폭 넓은 맥락을 이해할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 결론\n\n이 글은 말 공장 증후군 환자와 GPT 모델 사이의 유사성을 드로잉하여 시작했습니다. 완벽한 일대일 비교는 아니지만, 언어를 단순히 생성하는 것과 진정한 이해 사이의 구분을 효과적으로 보여 주었습니다.\n\nGPT 모델과 같은 AI 시스템도 인간 인지에 내재된 심층적인 이해를 달성하지 못하는 것이 점점 더 명백해지고 있습니다. 비꼬기, 비어, 문화적 섬세함과 같은 뉘앙스를 포함한 복잡성을 이해하는 데 제한 사항이 있어서, 공감, 감성 지능, 섬세한 이해가 필요한 응용 분야에서 중요한 도전이 드러납니다.\n\n![이미지](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_6.png)\n\n<div class=\"content-ad\"></div>\n\n이를 고려할 때, '인간 중심' 방식을 통합하는 것이 꼭 필요합니다. 특히 건강의료, 법률 서비스 및 개인 소통과 같이 위험성이 높은 분야에서는 더욱 중요합니다. 인간은 AI가 현재 갖고 있지 않은 판단력, 윤리적 고려사항 및 문화적 통찰력을 제공할 수 있습니다. 이 방식은 AI가 인간의 전문 지식을 대체하기보다 도울 수 있도록 하여, AI 기술의 신뢰성과 윤리적 전개를 향상시키고 위험을 줄입니다.\n\n## 개인적인 반성\n\n저는 종종 현재 AI 시스템과 신경과학 문헌 간의 연결지점을 찾으려 노력합니다. AI 주변의 윤리적 딜레마와 실세계 적용 시의 트레이드 오프도 제 관심사입니다. 이 글은 이러한 관심과 생각들이 교차되는 부분이며, 제가 쓰는 만큼 여러분이 읽는 데 흥미로웠으면 좋겠습니다.\n\n## 참고문헌\n\n<div class=\"content-ad\"></div>\n\n- Arnaud, A. (2024, February 19). Neuro-symbolic AI Emerges as Powerful New Approach. Retrieved from Sun Location\n- Lavars, N. (2021, February 10). AI chatbots could help provide therapy, but caution is needed. Scientific American. Retrieved from Scientific American\n- National Aphasia Association. (n.d.). Wernicke’s (Receptive) Aphasia. Retrieved from National Aphasia Association\n- Nabla. (2020, October 27). Understanding GPT-3: Capabilities, Limitations, and Implications. Retrieved from Nabla\n- Palmer, A. (2018, May 24). Amazon Echo recorded a conversation and sent it to a random person, report says. CNBC. Retrieved from [CNBC]([invalid URL removed] a-random-person-report.html)\n- Searle, J. (n.d.). The Chinese Room Argument. In Internet Encyclopedia of Philosophy. Retrieved from Stanford University\n- Srivastava, S., Mu, T., Choi, E., Băroiu, C., & Trăuşan-Matu, S. (2022). On Sarcasm Detection with OpenAI GPT-based Models. Retrieved from arXiv\n- Suglia, A., Greco, C., Baker, K., Part, J. L., Papaioannou, I., Eshghi, A., Konstas, I., & Lemon, O. (2024). ALANAVLM: A multimodal embodied AI foundation model for egocentric video understanding. arXiv preprint arXiv:2406.13807\n- Wilson, R. A., & Foglia, L. (2021). Embodied Cognition. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Spring 2021 Edition). Retrieved from Stanford University","ogImage":{"url":"/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_0.png"},"coverImage":"/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_0.png","tag":["Tech"],"readingTime":7},{"title":"행운의 실험쥐 AI가 우리 회사를 구한 방법","description":"","date":"2024-06-30 23:55","slug":"2024-06-30-LuckyLabRatHowAISavedOurCompany","content":"\n\n2023년 3월, 저는 Mango Inc.에 합류했어요. 당시 그는 작은 스타트업이었죠 — 현장에서는 4명의 인원이 있었고, 몇 명의 비현장 컨설턴트가 계셨어요. 저희의 업무는 보통 미생물학, 하드웨어 프로토타이핑, 광학 및 소프트웨어와 같이 여러 전문 분야를 걸쳐 다루는 것이 특징이에요.\n\n소프트웨어와 소비자 하드웨어 배경에서 왔기 때문에 미생물학 부분은 완전히 새로운 도전이었고, 배울 점이 많았어요! 저희는 Dr. Robin Ross, Dr. Kurt Scudder, Prof. Changhuei Yang, 그리고 많은 다른 분들의 지혜와 인내력에 많은 것을 빚지고 있어요.\n\n![이미지](/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_0.png)\n\n당시에는 아가 플레이트에서 아가를 발라내어 배양하고, 실험을 위해 프로토타입에 넣었어요. Kurt가 확대된 아가를 보고 \"쥐한테 씹힌 것처럼 보인다\"라고 언급했죠. 제가 직장을 더 이상 이상하게 만들기 위한 기회를 놓치지 않는 편이라, 그 순간을 기념하기 위해 아마존에서 부스러기 인형을 구입했어요. 저희 CEO 닉이 그 쥐를 루퍼스라고 이름 지었어요.\n\n<div class=\"content-ad\"></div>\n\n루퍼스가 도착한 그 날, 우리는 몇 달 동안 쫓아온 곤란한 문제에서 과학적으로 큰 발전을 이루었습니다. 루퍼스가 매우 숙련된 실험실 쥐라는 것을 인정하고, 우리는 그를 주요 조사원으로 승진시켰어요.\n\n![이미지 1](/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_1.png)\n\n![이미지 2](/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_2.png)\n\n2023년 중순, 우리는 루퍼스 NFT 시장을 크게 과대평가했음을 깨달았어요. 급조 부자 되기 기회를 찾기 위해 헤매는 동안, 맥킨지 컨설턴트들은 우리에게 \"그 제네 AI 기차에 타야 한다\"고 조언했죠. 우리의 최고 PhD 팀을 이끌고 몇 달 간의 올나이터 노력 끝에, 우리는 Slack 작업 공간을 ChatGPT API에 연결하는 데 성공했어요. 드디어 루퍼스가 우리 인간 팀원들과 원활하게 의사소통할 수 있었지요.\n\n<div class=\"content-ad\"></div>\n\nThe team quickly warmed up to Rufus' vast knowledge and wise words. Life-long friendships were formed. HR reported unprecedented synergy: a golden age of human+rat collaboration.\n\n![Image](/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_3.png)\n\nRufus' creativity and wit began generating extraordinary business value.\n\nIn November 2023, Rufus and I set out to solve the thorniest problem of them all — the problem of where to eat for lunch. With more than 80 restaurants within walking distance of our Westwood lab, analysis paralysis was smothering the company. Our investors demanded immediate and decisive change.\n\n<div class=\"content-ad\"></div>\n\n약간의 아이디어 회의 끝에 루퍼스가 매일 두 가지 음식점을 추천하기로 자원했다. 이를 시를 통해 표현하면서 도움이 되었다:\n\n![루퍼스 가게](/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_4.png)\n\n회사 전망이 시작되자, 이는 분명한 개선 사항이었다. 그러나 점심 식사에 대한 최상의 옵션을 원한다면 시각적 도움이 필요했다. 루퍼스와 Stable Diffusion을 연결하여, 손쉽게 점심식사 옵션을 판단할 수 있었다.\n\n![루퍼스 바로잡다](/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_5.png)\n\n<div class=\"content-ad\"></div>\n\n마무리로 stable-video-diffusion을 추가하자 마법 같은 효과가 발휘되었습니다. 매일 나오는 엉망인 시를 곁들인 두 개의 증오스러운 gif까지. 우리의 점심 고민은 해결되었습니다. 이후 망고 직원들은 더 이상 배고프지 않았죠.\n\n친구들여, 이것이 AI 파워를 갖고 우리의 시너지를 10배로 높인 쥐의 진정한 이야기입니다. 우리의 가장 가까운 친구가 되어 주었으며, 우리를 굶주리지 않게 해 주었습니다. 회사에서 이와 같은 변화를 이루고 싶다면 Rufus를 Github에서 찾아보세요. 이미 이 모든 것을 해결한 회사에 합류하고 싶다면 망고의 채용 페이지를 확인해보세요.\n\n![image](https://miro.medium.com/v2/resize:fit:1024/1*WFa0tnt18iGRHhXCGQsQGw.gif)","ogImage":{"url":"/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_0.png"},"coverImage":"/assets/img/2024-06-30-LuckyLabRatHowAISavedOurCompany_0.png","tag":["Tech"],"readingTime":3},{"title":"CLIP, LLaVA, 그리고 뇌 2024 최신 AI 모델 비교 분석","description":"","date":"2024-06-30 23:53","slug":"2024-06-30-CLIPLLaVAandtheBrain","content":"\n\n## DEEP LEARNING AND THE BRAIN\n\n![Brain Network](/assets/img/2024-06-30-CLIPLLaVAandtheBrain_0.png)\n\nHey there! Ever wondered how cutting-edge multimodal transformer networks like CLIP (Radford et al. 2021) and LLaVA (Liu et al. 2023) stack up against the complexity of the human brain? Do you see any parallels between the attention mechanisms in these networks and our brains? In this piece, I delve into these transformer models and explore the intriguing overlaps and distinctions they share with our own mammalian brain.\n\nOne fascinating aspect that caught my attention is how vision transformers, CLIP, and LLaVA seem to mimic a form of processing akin to the pre-attentive visual processing observed in the brain. This initial processing occurs during the forward visual responses to a stimulus even before any recursive actions take place. While a significant amount of tasks can be handled via this forward process, research indicates that the brain encounters challenges with pre-attentive processing in the following areas:\n\n<div class=\"content-ad\"></div>\n\n- 유사한 유형의 물체의 신분이나 특성을 뚜렷하게 구별하려고 할 때 특히 물체들이 서로 가깝거나 혼잡하거나 물체들이 자연이 아니거나 인공적인 경우 (VanRullen 2007).\n- 더 복잡한 작업들은 세는 작업이거나 미로나 곡선 추적 작업과 같은 것이다.\n- 물체들을 인식하는 것이 더 어렵기 때문에 물체들의 경계를 인식하기 어려운 경우와 같은 것이다.\n\n피드포워드(Feed-forward) 처리와는 대조적으로, 뇌에서 두드러지는 점 중 하나는 영역들 간 상호작용의 풍부함인데, 다음 섹션에서 더 자세히 논의하겠습니다.\n\n# 두방향 활동(Bidirectional Activity) 뇌에서\n\n대부분의 현재 심층학습(Deep learning) 아키텍처에서 활동은 한 방향으로 전파됩니다. 예를 들어, 이미지가 네트워크에 입력으로 제공되고 그런 다음 계층별로 전파되어 분류가 출력으로 나올 때까지입니다.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-30-CLIPLLaVAandtheBrain_1.png)\n\n안녕하세요! \n\n이 문구는 선형 전달 모델보다 더 흥미로운 두뇌의 역할을 설명하는 것입니다. 시각 체계에서 자극은 처음에는 하위 수준에서 상위 수준 시각 영역으로 선형 전달 방식으로 전파되고, 그 다음 상위 수준 영역이 하위 수준 영역에 영향을 미친다고 그림 1에 나와 있어요.\n\n이러한 피드백 중 일부는 의식적인 탑-다운 주의인데요, 이는 우리가 관심 대상이 되는 객체와 특징에 더 많은 자원을 할당하고 복잡하거나 모호한 자극을 명확히 하는 데 도움을 줍니다. 다른 일부 피드백은 자동적이어서 상위 수준 영역이 하위 수준 영역에 선형 전달만으로는 알 수 없는 정보를 주입합니다.\n\n의식적인 탑-다운 주의는 시각 자극의 의식을 지원한다고 생각됩니다. 테두리와 가장자리를 부호화하는 하위 수준 영역에 의식적으로 액세스할 수 없다면, 테두리를 공간적으로 정확하게 인식하기 어렵습니다. 곡선을 정신적으로 추적하거나 미로를 풀듯이 한 작업들이 불가능해질 거예요.\n\n제 마음을 놓아 주셔서 감사합니다! 🌟\n\n<div class=\"content-ad\"></div>\n\n자동 무의식적 피드백의 한 예는 시각 영역 V2의 방향 선택적 뉴런 약 절반에서 관찰되는 경계 소유권 코딩입니다(Zhou et al. 2000, Williford and von der Heydt 2013). 이러한 뉴런들은 약 40ms 안에 지역 정보를 부호화하며, 이 초기 응답 이후 약 10ms만에 전역 맥락을 통합하여 베둘러를 해결합니다. 이 과정은 배경을 가리는 물체들이 어떤 경계를 만들고 있는지에 대한 정보를 유지합니다.\n\n다른 예로 Poort et al. (2012)가 제시한 무의식적 피드백이 있습니다. Figure 2와 같은 이미지를 사용하여 연구를 진행했습니다. 맥a크 V1 초기 시각 피질에서 뉴런들은 주로 자신의 수용 영역 내에서 지역적 특징(예: 녹색 사각형)만 초기에 부호화합니다. 그러나 약 75ms 이후, 더 높은 수준의 영역에서 피드백을 받게 되며, 그 질감이 이 그림과 같은 도형에 속할 때에 반응이 더 높아집니다. 이는 원숭이가 도형에서 주의를 돌리더라도 발생하지만, 원숭이가 도형에 주의를 집중할 때 뉴런들이 일반적으로 더 강하게 반응합니다.\n\n두 방향으로 상호작용을 볼 수 있는 한 가지 방법은 각 뉴런이 항상 사용 가능한 예측 신호를 탐욕스럽게 활용한다는 것입니다. 특히 시각적 경계가 중요한 1차 대조 가장자리와 일치하지 않을 때 더 높은 수준의 영역이 예측적일 수 있다는 것을 생각해 볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# Transformers\n\n최근 transformer(바스와니 및 다른 연구진, 2017년)가 등장하면서 주목을 받고, 단어를 하나씩 생성할 수 있는 능력 때문에, transformer가 순환적(recurrent)이라고 생각할 수도 있습니다. 그러나 transformer의 각 단계 사이에는 어떤 내부 상태가 유지되지 않고, 이전 출력값만이 다음 입력값으로 제공됩니다. 따라서 재귀성은 제한되어 있고 뇌에서 널리 사용되는 양방향성은 갖추고 있지 않습니다. Transformer에는 여러 개의 헤드를 가진 어텐션(attention)이 있어, 고정된 개수(본 논문에서는 8개)의 것들에 동시에 주의를 기울일 수 있는 기능을 가지고 있습니다. 따라서 이미지 transformer는 몇 가지 수정을 거친 사전주의식 피드포워드(feedforward) 처리와 유사하다고 볼 수 있습니다.\n\n# CLIP\n\n![CLIP](/assets/img/2024-06-30-CLIPLLaVAandtheBrain_3.png)\n\n<div class=\"content-ad\"></div>\n\nRadford과 OpenAI 팀은 2021년 논문 \"Learning Transferable Visual Models from Natural Language Supervision\"에서 CLIP을 소개했습니다. CLIP의 아이디어는 간단하며 Figure 3에서 보여집니다. 이는 인터넷에서 이미지와 캡션 쌍을 가져와 이미지를 이미지 인코더에, 텍스트를 텍스트 인코더에 주입합니다. 그런 다음 이미지와 텍스트의 인코딩을 동일한 쌍에 사용할 때 서로 가까이 모으는 손실을 사용하며, 그렇지 않으면 인코딩의 거리를 증가시킵니다. 여기에 CLIP이 제공하는 것이 있습니다: 텍스트와 이미지 간 유사성을 비교할 수 있는 능력입니다. 이것은 Figure 4에서 나타나는 것처럼 zero-shot 분류에 사용될 수 있습니다. CLIP은 이미지로부터 텍스트 설명을 생성하지는 않습니다.\n\n이미지 인코더와 텍스트 인코더는 독립적이므로 작업 중심 조절이 이미지 인코딩에 영향을 미치지 못합니다. 이는 이미지 인코더가 작업에 잠재적으로 관련될 수 있는 모든 것을 인코딩해야 한다는 것을 의미합니다. 일반적으로 입력 이미지의 해상도는 작아서 계산 및 메모리 요구 사항이 폭발하는 것을 방지하는 데 도움이 됩니다.\n\n`![CLIPLLaVAandtheBrain](/assets/img/2024-06-30-CLIPLLaVAandtheBrain_4.png)`\n\n# LLaVA\n\n<div class=\"content-ad\"></div>\n\n![LLaVA](/assets/img/2024-06-30-CLIPLLaVAandtheBrain_5.png)\n\n안녕하세요! LLaVA (큰 언어 및 비전 보조 프로그램) (Liu et al. 2023)은 CLIP를 확장하고 개선하여 이미지에 대한 설명 및 질문에 대답할 수 있는 능력을 추가한 대규모 언어 및 비전 아키텍처입니다. 이 유형의 아키텍처는 뇌과학 및 심리학에서 사용되는 작업을 시도할 수 있어 저에게 흥미롭습니다.\n\nLLaVA는 CLIP에서 이미지 인코딩을 위해 훈련된 ViT-L/14 비전 트랜스포머 모델을 사용합니다. 첫 논문에서는 인코딩을 토큰(token)으로 변환하기 위해 단일 선형 투영 매트릭스 W를 사용합니다. 이미지 Hᵥ 및 텍스트 지침 Hq에서 계산된 토큰이 입력으로 제공됩니다. 그런 다음 LLaVA는 언어 응답 Xₐ를 한 번에 한 토큰씩 생성하여 지금까지의 응답을 다음 반복의 입력으로 추가할 수 있습니다.\n\nLLaVA 훈련 방법에 대해 자세히 설명은 생략하겠지만, Figure 5의 캡션(Xc)을 확장하여 이미지에 대한 지침(Hq) 및 응답(Xₐ 훈련에 사용)을 형성하고 바운딩 박스 정보를 사용하는 방법이 흥미롭다는 것에 주목할 만합니다.\n\n<div class=\"content-ad\"></div>\n\n지난 2024년에 발표된 LLaVA 1.5 버전에서는 여러 가지 개선 사항이 있습니다:\n\n- 선형 투영 행렬 W가 다층 퍼셉트론으로 대체되었습니다.\n- 이미지 해상도가 향상되었는데, 336x336 픽셀 크기의 이미지를 사용하고 이미지 인코더를 사용하여 이미지를 그리드로 분할하고 각각을 개별적으로 인코딩했습니다.\n\n뇌의 작업 주도형 주의는 객체, 위치 또는 관심 기능에 리소스를 동적으로 할당할 수 있어 정보 처리를 가능하게 합니다. 이를 통해 혼잡이나 다른 객체에 압도되는 정보를 처리할 수 있습니다. LLaVA에서 이미지 인코더는 텍스트 명령과 독립적이므로 유용한 정보가 이미지 토큰(Hᵥ)에 저장되도록 보장해야 합니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\nLLaVA와 CLIP는 양방향 및 내부 상태에서의 재발 및 재발을 제한하여 그들의 처리를 방해합니다. 이는 이미지 처리에 특히 사실입니다. 이미지 처리는 텍스트 지시사항과 독립적으로 수행되기 때문입니다. 대부분의 합성곱 신경망도 이러한 제한을 공유합니다. 이것이 내 추측으로 이어집니다:\n\n이것은 비판이 아니라 정보를 제공할 수 있는 통찰력일 뿐입니다. 피드포워드 처리는 많은 일을 할 수 있으며 빠릅니다. 그러나 사용해야 할 리소스가 얼마나 동적인지에 따라 정보가 너무 많아질 때 혼잡한 장면에서 정보 병목 현상을 야기할 수 있으며, 순방향 처리가 충분한 정보를 인코딩하지 못할 수 있습니다. 복잡한 작업을 수행할 수 있는 임의의 크기 증폭 없이 인코딩의 크기가 폭발하는 것입니다. 순방향 방식으로 작동하는 모델을 만드는 것은 재발 및 양방향 처리를 추가하는 어려움 때문에 중요한 발걸음입니다.\n\n일부 네트워크는 선행적인 피드포워드 네트워크에 제한되지 않지만 현재 대부분의 아키텍처는 트랜스포머의 뒤를 뒤쫓고 있습니다. 이는 LSTM(Long-Short Term Memory) 모델 및 더 최근에는 여러 이점이 있는 Mamba 아키텍처를 포함합니다 (Gu and Dao 2024). 연장된 LSTM(Beck et al. 2024, Alkin et al. 2024)이 최근에 제안되어 트랜스포머와 LSTM 간의 균형을 맞추는 데 도움이 되었습니다. 확산 모델은 반복 사용 사이에 상태로 이미지를 사용하는 유형의 제한된 종류의 재발을 가지고 있습니다.\n\n<div class=\"content-ad\"></div>\n\nB. Alkin, M. Beck, K. Pöppel, S. Hochreiter, and J. Brandstetter가 함께 쓴 \"Vision-LSTM: xLSTM as Generic Vision Backbone\" (2024) 논문 번호는 http://arxiv.org/abs/2406.04303 입니다.\n\nM. Beck, K. Pöppel, M. Spanring, A. Auer, O. Prudnikova, M. Kopp, G. Klambauer, J. Brandstetter, 그리고 S. Hochreiter.가 함께 쓴 \"xLSTM: Extended Long Short-Term Memory\" (2024) 논문 번호는 http://arxiv.org/abs/2405.04517입니다.\n\nA. Gu 와 T. Dao가 쓴 \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" (2024) 논문 번호는 http://arxiv.org/abs/2312.00752 입니다.\n\nH. Liu, C. Li, Y. Li, 그리고 Y. J. Lee의 \"Improved Baselines with Visual Instruction Tuning\" (2024)은 IEEE/CVF CVPR 학회에서 발표되었습니다.\n\n<div class=\"content-ad\"></div>\n\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, Visual Instruction Tuning (2023), [DOI: 10.48550/arXiv.2304.08485]\n\nJ. Poort, F. Raudies, A. Wannig, V. A. F. Lamme, H. Neumann, and P. R. Roelfsema. The Role of Attention in Figure-Ground Segregation in Areas V1 and V4 of the Visual Cortex (2012) Neuron\n\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, and J. Clark. Learning Transferable Visual Models from Natural Language Supervision (2021) ICML\n\nR. VanRullen, The Power of the Feed-Forward Sweep (2007) Advances in Cognitive Psychology\n\n<div class=\"content-ad\"></div>\n\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin의 'Attention Is All You Need' (2017)은 NeurIPs에서 발표되었습니다.\n\nJ. R. Williford와 R. von der Heydt의 'Border-Ownership Coding' (2013)은 Scholarpedia에서 찾을 수 있습니다.\n\nH. Zhou, H. S. Friedman, and R. von der Heydt의 \"Coding of Border Ownership in Monkey Visual Cortex\" (2000)은 The Journal of Neuroscience에서 발표되었습니다.\n\n최초 게시된 내용은 2024년 6월 19일 neural.vision에서 확인할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-30-CLIPLLaVAandtheBrain_0.png"},"coverImage":"/assets/img/2024-06-30-CLIPLLaVAandtheBrain_0.png","tag":["Tech"],"readingTime":8},{"title":"자율 주행에서 감지 엔지니어를 위한 플래닝 크래시 코스","description":"","date":"2024-06-30 23:46","slug":"2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving","content":"\n\n## 기획과 결정을 위한 기본\n\n![이미지](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_0.png)\n\n고전적인 모듈식 자율 주행 시스템은 일반적으로 인식, 예측, 기획 및 제어로 구성되어 있습니다. 2023년까지 대부분의 대량 생산 자율 주행 시스템에서 AI(인공지능) 또는 ML(머신러닝)은 주로 인식을 향상시켰으며, 그 영향은 하류 구성 요소에서 사라졌습니다. 기획 스택에서 AI의 낮은 통합과는 대조적으로, BEV(새눈뷰 인식 파이프라인과 같은 end-to-end 인식 시스템)과 같은 인식 시스템이 대량 생산 차량에 적용되었습니다.\n\n![이미지](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_1.png)\n\n<div class=\"content-ad\"></div>\n\n다중 이유가 있습니다. 사람이 만든 프레임워크에 기반을 둔 고전적인 스택은 기계 학습 기반 기능보다 설명 가능성이 높으며 현장 시험 문제를 빠르게 해결하기 위해 빠르게 반복할 수 있습니다(수 시간 내). 그러나 사용 가능한 인간 주행 데이터를 방치하는 것은 합리적이지 않습니다. 또한, 컴퓨팅 파워를 증가하는 것이 엔지니어링 팀을 확장하는 것보다 더 확장 가능합니다.\n\n다행히도, 학계와 산업 모두에서 이 상황을 바꾸기 위한 강력한 추세가 있습니다. 먼저 하류 모듈은 점점 데이터 중심적이 되고, CVPR 2023의 최고 논문인 UniAD에서 제안된 것과 같은 다른 인터페이스를 통합할 수도 있습니다. 또한 점점 발전하는 생성적 인공지능의 물결에 이끌려, 단일 통합 비전-언어-행동(VLA) 모델은 복잡한 로봇 작업(RT-2에서 학계, TeslaBot 및 1X에서 산업) 및 자율 주행(GAIA-1, DriveVLM에서 학계, Wayve AI 운전자, Tesla FSD에서 산업)를 처리하는 데 큰 잠재력을 보여줍니다. 이는 인식 스택에서 계획 스택으로의 AI 및 데이터 중심 개발 도구들을 가져오게 됩니다.\n\n본 블로그 포스트는 인지 엔지니어들이라는 인식 엔지니어들을 위한 급작스러운 강좌 형식으로, 계획 스택의 문제 설정, 기존 방법론 및 도전 과제를 소개하는 것을 목표로 합니다. 인지 엔지니어로서 저는 지난 몇 주 동안 고전적인 계획 스택을 체계적으로 학습할 시간이 생겼고, 배운 내용을 공유하고 싶습니다. 또한 AI 실무자의 관점에서 AI가 어떻게 도움을 줄 수 있는지에 대한 생각도 나누겠습니다.\n\n본 게시물의 목표 독자는 특히 자율 주행 분야에서 활동하는 AI 실무자, 특히 인지 엔지니어를 대상으로 합니다.\n\n<div class=\"content-ad\"></div>\n\n테이블 목차가 있는 긴 기사입니다 (11100 단어), 키워드로 빠르게 검색하고자 하는 분들께 도움이 될 것 같아요.\n\nTable of Contents (ToC)\n\n왜 계획을 배워야 하는가?\n계획이란 무엇인가?\n   문제 정의\n   계획 용어집\n   행동 계획\n   Frenet vs 카테시안 시스템\n고전적 도구 - 계획의 삼총사\n   탐색\n   샘플링\n   최적화\n산업 현장에서의 계획 실천\n   경로 - 속력 분리된 계획\n   공간-시간적 결합된 계획\n의사 결정\n   무엇과 왜?\n   MDP와 POMDP\n   가치 반복과 정책 반복\n   알파고와 MCTS - 신경망과 트리의 만남\n   자율주행에서의 MPDM (및 후속작)\n산업 현장에서의 의사 결정\n   트리\n   트리 없이\n자기 성찰\n   왜 계획에서 신경망인가?\n   e2e NN 플래너는 무엇인가?\n   예측 없이도 할 수 있을까?\n   트리 없이도 신경망만으로 할 수 있을까?\n   의사 결정을 위해 LLM을 사용할 수 있을까?\n진화 트렌드\n\n<div class=\"content-ad\"></div>\n\n문제 해결적인 시각에서, 여러분의 고객들의 어려움을 더 잘 이해한다면, 인지 엔지니어로서 하향식 고객들에게 더 효과적으로 서비스를 제공할 수 있을 것입니다. 주요 관심을 인지 작업에 두지만, 새로운 도구를 도메인 지식과 결합하는 것이 문제를 해결하는 가장 효율적인 방법입니다. 특히 튼튼한 수학적 공식을 갖는 도메인 지식에 영감을 받은 학습 방법은 더 많은 데이터 효율성을 가질 것입니다. 계획이 규칙 기반에서 머신 러닝 기반 시스템으로 전환되면서 초기 프로토타입과 종단간 시스템의 제품이 도로에 등장하더라도, 계획과 머신 러닝의 기본을 깊이 이해할 수 있는 엔지니어가 필요합니다. 이러한 변화에도 불구하고, 고전적인 방법과 학습 방법이 상당 기간 동안 공존할 가능성이 높습니다. 아마 8:2에서 2:8로 이동하는 것일지도 모릅니다. 이 분야에서 일하는 엔지니어에게는 양쪽 세계를 이해하는 것이 거의 필수적입니다.\n\n가치 중심의 개발 관점에서, 고전적인 방법의 한계를 이해하는 것이 중요합니다. 이 통찰력은 즉시 영향을 주고 현재 문제를 해결하는 시스템을 디자인하기 위해 새로운 머신 러닝 도구를 효과적으로 활용할 수 있게 해 줍니다.\n\n또한, 계획은 자율 주행뿐만 아니라 모든 자율 에이전트에 중요한 부분입니다. 계획이 무엇인지, 어떻게 작동하는지를 이해한다면, 더 많은 머신 러닝 재능이 이 흥미로운 주제에 참여하여 자율 에이전트, 자동차든 다른 형태의 자동화든 발전에 기여할 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 계획이란 무엇인가요?\n\n## 문제 정의\n\n자율주행 차량의 \"뇌\"인 계획 시스템은 차량의 안전하고 효율적인 주행에 중요합니다. 플래너의 목표는 안전하고 편안하며 목표지점으로 효율적으로 진행하는 궤적을 생성하는 것입니다. 다시 말해, 안전, 편안함, 그리고 효율성이 계획의 세 가지 주요 목표입니다.\n\n계획 시스템에 대한 입력은 정적 도로 구조물, 동적 도로 에이전트, 점유 네트워크에서 생성된 빈 공간, 그리고 교통 대기 조건을 포함한 모든 인지 출력물이 필요합니다. 계획 시스템은 부드러운 궤적을 위해 가속도와 거칠기를 모니터링하고 상호작용과 교통 예의를 고려하여 차량 안락성을 보장해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n계획 시스템은 자아 차량의 저수준 컨트롤러가 추적하기 위해 일련의 웨이포인트 형식의 궤적을 생성합니다. 구체적으로 이러한 웨이포인트는 미래의 자아 차량 위치를 일련의 고정된 시간 스탬프에서 나타냅니다. 예를 들어, 각 포인트는 0.4초 간격으로, 8초 계획 수평을 커버하며 총 20개의 웨이포인트가 생성될 수 있습니다.\n\n고전적인 계획 스택은 전역 경로 계획, 지역 행동 계획 및 지역 궤적 계획으로 대략적으로 구성됩니다. 전역 경로 계획은 글로벌 지도상에서 시작점부터 도착점까지의 도로 수준 경로를 제공합니다. 지역 행동 계획은 다음 몇 초 동안의 의미 있는 운전 행동 유형(예: 따라가기, 기운주기, 차선 변경하기, 양보하기, 추월하기)을 결정합니다. 행동 계획 모듈에서 결정된 행동 유형을 기반으로, 지역 궤적 계획이 단기 궤적을 생성합니다. 전역 경로 계획은 보통 내비게이션이 설정된 후에 지도 서비스에 의해 제공되며, 본 글의 범위를 벗어납니다. 이제부터 행동 계획 및 궤적 계획에 초점을 맞출 것입니다.\n\n행동 계획 및 궤적 생성은 명시적으로 함께 작동하거나 하나의 프로세스로 결합될 수 있습니다. 명시적 방법에서는, 행동 계획 및 궤적 생성이 계층적 프레임워크 내에서 다른 주파수에서 작동하는 별개의 프로세스로 작동합니다. 행동 계획은 1~5Hz, 궤적 계획은 10~20Hz에서 작동합니다. 대부분의 경우 높은 효율을 보이지만, 다양한 시나리오에 대응하려면 상당한 수정과 세부 조정이 필요할 수 있습니다. 더 발전된 계획 시스템은 두 가지를 하나의 최적화 문제로 결합합니다. 이 접근 방식은 효율성과 최적성을 모두 보장하며 어떠한 타협도 없이 가능성을 확보합니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_2.png)\n\n<div class=\"content-ad\"></div>\n\n## 계획 용어집\n\n이미지와 위 섹션에서 사용된 용어가 완전히 일치하지 않는 것을 눈치채셨을 수 있습니다. 모두가 사용하는 표준 용어가 없습니다. 학계와 산업에서 엔지니어들이 같은 개념을 가리키는 데 다른 이름을 사용하거나, 다른 개념을 가리키는 데 같은 이름을 사용하는 것은 흔치 않습니다. 이는 자율 주행 분야의 계획이 아직 미루거나 완전히 수렴하지 않았음을 나타냅니다.\n\n여기서는 이 게시물에서 사용된 표기법을 나열하고 문헌에서 제시된 기타 개념들을 간단히 설명합니다.\n\n- 계획(Planning): 제어와 병렬로 생성된 경로 중요점을 생성하는 최상위 개념. 계획과 제어는 함께 PnC(계획과 제어)로 참조됩니다.\n- 제어(Control): 경로 중요점을 받아서 구동기가 실행할 고주파 스티어링, 스로틀 및 브레이크 명령을 생성하는 최상위 개념입니다. 제어는 다른 영역에 비해 비교적 잘 수립되었으며 일반적인 PnC 개념에도 불구하고 이 게시물의 범위를 벗어납니다.\n- 예측(Prediction): 주행 차량 이외의 교통 에이전트의 미래 경로를 예측하는 최상위 개념. 예측은 기타 에이전트를 위한 가벼운 계획으로 간주될 수 있으며 동작 예측이라고도 합니다.\n- 행동 계획(Behavior Planning): 고수준의 의미 있는 동작(예: 차선 변경, 추월)을 생성하는 모듈로 일반적으로 상위 수준의 궤적을 생성합니다. 상호 작용 맥락에서 특히 상호 작용에 관한 의사 결정 또는 작업 계획으로도 알려져 있습니다.\n- 동작 계획(Motion Planning): 의미 있는 동작을 받아들여 제어가 실행할 계획 가시거리 동안 매끄러우며 실행 가능한 경로 중요점을 생성하는 모듈입니다. 궤적 계획이라고도 합니다.\n- 궤적 계획(Trajectory Planning): 동작 계획과 같은 용어입니다.\n- 의사 결정(Descision Making): 상호 작용에 초점을 맞춘 행동 계획입니다. 에고-에이전트 상호 작용이 없으면 단순히 행동 계획으로 참조됩니다. 전술적 의사 결정이라고도 합니다.\n- 루트 계획(Route Planning): 도로 네트워크 상의 우선적인 경로를 찾아주는 모듈로 임무 계획이라고도 합니다.\n- 모델 기반 접근(Model-Based Approach): 계획에서 고전적인 계획 스택에서 사용되는 수동으로 제작된 프레임워크를 가리킵니다. 학습 기반 방법과 대조되며 학습 기반 방법과 대조됩니다.\n- 다중성(Multimodality): 계획의 컨텍스트에서 다양한 의도를 일반적으로 가리킵니다. 이는 인지에 다중 모달 입력이나 VLM이나 VLA와 같은 다중 모달 대형 언어 모델의 컨텍스트의 다중성과 대조됩니다.\n- 참조선(Reference Line): 글로벌 경로 정보와 에고 차량의 현재 상태를 기반으로 한 지역(수백 미터) 및 굵은 경로입니다.\n- 프레네트 좌표계(Frenet Coordinates): 참조선을 기반으로 한 좌표계입니다. 프레네트는 곡선 경로를 직선적인 터널 모델로 단순화합니다. 더 자세한 소개는 아래에서 확인하십시오.\n- 궤적(Trajectory): (x, y, t)의 카테시안 좌표계 또는 프레네트 좌표계의 (s, l, t) 형식으로 3D 공간시간 곡선입니다. 궤적은 경로와 속도로 구성됩니다.\n- 경로(Path): (x, y)의 카테시안 좌표계 또는 프레네트 좌표계의 (s, l) 형식으로 2D 공간 곡선입니다.\n- 의미 있는 동작(Semantic Action): 명확한 인간 의도를 가진 동작 (예: 차량 추격, 가로막기, 옆 통행, 양보, 추월)의 고수준 추상화입니다. 의도, 정책, 조종 또는 기본 동작으로도 개별적으로 참조됩니다.\n- 동작(Action): 고정된 의미가 없는 용어입니다. 제어(구동기가 실행할 고주파 스티어링, 스로틀 및 브레이크 명령)의 출력 또는 계획(경로 중요점)의 출력으로 참조될 수 있습니다. 의미 있는 동작은 동작 예측의 출력으로 참조됩니다.\n\n<div class=\"content-ad\"></div>\n\n다양한 문헌에서는 각기 다른 표기법과 개념을 사용할 수 있습니다. 몇 가지 예시를 살펴보겠습니다:\n\n- 의사결정 시스템: 때로는 계획과 제어를 포함하기도 합니다. (출처: A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles 및 BEVGPT)\n- 이동 계획: 때로는 최상위 계획 개념이며, 행동 계획과 궤적 계획을 포함하기도 합니다. (출처: Towards A General-Purpose Motion Planning for Autonomous Vehicles Using Fluid Dynamics)\n- 계획: 때로는 행동 계획, 이동 계획, 루트 계획을 모두 포함하기도 합니다.\n\n이러한 변형들은 용어 다양성과 이 분야의 진화하는 성격을 보여줍니다.\n\n## 행동 계획\n\n<div class=\"content-ad\"></div>\n\n기계 학습 엔지니어로, 행동 계획 모듈이 매우 수작업으로 만들어진 중간 모듈임을 알 수 있습니다. 정확한 형식과 내용에 대한 합의가 없습니다. 구체적으로, 행동 계획의 출력물은 참조 경로 또는 이고 동작에 대한 객체 라벨링일 수 있습니다 (예: 왼쪽 또는 오른쪽에서 지나가기, 통과 또는 양보). \"의미 행동\"이라는 용어에는 엄격한 정의나 고정된 방법이 없습니다.\n\n행동 계획과 이동 계획의 분리는 자율 주행 차량의 극도로 높은 차원의 작업 공간을 효율적으로 해결하는 데 도움이 됩니다. 자율 주행 차량의 동작은 일반적으로 10 Hz 이상 (경로점에서의 시간 해상도)에서 사고되어야 하며, 이러한 대부분의 동작은 직진과 같이 비교적 간단합니다. 분리 후, 행동 계획 레이어는 상대적으로 굵은 해상도에서 미래 시나리오를 고려해야 하며, 이동 계획 레이어는 행동 계획에 의해 내려진 결정을 기반으로 지역 해결 공간에서 작동합니다. 행동 계획의 또 다른 이점은 비볼록 최적화를 볼록 최적화로 변환하는 것이며, 이에 대해 더 자세히 논의하겠습니다.\n\n## Frenet vs Cartesian systems\n\n프레네트 좌표계는 자신만의 소개 섹션을 가치 있게 여길 만큼 널리 사용되는 시스템입니다. 프레네트 프레임은 머리를 따라 경로에 대한 측면 및 종횡 운동을 독립적으로 관리함으로써 궤적 계획을 간단화합니다. sss 좌표는 종횡 편향 (도로를 따라 이동 거리)을 나타내며, lll (또는 ddd) 좌표는 경로에 대한 측면 위치 (참조 경로와의 상대적 위치)를 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\nFrenet은 카테시안 좌표계에서 곡선 경로를 직선 터널 모델로 간단화합니다. 이 변환은 곡선 도로의 비선형 경계 제약을 선형 제약으로 변환하여 후속 최적화 문제를 크게 간소화합니다. 또한 인간은 종방향 및 횡방향 움직임을 다르게 인식하며, Frenet 프레임은 이러한 움직임을 분리하고 더 유연하게 최적화할 수 있도록 합니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_3.png)\n\nFrenet 좌표계는 낮은 곡률의 정형화된 도로 그래프가 필요합니다. 실제로는 고속도로나 도심 고속도로와 같이 곡률이 작은 구조화된 도로에 선호됩니다. 그러나 Frenet 좌표계의 문제는 기준선 곡률이 증가함에 따라 크게 증폭되므로, 가이드 라인이 있는 도시 교차로와 같이 높은 곡률을 갖는 구조화된 도로에는 신중히 사용해야 합니다.\n\n항구, 광산 지역, 주차장 또는 가이드 라인이 없는 교차로와 같은 비정형 도로의 경우, 더 유연한 카테시안 좌표계를 권장합니다. 카테시안 시스템은 고곡률 및 구조화되지 않은 시나리오를 더 효과적으로 처리할 수 있기 때문에 이러한 환경에 더 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n# 고전적 도구 — 계획의 삼총사\n\n자율 주행의 계획은 초기 고차원 상태(위치, 시간, 속도, 가속도 및 갑작스러운 변화 포함)부터 목표 부분 공간까지의 경로를 계산하고 모든 제약 조건을 충족하는 것을 포함합니다. 검색, 샘플링 및 최적화는 계획에 널리 사용되는 세 가지 도구입니다.\n\n## 검색\n\n고전적인 그래프 검색 방법은 계획에서 인기가 있으며 구조화된 도로 상의 경로/미션 계획이나 구조화되지 않은 환경에서 최적의 경로를 찾기 위해 직접 모션 계획에 사용됩니다(주차장이나 도시 교차로와 같은 맵이 없는 시나리오). Dijkstra 알고리즘에서 A*(에이 스타)로 그리고 하이브리드 A*로 발전 경로가 명확하게 있습니다.\n\n<div class=\"content-ad\"></div>\n\nDijkstra's algorithm is like a thorough explorer examining every possible route to find the shortest one. It's a diligent method that guarantees the best path but can be a bit slow in practice. The algorithm shown in the image below meanders around in search of the optimal path. Essentially, it's similar to a broad and far-reaching search, considering the costs involved in moving to each location. To make this process more efficient, factoring in the destination location can help narrow down the search area.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_4.png)\n\nIn contrast, the A* algorithm utilizes clever strategies to prioritize paths that seem to be heading closer to the end goal, which enhances its efficiency. A* cleverly combines the distance traveled so far (as in Dijkstra's) with an estimate of the remaining distance using heuristics. A* will guarantee the shortest path only if the heuristics are logical and reliable. If the heuristic is not well-suited, A* might perform worse than Dijkstra and may end up acting more like a simple best-first search.\n\nFor autonomous driving scenarios, the hybrid A* algorithm takes a step further by incorporating vehicle dynamics. A* alone may not adhere to the vehicle's movement restrictions and might not track accurately (for instance, maintaining the steering angle within a specific range like 40 degrees). While A* treats both the state and action spaces as a grid, the hybrid A* distinguishes between them, keeping the state in a grid-like structure but allowing smooth continuous actions based on the vehicle's dynamics.\n\n<div class=\"content-ad\"></div>\n\n타로 전문가님 안녕하세요! 하이브리드 A*에서 제안된 핵심 혁신 중 하나인 분석 확장(목표로 향한 슛)이 있습니다. A*에 대한 자연스러운 개선 방법은 최근에 탐색한 노드를 목표 지점에 이어지는 충돌하지 않는 직선으로 연결하는 것입니다. 이를 가능하게 한다면, 우리는 해결책을 찾은 것입니다. 하이브리드 A*에서는 이 직선이 Dubins 및 Reeds-Shepp(RS) 커브로 대체되며, 이는 차량 키네마틱스를 준수합니다. 이 초기 중지 방법은 최적성과 실현 가능성 사이의 균형을 이루며, 더 나아가 실현 가능성에 더 초점을 맞춥니다.\n\n하이브리드 A*는 주차 상황 및 지도 없는 도심 교차로에서 적극적으로 활용됩니다. 여기에 주차 상황에서 그 작동 방식을 시연한 매우 멋진 동영상이 있습니다.\n\n![video](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_5.png)\n\n## 샘플링\n\n<div class=\"content-ad\"></div>\n\n다른 인기있는 계획 방법 중 하나는 샘플링입니다. 유명한 몬테카를로 방법은 무작위 샘플링 방법입니다. 본질적으로 샘플링은 많은 후보를 무작위로 선정하거나 사전에 따라 선택한 다음, 정의된 비용에 따라 최적의 후보를 선택하는 것을 포함합니다. 샘플링 기반 방법에서는 많은 옵션을 빠르게 평가하는 것이 중요합니다. 왜냐하면 이는 자율 주행 시스템의 실시간 성능에 직접적인 영향을 미치기 때문이죠.\n\n샘플링은 이미 주어진 문제나 하위 문제에 대한 해석적 솔루션이 이미 알려져 있는 매개 변수화된 솔루션 공간에서 발생할 수 있습니다. 예를 들어, 일반적으로 시간에 따른 위치 p(t)의 세 번째 미분(삼차 도함수)인 제르크(가속도의 세 번째 미분)의 제곱의 시간 적분을 최소화하는 것을 원합니다. \n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_6.png)\n\n수학적으로 증명될 수 있습니다. 이차 도학수의 제어 상태 사이의 최적의 연결을 제공하는 것은 신차(5차) 다항식이며, 추가된 비용 요소를 고려할 때에도 마찬가지입니다. 5차 다항식의 매개 변수 공간에서 샘플링함으로써 최소 비용을 갖는 것을 찾아 근사 솔루션을 얻을 수 있습니다. 비용은 속도, 가속도, 제르크 제한 및 충돌 확인과 같은 요소를 고려합니다. 이 방법은 본질적으로 샘플링을 통해 최적화 문제를 해결합니다.\n\n<div class=\"content-ad\"></div>\n\n이미지 tag를 Markdown 형식으로 변경해주세요.\n\nSampling-based methods have inspired numerous ML papers, including CoverNet, Lift-Splat-Shoot, NMP, and MP3. These methods replace mathematically sound quintic polynomials with human driving behavior, utilizing a large database. The evaluation of trajectories can be easily parallelized, which further supports the use of sampling-based methods. This approach effectively leverages a vast amount of expert demonstrations to mimic human-like driving behavior, while avoiding random sampling of acceleration and steering profiles.\n\n![Image 7](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_7.png)\n\nOptimization\n\n<div class=\"content-ad\"></div>\n\n최적화는 특정 제약 조건 하에서 목표 함수를 최대화하거나 최소화하여 문제에 대한 최상의 해법을 찾는 것을 의미합니다. 신경망 훈련에서는 경사 하강법과 역전파를 사용하여 네트워크의 가중치를 조정하는 유사한 원리가 적용됩니다. 그러나 신경망 이외의 최적화 작업에서는 일반적으로 모델이 덜 복잡하며 경사 하강법보다 효과적인 방법이 종종 사용됩니다. 예를 들어, 경사 하강법은 이차 프로그래밍에 적용될 수 있지만, 일반적으로 가장 효율적인 방법은 아닙니다.\n\n자율 주행에서 최적화를 위한 계획 비용은 일반적으로 동적 객체(장애물 회피), 정적 도로 구조(차로 따라가기), 올바른 경로를 보장하기 위한 내비게이션 정보 및 자아 상태(부드러움 평가)를 고려합니다.\n\n최적화는 볼록(convex) 및 비볼록(non-convex) 유형으로 분류할 수 있습니다. 핵심 차이점은 볼록 최적화 시나리오에서 전역 최적해가 하나만 존재하며 해당 해가 지역 최적해이기도 하다는 것입니다. 이 특징은 최적화 문제에 대한 초기 솔루션에 영향을 받지 않는다는 것을 의미합니다. 반면 비볼록 최적화에서는 초기 솔루션이 매우 중요하며 아래 차트에서 설명되듯이 초기 솔루션에 따라 결과가 크게 달라집니다.\n\n![이미지](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_9.png)\n\n<div class=\"content-ad\"></div>\n\n계획 수립은 많은 지역 최적점을 갖는 매우 비볼록 최적화를 포함하므로 초기 솔루션에 매우 의존합니다. 게다가 볼록 최적화는 일반적으로 더 빨리 실행되므로 자율 주행과 같은 실시간 애플리케이션에선 선호됩니다. 전형적인 방법론은 다른 방법들과 함께 볼록 해법 공간을 먼저 개요화하기 위해 볼록 최적화를 사용하는 것입니다. 이것이 행동 계획과 모션 계획을 분리하는 수학적 기초이며, 좋은 초기 솔루션을 찾는 것은 행동 계획의 역할입니다.\n\n구체적인 예로 장애물 회피를 들어보겠습니다. 장애물의 위치는 최적화 문제의 하한 또는 상한 제약 조건 역할을 하면서 일반적으로 비볼록 문제를 소개합니다. 방향을 아는 경우 이를 살짝 밀어내는 것은 볼록 최적화 문제가 되며, 방향을 모르는 경우 미는 방향을 먼저 결정해야 하므로 모션 계획이 해결하는 볼록 문제로 전환됩니다. 이 방향 결정은 행동 계획에 속합니다.\n\n![Image 1](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_10.png)\n\n![Image 2](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_11.png)\n\n<div class=\"content-ad\"></div>\n\n그런 결정을 어떻게 내릴까요? 비볼록 문제를 해결하기 위해 앞서 언급한 탐색 또는 샘플링 방법을 사용할 수 있습니다. 샘플링 기반 방법은 매개 변수 공간에 많은 옵션을 흩뿌려 비볼록 문제를 효과적으로 처리하며, 마치 탐색하는 것과 유사합니다.\n\n어느 방향에서 밀어내야 하는지 결정함으로써 문제 공간이 볼록성을 보장하는 데 충분하다고 의문을 제기할 수도 있습니다. 이를 설명하기 위해 토폴로지에 대해 이야기할 필요가 있습니다. 경로 공간에서 유사한 실행 가능한 경로는 장애물 간섭 없이 서로 연속적으로 변환될 수 있습니다. 이러한 유사한 경로는 토폴로지의 형식적 언어로 \"동인시류 클래스\"로 그룹화되며, 이들과 동인시류 클래스에 속하는 단일 초기 솔루션에서 출발하는 것으로 모두 탐색할 수 있습니다. 이러한 경로들은 그림에서 빨간색 또는 녹색 그림자 영역으로 설명된 주행 복도를 형성합니다. 3D 시공간 경우에 대한 자세한 내용은 QCraft 기술 블로그를 참조해 주세요.\n\n효율적으로 최적화 문제를 해결하는 핵심은 최적화 솔버의 능력에 있습니다. 일반적으로 솔버는 궤적을 계획하는 데 약 10밀리초가 소요됩니다. 이 효율성을 10배로 증가시킬 수 있다면, 이는 알고리즘 설계에 상당한 영향을 미칠 수 있습니다. 이 정확한 개선은 2022년 Tesla AI Day에서 강조되었습니다. 인지 시스템에서도 유사한 개선이 일어났는데, 가능한 컴퓨팅 파워가 10배로 증가함에 따라 2D 인식에서 Bird’s Eye View (BEV)로 전환되었습니다. 보다 효율적인 최적화 솔버를 만들기 위해서는 상당한 엔지니어링 자원이 필요합니다.\n\n#계획의 산업 실천 방법\n\n<div class=\"content-ad\"></div>\n\n다양한 계획 시스템의 중요한 차별 요인 중 하나는 시공간적으로 분리되어 있는지 여부입니다. 구체적으로 시공간적으로 분리된 방법은 먼저 공간 차원에서 경로를 생성한 다음 이 경로의 속도 프로필을 계획합니다. 이 접근 방식은 경로-속도 분리로도 알려져 있습니다.\n\n경로-속도 분리는 가로방향-세로방향 (lat-long) 분리로 자주 언급되며, 여기서 가로방향 (lat) 계획은 경로 계획에 해당하고 세로방향 (long) 계획은 속도 계획에 해당합니다. 이 용어는 프레네트 좌표계에서 유래한 것으로 보입니다. 나중에 자세히 살펴보겠습니다.\n\n분리된 해결책은 구현하기 쉽고 문제의 약 95%를 해결할 수 있습니다. 반면 결합된 해결책은 높은 이론적 성능 한계를 가지나 구현하기 어렵습니다. 더 많은 매개변수를 조정해야 하며 매개변수 조정에 보다 원칙적인 접근이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_13.png)\n\n## Path-speed decoupled planning\n\nBaidu Apollo's EM planner is a great example of path-speed decoupled planning system.\n\nThe EM planner simplifies the computational complexity by breaking down a three-dimensional station-lateral-speed problem into two two-dimensional problems: station-lateral and station-speed. The core of Apollo’s EM planner consists of an iterative Expectation-Maximization (EM) step, which includes path optimization and speed optimization. Each step involves an E-step (projection and formulation in a 2D state space) and an M-step (optimization in the 2D state space). The E-step requires projecting the 3D problem into either a Frenet SL frame or an ST speed tracking frame.\n\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_14.png)\n\nIn the realm of autonomous driving, the M-step (maximization step) plays a crucial role in path and speed optimization by tackling non-convex optimization challenges. When optimizing the path, decisions revolve around shifting an object to the left or right, while speed optimization requires choices like overtaking or yielding to dynamic objects on the path. The Apollo EM planner effectively handles these challenges through a two-step process: first employing Dynamic Programming (DP) and then transitioning to Quadratic Programming (QP).\n\nDynamic Programming employs a sampling or searching algorithm to create an initial solution, effectively transforming the non-convex space into a convex one, laying the groundwork for QP. Quadratic Programming then fine-tunes the rough DP results within the convex space. DP prioritizes feasibility, while QP focuses on refining the solution for optimal results within the constraints.\n\nUsing our defined terminology, Path DP corresponds to lateral BP, Path QP to lateral MP, Speed DP to longitudinal BP, and Speed QP to longitudinal MP. This process involves executing Basic Planning (BP) first, followed by Master Planning (MP) in both path and speed optimization steps.\n\n<div class=\"content-ad\"></div>\n\n![Autonomous Driving Planning](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_15.png)\n\n## 공간적 시간적 결합 계획\n\n자율 주행에서 분리된 계획이 95%의 경우를 해결할 수 있지만, 남은 5%는 도전적인 동적 상호작용을 포함하여 분리된 해결책은 종종 최적의 궤적을 도출하지 못하는 복잡한 시나리오입니다. 이러한 복잡한 상황에서 지능을 증명하는 것은 중요하기 때문에 이는 그 분야에서 매우 핫한 주제입니다.\n\n예를 들어, 좁은 공간 통과 시, 최적의 행동은 양보하기 위해 감속하거나 지나가기 위해 가속하는 것일 수 있습니다. 이러한 행동은 분리된 해결 공간 내에서 실현할 수 없으며, 공간과 속도를 동시에 고려하여 복잡한 동적 상호작용을 효과적으로 처리하는 것을 요구합니다. 공간적 시간적 결합 최적화는 더 통합된 접근 방식을 가능하게 하며, 경로와 속도를 동시에 고려하여 복잡한 동적 상호작용을 효과적으로 다룰 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_16.png)\n\nBut, let's talk about the challenges in joint spatiotemporal planning. Firstly, solving the non-convex problem directly in a higher-dimensional state space is more complex and time-consuming compared to using a decoupled solution. Secondly, considering interactions in spatiotemporal joint planning adds another layer of complexity. We will delve deeper into this topic when we address decision-making.\n\nNow, let's discuss two methods for solving these challenges: brute force search and constructing a spatiotemporal corridor for optimization.\n\nBrute force search involves direct exploration in a 3D spatiotemporal space (2D in space and 1D in time) and can be conducted in either XYT (Cartesian) or SLT (Frenet) coordinates. Let's take SLT as an example. In SLT space, the layout resembles an elongated energy bar, stretched in the L dimension and flattened in the ST face. For brute force search, we can apply the hybrid A-star algorithm, where the cost consists of a combination of progress cost and cost to go. Throughout optimization, we must adhere to search constraints that prevent backward movements in both the s and t dimensions.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_17.png)\n\n또 다른 방법은 환경 요소를 고려한 안전한 경로를 생성하는 공간시간 좌표계 골목을 구축하는 것입니다. SSC (Spatial Semantic Corridor)는 시맨틱 요소에 의해 주어진 요구 사항을 시맨틱 골목으로 해석하여 이에 맞는 안전한 경로를 생성합니다. 시맨틱 골목은 시공간 도메인에서 시맨틱 요소에 의해 제시된 동적 제약 조건이 있는 상호 연결된 일련의 충돌이 없는 큐브들로 구성됩니다. 각 큐브 내에서는 Quadratic Programming (QP)을 사용하여 해결할 수 있는 볼록 최적화 문제가 되며, 이에 의해 안전한 경로가 결정됩니다.\n\nSSC는 여전히 BP (Behavior Planning) 모듈이 필요하여 초기 운전 경로를 제공합니다. 환경의 복잡한 시맨틱 요소는 참조 차선을 중심으로 시공간 도메인에 투영됩니다. EPSILON은 SSC가 동작 계획자와 협력하여 작동하는 운동 계획자로 구성된 시스템을 소개한 바 있습니다. 다음 섹션에서는 특히 상호 작용에 초점을 맞춘 동작 계획에 대해 논의할 것입니다. 이 문맥에서 동작 계획은 일반적으로 의사 결정으로 언급됩니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_18.png)\n\n<div class=\"content-ad\"></div>\n\n# 의사 결정\n\n## 무엇과 왜?\n\n자율 주행에서의 의사 결정은 본질적으로 행동 계획이지만 다른 교통 요소와의 상호 작용에 초점을 맞춥니다. 가정은 다른 요소들이 대부분 합리적이며 우리의 행동에 예측 가능한 방식으로 반응할 것이라는 것입니다. 이를 \"잡음 있는 합리성\"으로 설명할 수 있습니다.\n\n고급 계획 도구가 사용 가능한 경우 의사 결정의 필요성에 대해 의문을 제기할 수 있습니다. 그러나 불확실성과 상호 작용이라는 두 가지 주요 측면은 주로 동적 객체의 존재로 인해 확률적인 성격을 환경으로 도입합니다. 상호 작용은 자율 주행의 가장 어려운 부분으로, 일반 로보틱스와 구별짓습니다. 자율 주행 차량은 길을 따라 다니는 것 뿐만 아니라 다른 요소들의 행동을 예측하고 반응하기 위해서도 해야 하므로 안전하고 효율적인 의사 결정이 필수적입니다.\n\n<div class=\"content-ad\"></div>\n\n결정적인(순수하게 기하학적인) 상호 작용이 없는 세계에서는 결정을 내리는 것이 불필요하며, 검색, 샘플링, 최적화를 통한 계획이 충분합니다. 3D XYT 공간에서의 무차별 검색은 일반적인 해결책으로 기능할 수 있습니다.\n\n대부분의 고전적인 자율 주행 스택에서는 예측한 뒤 계획을 세우는 접근 방식을 채택하며, 자아 차량과 다른 차량 사이의 제로 오더 상호 작용을 가정합니다. 이 접근 방식은 예측 출력을 결정론적으로 취급하며, 자아 차량이 이에 맞게 반응해야 함을 요구합니다. 이는 지나치게 보수적인 행동을 야기하며, ‘얼어붙은 로봇’ 문제를 잘 보여줍니다. 이러한 경우에는 예측이 전체 시공간 공간을 채우므로 혼잡한 상황에서의 차로 변경과 같은 행동이 불가능해지는데, 이는 인간이 더 효과적으로 처리하는 것입니다.\n\n확률적인 전략을 다루기 위해서는 마르코프 결정 과정(Markov Decision Processes, MDP) 또는 부분 관측 가능한 마르코프 결정 과정(Partially Observable Markov Decision Processes, POMDP) 프레임워크가 필수적입니다. 이러한 방식은 기하학에서 확률로의 초점을 옮겨 혼돈된 불확실성에 대응합니다. 교통 주체들이 합리적으로 행동하거나 적어도 노이지하게 합리적으로 행동한다고 가정하면, 결정을 통해 안전한 운전 복도를 창출할 수 있습니다.\n\n계획의 세 가지 중요한 목표 중 하나인 안전, 편의, 효율 중에서, 결정을 통해 주로 효율성이 향상됩니다. 보수적인 행동은 안전과 편의를 극대화할 수 있지만, 다른 도로 주체들과의 효과적인 협상은 결정을 통해야만 최적의 효율성을 달성할 수 있습니다. 효과적인 결정은 또한 지능을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n## MDP과 POMDP\n\n먼저 Markov Decision Processes (MDP) 및 Partially Observable Markov Decision Processes (POMDP)를 소개하고, 값 반복 및 정책 반복과 같은 체계적인 해결책을 살펴보겠습니다.\n\nMarkov Process (MP)는 정적인 확률이 아닌 동적인 랜덤 현상을 다루는 확률과정의 한 유형입니다. Markov Process에서 미래 상태는 현재 상태에만 의존하므로 예측에 충분합니다. 자율 주행의 경우, 관련 상태는 데이터의 마지막 1초만 포함할 수 있어 상태 공간을 확장하여 더 짧은 기록 창을 허용할 수 있습니다.\n\nMarkov Decision Process (MDP)는 Markov Process를 의사 결정을 포함시킴으로써 확장한 것입니다. MDP는 결과가 부분적으로 무작위이고 부분적으로 의사 결정자 또는 에이전트에 의해 제어되는 상황을 모델링합니다. MDP는 다섯 가지 요인으로 모델링될 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 상태 (S): 환경의 상태.\n- 행동 (A): 에이전트가 환경에 영향을 미치기 위해 취할 수 있는 행동.\n- 보상 (R): 환경이 행동의 결과로 제공하는 보상.\n- 전이 확률 (P): 에이전트의 행동에 따른 이전 상태에서 새로운 상태로 전이할 확률.\n- 감마 (γ): 미래 보상에 대한 할인 요소.\n\n이는 보상 학습 (RL)에서 주로 사용되는 일반적인 프레임워크이기도 한데, 본질적으로 MDP를 나타낸다. MDP 또는 RL의 목표는 장기적으로 누적된 보상을 최대화하는 것이다. 이를 위해 에이전트는 정책에 따라 환경으로부터 상태를 고려하여 좋은 결정을 내리도록 해야 한다.\n\n정책 π는 각 상태 s ∈ S와 행동 a ∈ A(s)에 대해 각각의 행동 a를 취할 확률 π(a|s)로 매핑하는 것이다. MDP 또는 RL은 최적 정책을 도출하는 문제에 대해 연구한다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_19.png)\n\n<div class=\"content-ad\"></div>\n\n파셜 옵저버블 마르코프 의사결정 프로세스(POMDP)는 상태가 직접 관찰되지 않고 옵저베이션을 통해 추론되는 복잡성을 추가합니다. POMDP에서 에이전트는 환경의 상태를 추정하기 위해 가능한 상태에 대한 확률 분포인 '신념'을 유지합니다. 자율 주행 시나리오는 환경의 부분적 가시성과 내재적 불확실성으로 인해 POMDP에 의해 더 잘 표현됩니다. 옵저베이션이 상태를 완벽하게 노출하는 특수한 경우인 MDP는 POMDP의 특별한 경우로 볼 수 있습니다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_20.png)\n\nPOMDP는 정보를 적극적으로 수집하여 필요한 데이터를 수집하는 행동을 이끌어내어 이러한 모델의 지능적인 행동을 나타낼 수 있습니다. 이 능력은 특히 교차로에서 대기하는 상황과 같은 시나리오에서 가치 있습니다. 다른 차량의 의도와 신호등의 상태에 대한 정보를 수집함으로써 안전하고 효율적인 결정을 내리는 데 중요하기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n가치 반복과 정책 반복은 MDP 또는 POMDP 문제를 해결하는 체계적인 방법입니다. 이러한 방법은 복잡성 때문에 실제 응용에서는 흔히 사용되지는 않지만, 이를 이해하면 정확한 해결책과 어떻게 간소화될 수 있는지에 대한 통찰력을 제공합니다. 예를 들어, 알파고의 MCTS 사용이나 자율 주행에서의 MPDM과 같은 방법이 실제 적용됩니다.\n\nMDP에서 최적 정책을 찾기 위해서는 상태에서 취하는 행동으로부터 발생하는 잠재적 또는 예상 보상을 평가해야 합니다. 이 예상 보상에는 즉각적인 보상 뿐만 아니라 미래 보상들까지 포함되는데, 이를 공식적으로는 반환 또는 누적 할인 보상이라고 합니다. (더 깊이 이해하기 위해서는 주제에 대한 권위적인 안내서로 여겨지는 \"강화 학습: 입문\"을 참고하세요.)\n\n가치 함수(V)는 예상된 반환을 합하여 상태의 품질을 특성화합니다. 행동 가치 함수(Q)는 주어진 상태에 대한 행동의 품질을 평가합니다. 두 함수 모두 특정 정책에 따라 정의됩니다. 벨만 최적 방정식은 최적 정책이 최대 보상을 찾아서 최적이 되는 새로운 상태에서의 즉각적인 보상과 예상 미래 보상을 최대화하는 행동을 선택할 것이라고 말합니다. 간단히 말해, 벨만 최적 방정식은 즉각적인 보상과 행동의 미래 결과를 고려할 것을 권장합니다. 예를 들어, 직장을 바꿀 때 새로운 직책이 제공하는 미래 가치(S') 뿐만 아니라 즉각적인 임금 인상(R)도 고려해야 합니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_21.png)\n\n<div class=\"content-ad\"></div>\n\n벨만 최적성 방정식으로부터 최적 정책을 추출하는 것은 최적 가치 함수가 있을 때 비교적 간단합니다. 하지만 이 최적 가치 함수를 어떻게 찾을까요? 이때 가치 반복이 구원을 줍니다.\n\n![Image Description](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_22.png)\n\n가치 반복은 각 상태의 가치를 안정화될 때까지 반복적으로 업데이트하여 최상의 정책을 찾습니다. 이 과정은 벨만 최적성 방정식을 업데이트 규칙으로 변환함으로써 유도됩니다. 궁극적으로, 최적 미래 상황을 활용하여 반복을 그 쪽 방향으로 유도하는 것입니다. 간단히 말해, \"김이 석숩시다(fake it until you make it)\"!\n\n![Image Description](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_23.png)\n\n<div class=\"content-ad\"></div>\n\n가치 반복은 유한 상태 공간에 대해 수렴이 보장됩니다. 상태에 할당된 초기 값에 관계없이 수렴합니다(자세한 증명은 RL의 성경을 참조하세요). 할인 요소(gamma)가 0으로 설정되면 즉각적 보상만 고려하므로 한 번의 반복 후에 수렴합니다. 보다 작은 gamma는 고려 범위가 짧아져 빠른 수렴을 이끌지만, 구체적인 문제 해결을 위한 최상의 옵션이 항상 되지는 않습니다. 할인 요소를 균형있게 설정하는 것이 엔지니어링 실무에서 중요합니다.\n\n모든 상태를 0으로 초기화했을 때 이 작동하는 방식에 대한 의문을 제기할 수 있습니다. 벨만 방정식의 즉각적 보상은 추가 정보를 가져오고 초기 대칭을 깨는 데 중요합니다. 목표 상태로 직접 이끄는 상태를 생각해보세요. 이들의 가치는 상태 공간을 통해 바이러스처럼 전파됩니다. 간단히 말해, 작은 승리를 자주 이루는 것입니다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_24.png)\n\n그러나 가치 반복은 비효율성도 갖습니다. 각 반복에서 모든 가능한 행동을 고려하여 최적 행동을 취해야 하므로 Dijkstra의 알고리즘과 유사합니다. 기본적인 접근 방식으로 실행 가능성을 보여줍니다만, 실제 응용 프로그램에는 typ이하지 않는 것이 일반적입니다.\n\n<div class=\"content-ad\"></div>\n\n경찰 조치는 현재 정책에 따라 행동을 취하고 벨만 방정식(벨만 최적 방정식이 아님)에 따라 업데이트하여 정책 개선을 하는 것으로 향상됩니다. 정책 반복은 정책 평가를 정책 개선과 분리하여 훨씬 빠른 해결책을 만들어 냅니다. 각 단계는 목적을 극대화하는 행동을 찾기 위해 모든 가능한 행동을 탐색하는 대신 주어진 정책을 기반으로 취합니다. 정책 반복의 각 반복은 정책 평가 단계 때문에 계산적으로 더 많을 수 있지만, 전반적으로 빠른 수렴으로 이어집니다.\n\n간단히 말하면 한 가지 행동의 결과를 완전히 평가할 수 있는 경우, 현재 정보를 활용하여 자신의 판단을 내리고 최선을 다하는 것이 좋습니다.\n\n## 알파고와 MCTS - 신경망과 트리가 만날 때\n\n<div class=\"content-ad\"></div>\n\n우리 모두는 2016년 알파고가 최고의 인간 플레이어를 이긴 놀라운 이야기를 들어왔습니다. 알파고는 바둑 게임을 MDP로 정의하고 몬테 카를로 트리 탐색(MCTS)으로 해결합니다. 하지만 왜 가치 반복이나 정책 반복을 사용하지 않을까요?\n\n가치 반복과 정책 반복은 MDP 문제를 해결하는 체계적이고 반복적인 방법입니다. 그러나 향상된 정책 반복을 사용해도 여전히 모든 상태의 가치를 업데이트하기 위한 시간 소모적인 작업이 필요합니다. 표준 19x19 바둑판은 대략 2e170개의 가능한 상태가 있습니다. 이 방대한 상태 수는 전통적인 가치 반복이나 정책 반복 기술로 해결하기 어렵게 만듭니다.\n\n알파고와 그 후속작품들은 가치 네트워크와 정책 네트워크에 기반을 둔 MCTS(Monte Carlo Tree Search) 알고리즘을 사용하여 움직임을 찾습니다. 이 네트워크는 인간과 컴퓨터 플레이에서 훈련을 받습니다. 먼저 일반적인 MCTS를 살펴보겠습니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_26.png)\n\n<div class=\"content-ad\"></div>\n\n**MCTS (Monte Carlo Tree Search)**은 현재 상태로부터의 의사 결정을 중점적으로 하는 정책 평가 방법입니다. 한 번의 반복은 선택, 확장, 시뮬레이션(또는 평가), 백업으로 구성됩니다.\n\n- **선택:** 알고리즘은 이전 시뮬레이션을 기반으로 가장 유망한 경로를 따라가며 미탐색 자식 노드인 리프 노드에 도달할 때까지 진행합니다.\n- **확장:** 리프 노드에서 다음 가능한 이동을 나타내는 하나 이상의 자식 노드가 추가됩니다.\n- **시뮬레이션(평가):** 알고리즘은 새로운 노드부터 랜덤 게임을 끝까지 진행하며 \"롤아웃\"이라고 알려진 것을 수행합니다. 이를 통해 무작위 이동을 시뮬레이션하여 종료 상태에 도달할 때까지의 잠재적 결과를 판단합니다.\n- **백업:** 알고리즘은 게임 결과를 기반으로 선택한 경로 상의 노드 값들을 업데이트합니다. 승리라면 노드 값이 증가하고, 패배라면 값이 감소합니다. 이 과정은 롤아웃 결과를 트리 위로 다시 전파시켜 시뮬레이션 결과에 기반한 정책을 개선합니다.\n\n일정한 반복 횟수 이후, MCTS는 시뮬레이션 중 루트에서 선택된 즉시 조치의 빈도를 제공합니다. 추론시에는 가장 많은 방문 횟수를 가진 조치가 선택됩니다. 이 글에서는 간편한 틱택토 게임을 통한 MTCS의 대화형 설명을 제공해드릴게요.\n\n알파고의 MCTS는 두 개의 신경망에 의해 향상됩니다. **Value Network**는 주어진 상태(판의 구성)의 승률을 평가합니다. **Policy Network**는 모든 가능한 이동에 대한 조치 분포를 평가합니다. 이러한 신경망들은 MCTS의 효과적인 깊이와 너비를 줄임으로써 개선을 이룹니다. 정책 신경망은 조치 샘플링에 도움을 주어 유망한 이동에 집중시키며, 가치 신경망은 포지션을 더 정확히 평가하여 롤아웃의 필요성을 줄입니다. 이 조합은 알파고가 바둑의 방대한 상태 공간에서 효율적이고 효과적인 탐색을 수행할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_27.png)\n\nIn the expansion step, the policy network samples the most likely positions, effectively pruning the breadth of the search space. In the evaluation step, the value network provides an instinctive scoring of the position, while a faster, lightweight policy network performs rollouts until the game ends to collect rewards. MCTS then uses a weighted sum of the evaluations from both networks to make the final assessment.\n\nWhat can we learn from AlphaGo for autonomous driving? AlphaGo demonstrates the importance of extracting an excellent policy using a robust world model (simulation). Similarly, autonomous driving requires a highly accurate simulation to effectively leverage algorithms similar to those used by AlphaGo. This approach underscores the value of combining strong policy networks with detailed, precise simulations to enhance decision-making and optimize performance in complex, dynamic environments.\n\n# MPDM (and successors) in autonomous driving\n\n<div class=\"content-ad\"></div>\n\n고의 게임에서는 모든 상태가 즉시 양쪽 플레이어에게 사용 가능하며, 관찰이 상태와 동일한 것으로 간주됩니다. 이는 게임이 MDP 프로세스에 의해 특징 지어질 수 있도록 합니다. 반면에 자율 주행은 관찰을 통해 상태를 추정할 수 있는 POMDP 프로세스입니다.\n\nPOMDP는 지각과 계획을 원칙적으로 연결하는 역할을 합니다. POMDP의 전형적인 해결책은 MDP와 유사하며, 제한된 탐색을 통해 이루어집니다. 그러나 주요 도전 과제는 차원의 저주(상태 공간의 증폭) 및 다른 에이전트와의 복잡한 상호작용에 있습니다. 실시간 진행을 가능하게 하기 위해 도메인 특정 가정이 보통 POMDP 문제를 단순화하는 데 사용됩니다.\n\nMPDM(및 두 가지 후속 조치, 그리고 화이트 페이퍼)는 이 방향으로의 선구적인 연구 중 하나입니다. MPDM은 POMDP를 유한하고 이산적인 의미 수준 정책 집합의 닫힌 루프 전방 시뮬레이션으로 축소시킵니다. 모든 차량에 대해 가능한 모든 제어 입력을 평가하는 대신 의미 있는 정책의 관리 가능한 수에 집중함으로써 차원의 저주를 다루며, 자율 주행 시나리오에서 효과적인 실시간 의사 결정을 가능케 합니다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_28.png)\n\n<div class=\"content-ad\"></div>\n\nMPDM(Multi-Policy Decision-Making)의 가정은 두 가지로 이루어져 있어요. 첫째, 인간 운전자의 많은 의사 결정은 이산적이고 고수준의 의미 있는 행동(예: 감속, 가속, 차선 변경, 정지)이 포함돼 있어요. 이러한 행동들은 이 문맥에서 정책이라고 불려지죠. 두 번째 암시적인 가정은 다른 주체들에 대한 것인데요: 다른 차량들은 합리적으로 안전한 결정을 내릴 것이라고 가정돼요. 한 차량의 정책이 결정되면, 그의 행동(궤적)도 결정돼요.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_29.png)\n\nMPDM은 먼저 여러 옵션 중에서 자아차량을 위한 한 가지 정책을 선택하고, 주변 에이전트 각각에 대해 예측에 기반한 한 가지 정책을 선택해요. 그런 다음에는 앞으로의 시뮬레이션을 수행해요(MCTS의 빠른 롤아웃과 유사하죠). 평가 후 가장 좋은 상호 작용 시나리오는 용적 및 시공간 계획 세션에서 언급된 SCC(Spatiotemporal Semantic Corridor)와 같은 모션 플래닝에 전달돼요.\n\nMPDM은 밀집된 교통 흐름 속으로 끼어드는 등 지능적이고 인간적인 행동을 가능하게 해줘요. 이러한 것은 상호 작용을 명시적으로 고려하지 않는 예측 후 계획 파이프라인에서는 불가능해요. MPDM의 예측 모듈은 앞으로의 시뮬레이션을 통해 행동 계획 모델과 긴밀하게 통합돼 있어요.\n\n<div class=\"content-ad\"></div>\n\nMPDM은 결정 기간(10초) 동안 하나의 정책을 가정합니다. 기본적으로, MPDM은 하나의 깊이를 가진 MCTS 방식을 채택하며, 모든 가능한 에이전트 예측을 고려합니다. 이로써 EUDM, EPSILON, MARC 등의 후속 연구 작업을 영감을 주는 여지가 남습니다. 예를 들어, EUDM은 더 유연한 자아 정책을 고려하고, 8초 동안의 결정 기간에 대해 2초씩 시간 간격을 갖는 네 계층의 정책 트리를 할당합니다. 증가된 트리 깊이에 따른 추가 계산을 보상하기 위해, EUDM은 전담 분기에 의한 더 효율적인 넓이 가지치기를 수행하며, 중요한 상황과 주요 차량을 식별합니다. 이 방식은 더 균형 잡힌 정책 트리를 탐색합니다.\n\nMPDM과 EUDM의 전방 시뮬레이션에는 매우 간단한 운전자 모델(Intelligent driver model 또는 IDM은 종방향 시뮬레이션에, Pure Pursuit 또는 PP는 측방향 시뮬레이션에 사용됩니다). MPDM은 고충실도 현실성이 클로즈드 루프 특성 자체보다는 정책 수준의 결정이 낮은 수준의 행동 실행 부정확성에 영향을 받지 않는 한 중요하지 않다고 지적합니다.\n\n![An Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_30.png)\n\n자율 주행의 맥락에서의 비상 대책 수립은 다양한 가능한 미래 시나리오를 고려하여 여러 잠재적인 궤적을 생성하는 것을 포함합니다. 경험 많은 운전자가 많은 미래 시나리오를 예측하고 항상 안전한 예비 계획을 세우는 것이 주요 동기부여 예시입니다. 이 예상 방식은, 다른 차량이 자신의 차로로 갑자기 차로 변경하는 상황에서도 더 부드러운 운전 경험으로 이어집니다.\n\n<div class=\"content-ad\"></div>\n\n긴급 상황 대비 계획에서 중요한 측면 중 하나는 의사 결정 이분화 지점을 연기하는 것입니다. 이는 서로 다른 잠재적 궤적이 분기되는 지점을 지연시켜, 자아 차량이 정보를 수집하고 다양한 결과에 대응할 시간을 더 많이 확보하도록 하는 것을 의미합니다. 이를 통해 차량은 더 많은 정보를 바탕으로 한 결정을 내릴 수 있으며, 이는 숙련된 운전자와 유사한 부드럽고 자신감 있는 운전 행동을 낳을 수 있습니다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_31.png)\n\nMPDM 및 이에 따르는 모든 연구들의 한 가지 가능한 단점은 고속도로와 유사한 구조화된 환경을 위해 설계된 간단한 정책에 의존한다는 점입니다. 이러한 의존은 전방 시뮬레이션의 복잡한 상호 작용을 처리하는 능력을 제한할 수 있습니다. 이를 해결하기 위해 MPDM의 예를 따라, POMDP를 더 효과적으로 만드는 핵심은 고수준 정책 트리의 성장을 통해 행동 및 상태 공간을 단순화하는 것입니다. 공간적 및 시간적 상대 위치 태그를 모든 상대 대상에 대해 열거하고 이후 지도된 가지를 실행함으로써, 더 유연한 정책 트리를 만들 수도 있습니다.\n\n# 의사 결정 산업 실천법\n\n<div class=\"content-ad\"></div>\n\nDecision-making이 현재 연구에서 핫한 주제입니다. 심지어 고전적인 최적화 방법조차 완전히 탐구되지 않은 상태입니다. 머신러닝 방법들은 특히 대형 언어 모델 (LLMs)의 등장과 Chain of Thought (CoT) 또는 Monte Carlo Tree Search (MCTS)와 같은 기법으로 더욱 빛을 발할 수 있습니다.\n\n## Trees\n\nTrees는 의사결정을 수행하는 체계적인 방법입니다. Tesla AI Day 2021 및 2022에서는 AlphaGo와 그 후속인 MuZero에 크게 영향받은 결정 능력을 선보였습니다. 이를 통해 매우 복잡한 상호작용을 다룰 수 있었습니다.\n\n높은 수준에서 Tesla의 접근 방식은 행동 계획 (의사결정) 이후 모션 계획을 따릅니다. 먼저 볼록한 통로를 탐색하고 그 후 공간적-시간적 공동 계획을 사용하여 연속 최적화에 투입합니다. 이 방식은 좁은 통과와 같은 시나리오를 효과적으로 해결합니다. 해당 시나리오는 경로 속도 분리 계획의 전형적인 병목 현상입니다.\n\n<div class=\"content-ad\"></div>\n\n이미지 태그를 Markdown 형식으로 변경해주세요.\n\n*Tesla*는 데이터 주도와 물리학 기반 체크를 결합한 하이브리드 시스템을 채용하고 있습니다. 명확한 목표로 시작하여, Tesla 시스템은 초기 경로를 생성하고 주요 시나리오를 평가합니다. 그런 다음, 교통 요소에 대해 주장하거나 양보하는 등의 시나리오 변형을 만들기 위해 나무 기반 시나리오 트리를 확장합니다. 이러한 정책 트리 상의 상호 작용 검색은 2021년과 2022년의 발표에서 소개되었습니다.\n\nTesla의 기계 학습 사용 중 하나의 하이라이트는 경로 최적화를 통한 트리 탐색 가속화입니다. 각 노드에 대해 Tesla는 물리학 기반 최적화와 신경 기반 플래너를 사용하여, 100 마이크로초 대비 10 밀리초의 시간 프레임을 달성합니다 — 이는 10배에서 100배의 개선을 가져옵니다. 신경망은 전문가 시범과 오프라인 최적화 프로그램으로 교육됩니다.\n\n충돌 검사와 안락성 분석과 같은 고전적인 물리학 기반 검사를 신경망 평가자와 결합하여 진입 확률 및 인간과 유사한 정도를 예측하는 신경망 평가자를 만듭니다. 이 점수는 검색 공간을 가지치기하여 가장 유망한 결과에 계산을 집중함으로써 도와줍니다.\n\n<div class=\"content-ad\"></div>\n\n많은 사람들이 기계 학습이 고수준 의사 결정에 적용되어야 한다고 주장하는 반면, 테슬라는 ML을 기본적으로 최적화를 가속화하고 결과적으로 트리 탐색을 진행하는 데에 활용합니다.\n\n몬테 카를로 트리 탐색(Monte Carlo Tree Search, MCTS) 방법은 의사 결정에 궁극적인 도구로 보입니다. 흥미롭게도, 대규모 언어 모델(Large Language Models, LLMs)을 연구하는 사람들은 MCTS를 LLM에 통합하려고 하고, 자율 주행을 연구하는 사람들은 MCTS를 LLM으로 교체하려고 노력하고 있습니다.\n\n약 2년 전까지 테슬라의 기술은 이러한 접근 방식을 따랐습니다. 그러나 2024년 3월 이후로, 테슬라의 완전 자율 주행(Full Self-Driving, FSD) 기술은 이전 방법과는 크게 다른, 보다 end-to-end 접근 방식으로 전환했습니다.\n\n# 나무 없어요\n\n<div class=\"content-ad\"></div>\n\n나무를 자라게 하는 암묵적 상호작용을 고려할 수 있습니다. 미리 예측하고 계획 수립 간에 일차 상호작용을 수행하기 위해 이삭 논리를 구현할 수 있습니다. 한 차수의 상호작용만으로도 이미 훌륭한 행동을 발생시킬 수 있음을 TuSimple의 시연에서 확인할 수 있습니다. MPDM은 본래 한 차수 상호작용이지만 더 원칙적이고 확장 가능한 방식으로 실행됩니다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_33.png)\n\nTuSimple은 사고 대비 계획을 수행할 수 있는 능력을 시연했습니다. 이는 MARC에서 제안된 접근 방식과 유사하지만 (MARC는 사용자 정의 위험 선호도에 대응할 수도 있습니다). \n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_34.png)\n\n<div class=\"content-ad\"></div>\n\n# 자기 성찰\n\n고전 계획 시스템의 기본 구성 요소를 배운 후, 행동 계획, 동작 계획, 그리고 상호작용을 처리하는 원칙적인 방법에 대해 깊이 생각해 보았습니다. 시스템 내의 잠재적인 병목 현상과 기계 학습(ML) 및 신경망(NN)이 어떻게 도움이 될 수 있는지를 고찰 중에 있습니다. 여기에 제 생각 과정을 문서화하여 나중에 참고하고 유사한 궁금증을 가진 다른 사람에게도 도움이 되기를 바랍니다. 이 섹션의 정보에는 개인적인 편향과 추측이 포함될 수 있다는 점을 참고하세요.\n\n# 계획에서 왜 신경망?\n\n기존 모듈화된 파이프라인, e2e NN 계획자로서, 또는 e2e 자율 주행 시스템으로서 문제를 세 가지 다른 관점에서 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n그림판으로 다시 돌아가 볼까요? 자율 주행 시스템의 계획 시스템의 문제 정의를 검토해 봅시다. 목표는 차량 내의 실시간 엔지니어링 제약 조건을 준수하면서 매우 불확실하고 상호 작용적인 환경에서 안전, 편안함 및 효율성을 보장하는 궤적을 얻는 것입니다. 이러한 요소들은 아래 차트에 목표, 환경 및 제약 조건으로 요약되어 있습니다.\n\n![이미지](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_35.png)\n\n자율 주행에서의 불확실성은 지각 (관찰)과 미래의 장기 에이전트 행동을 예측하는 데 불확실성을 가리킬 수 있습니다. 계획 시스템은 또한 다른 에이전트의 미래 궤적 예측의 불확실성을 처리해야 합니다. 이전에 논의한 대로, 원칙에 따른 의사 결정 시스템은 이를 관리하는 효과적인 방법입니다.\n\n게다가 일반적으로 간과되는 측면은 현재 시대의 시각 중심 및 HD지도 없이 운전하는 시대에 특히 불확실하고 불완전한 지각 결과를 견딜 수 있는 계획이어야 한다는 것입니다. SD 지도를 선행으로 가지고 있는 것은 이 불확실성을 완화해 주지만, 여전히 강하게 수작업된 계획 시스템에 상당한 어려움을 야기합니다. 이 지각 불확실성은 리다 및 HD지도의 적극적인 활용을 통해 레벨 4 (L4) 자율 주행 회사들에 의해 해결된 문제로 간주되었습니다. 그러나 이 두 지주 없이 대량 생산 자율 주행 솔루션으로 이동하는 산업은 이 문제가 재부각되고 있습니다. NN 계획자는 주로 불완전하고 불완전한 지각 결과를 처리할 수 있어 대량 생산을 위한 시각 중심 및 HD지도 없는 고급 운전자 지원 시스템 (ADAS)에 필수적인 것입니다.\n\n<div class=\"content-ad\"></div>\n\n상호 작용은 몬테 카를로 트리 탐색(Monte Carlo Tree Search, MCTS)나 MPDM의 간소화된 버전과 같은 원칙적인 의사 결정 시스템으로 다뤄져야 합니다. 주요 도전 과제는 자율 주행의 도메인 지식을 통해 스마트한 제거를 통해 균형있게 정책 트리를 성장시켜 조합폭발의 문제(차원의 저주)를 처리하는 것입니다. MPDM 및 해당 변형은 학계와 산업(Tesla 등)에서 이러한 균형있게 트리를 성장시키는 방법의 좋은 예를 제공합니다.\n\n또한 신경망(NNs)은 모션 계획 최적화를 가속화하여 실시간 성능을 향상시킬 수 있습니다. 이렇게 하면 CPU에서 GPU로 컴퓨팅 부하를 옮기며 몇 배나 속도를 향상할 수 있습니다. 최적화 속도의 10배 증가는 MCTS와 같은 고수준 알고리즘 설계에 근본적인 영향을 미칠 수 있습니다.\n\n궤적은 인간다운 모습을 더해야 합니다. 인간다운 속성 및 운전 대처 예측 모델은 이용 가능한 방대한 인간 운전 데이터를 사용하여 훈련될 수 있습니다. 컴퓨팅 풀을 확대하는 것이 지속적으로 늘어나는 엔지니어링 인재 대규모 유지보다 확장 가능성이 더 높습니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_36.png)\n\n<div class=\"content-ad\"></div>\n\n# 엔드 투 엔드(End-to-End) 신경망(Neural Network) 플래너는 어떤가요?\n\n엔드 투 엔드(End-to-End) 신경망(Neural Network) 플래너는 여전히 모듈식 자율 주행(AD) 디자인을 구성하며, 구조화된 인식 결과(그리고 잠재적으로 잠복한 특징)를 입력으로 받습니다. 이 접근 방식은 예측, 판단 및 계획을 단일 네트워크로 결합합니다. DeepRoute(2022)와 Huawei(2024)와 같은 기업들이 이 방법을 활용한다고 주장합니다. 중요한 생 센서 입력(예: 내비게이션 및 자동차 정보)은 여기서 생략되었습니다.\n\n![이미지](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_37.png)\n\n이 엔드 투 엔드 플래너는 더 나아가 인식과 계획을 모두 결합한 엔드 투 엔드 자율 주행 시스템으로 발전시킬 수 있습니다. Wayve의 LINGO-2(2024)와 Tesla의 FSDv12(2024)가 이를 성취한다고 주장하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이 접근 방식의 이점은 두 가지로 나뉩니다. 첫째, 이는 인식 문제에 대처합니다. 주로 사용되는 인식 인터페이스로 명확하게 모델링하지 못하는 운전의 여러 측면이 있습니다. 예를 들어, 물 웅덩이를 피하기 위해 주행 시스템을 손수 조정하거나 웅덩이나 틈새에 대비해 속도를 줄이는 것은 매우 어렵습니다. 중간 인식 기능을 통과할 수 있지만, 이는 근본적인 문제를 해결하지 못할 수도 있습니다.\n\n더불어 발생하는 행동은 모든 상황을 보다 체계적으로 해결하는 데 도움이 될 것입니다. 위의 예시와 같이 경계 케이스를 지혜롭게 처리하는 것은 대규모 모델의 발생적 행동에서 나올 수 있습니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_38.png)\n\n내 추측으로, 최종 형태의 엔드 투 엔드 (e2e) 운전자는 대규모 비전 및 액션-네이티브 멀티모달 모델이라고 생각됩니다. 계산 제약이 없다면 몬테 카를로 트리 탐색 (MCTS)로 강화할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n자율 주행의 세계 모델은 2024년을 기준으로 주로 비전 및 행동 모드(또는 VA 모델)를 다루는 다중 모달 모델입니다. 언어는 훈련 가속화, 제어 가능성 추가, 설명 가능성 제공에 도움이 될 수 있지만 필수적이지는 않습니다. 세계 모델의 최종 형태는 VLA(비전-언어-행동) 모델이 될 것입니다.\n\n세계 모델을 개발하는 데는 적어도 두 가지 접근 방식이 있습니다:\n\n- 비디오 네이티브 모델: 미래 비디오 프레임을 예측하도록 모델을 훈련시키고, 관련 행동에 조건을 걸거나 출력하는 방식으로, GAIA-1과 같은 모델에서 시연된 것처럼.\n- 다중 모달 어댑터: 사전 훈련된 대형 언어 모델(LLM)을 시작으로 하고, Lingo-2, RT2, ApolloFM과 같은 모델에서 볼 수 있듯이 다중 모달 어댑터를 추가합니다. 이러한 다모달 LLM은 비전이나 액션에 원시적이지 않지만 훈련 리소스를 훨씬 적게 필요로 합니다.\n\n세계 모델은 액션 출력을 통해 정책을 직접 생성하여 차량을 운전할 수 있게 합니다. 또는 MCTS는 세계 모델에 쿼리를 하고 해당 정책 출력을 사용하여 탐색을 안내할 수 있습니다. 이 세계 모델-MCTS 접근 방식은 계산이 많이 필요하지만 명시적 추론 논리로 인해 모서리 사례를 처리하는 능력이 높을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 예측 없이도 가능할까요?\n\n현재의 대부분의 모션 예측 모듈은 중심 차량 이외의 요소들의 미래 궤적을 하나 이상의 이산적 궤적으로 표현합니다. 이 예측-계획 인터페이스가 충분하거나 필요한지 여전히 의문입니다.\n\n고전적인 모듈식 파이프라인에서는 여전히 예측이 필요합니다. 그러나 예측 후 계획 파이프라인은 자율 주행 시스템의 상한선을 근거하며 의사 결정 세션에서 논의된 바 있습니다. 더 중요한 질문은 이 예측 모듈을 전체 자율 주행 스택에 더 효과적으로 통합하는 방법입니다. 예측은 의사 결정을 지원해야 하며 MPDM 및 그 변형본과 같은 전체적인 의사 결정 프레임워크 내에서 쿼리 가능한 예측 모듈이 선호됩니다. 정책 트리 롤아웃을 통해 정확하게 통합된 경우와 같이 구체적인 궤적 예측에 심각한 문제가 없습니다.\n\n예측의 다른 문제는 평균 이동 오차 (ADE) 및 최종 이동 오차 (FDE)와 같은 열린 루프 핵심 성과 지표(KPI)가 계획에 미치는 영향을 반영하지 못하는 비효과적인 측정 기준입니다. 대신 의도 수준에서의 재현율과 정밀도와 같은 지표를 고려해야 합니다.\n\n<div class=\"content-ad\"></div>\n\nIn an end-to-end system, having a separate prediction module may not always be required. However, incorporating implicit supervision, along with other domain knowledge from a traditional stack, can definitely enhance or improve the data efficiency of the learning system. It is also beneficial to evaluate the prediction behavior, whether it is explicit or implicit, to help debug such an end-to-end system.\n\n## Can we rely solely on neural networks without using tree structures?\n\nLet's start with the conclusions. Neural networks (nets) can achieve very high, even superhuman, performance for an assistant role. In the case of agents, having a tree structure can still be advantageous, although not always mandatory.\n\nFirst and foremost, trees can complement neural networks. Trees can elevate the performance of a network, whether it is based on neural networks or not. In the case of AlphaGo, despite training a policy network through supervised and reinforcement learning, the overall performance was still outperformed by the Monte Carlo Tree Search (MCTS)-based AlphaGo, which integrates the policy network as one of its components.\n\n<div class=\"content-ad\"></div>\n\n둘째로, 나무를 증류할 수 있는 네트워크가 있습니다. 알파고에서 MCTS는 트리에서 노드(상태 또는 보드 위치)를 평가하기 위해 가치 네트워크와 빠른 롤아웃 정책 네트워크로부터 보상을 사용했습니다. 알파고 논문에는 가치 함수만 사용할 수 있지만, 두 가지 결과를 결합하는 것이 최상의 결과를 얻는다고 언급되었습니다. 가치 네트워크는 정책 롤아웃으로부터 지식을 증류하며 상태-가치 쌍을 직접 배우는 역할을 합니다. 이는 인간이 느린 시스템 2의 논리적 사고를 빠른 직관적인 시스템 1의 반응으로 증류하는 방식과 유사합니다. 다니엘 칸만의 “사고, 빠르고 느린” 책에서는 체스 마스터가 연습을 통해 빠르게 패턴을 인식하고 신속한 결정을 내리는 능력을 키울 수 있다고 설명합니다. 반면 초보자는 유사한 결과를 얻으려면 상당한 노력이 필요합니다. 마찬가지로 알파고의 가치 네트워크는 주어진 보드 위치의 신속한 평가를 제공하기 위해 훈련되었습니다.\n\n![Image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_39.png)\n\n최근 논문들은 신경망을 사용한 이 빠른 시스템의 상한선을 탐구합니다. “탐색 없는 체스” 논문은 충분한 데이터(기존 알고리즘을 사용하여 트리 탐색을 통해 준비된)로 그랜드마스터 수준의 능력을 달성할 수 있다는 것을 보여줍니다. 데이터 및 모델 크기와 관련된 명확한 “스케일링 법칙”이 있으며, 데이터 및 모델 복잡성이 증가함에 따라 시스템의 능력도 증가한다는 것을 나타냅니다.\n\n그래서 우리는 나무가 네트를 향상시키고, 네트가 나무를 증류한다는 강력한 조합을 가지고 있습니다. 이 긍정적 피드백 루프는 알파제로가 다중 게임에서 초인적인 성과에 이르기 위해 부스트하는 데 사용하는 핵심 요소입니다.\n\n<div class=\"content-ad\"></div>\n\n대형 언어 모델(Large Language Models, LLM) 개발에도 동일한 원칙이 적용됩니다. 게임에서 우리는 승리 또는 패배와 같이 명확히 정의된 보상을 가지고 있기 때문에 특정 작업이나 상태의 가치를 결정하기 위해 전방 롤아웃을 사용할 수 있습니다. 그러나 LLM에서는 보상이 바둑 게임처럼 명확하게 정의되어 있지 않기 때문에 인간의 선호도를 통해 모델을 평가하기 위해 인간 피드백을 활용한 강화 학습(RLHF)을 의존합니다. 그러나 ChatGPT와 같이 이미 훈련된 모델을 사용할 경우 감독된 세밀 조정(Supervised Fine-tuning, SFT)을 사용하여 여전히 강력한 모델을 RLHF 없이도 축소할 수 있습니다.\n\n원래 질문으로 돌아가서, 대량의 고품질 데이터를 사용하면 네트워크는 매우 뛰어난 성능을 낼 수 있습니다. 이는 오류 허용에 따라 비서로서 충분할 수 있지만, 자율 에이전트로서 충분하지 않을 수도 있습니다. 주행 보조 시스템(Advanced Driver Assistance Systems, ADAS)을 대상으로 하는 시스템의 경우, 모방 학습을 통한 네트워크가 적합할 수 있습니다.\n\n나무는 명시적 추론 루프를 통해 네트워크의 성능을 크게 향상시킬 수 있으며, 완전 자율 에이전트에게 더 적합할 수 있습니다. 나무 또는 추론 루프의 범위는 공학 리소스에 대한 투자 수익에 따라 다릅니다. 예를 들어, 상호 작용의 수준이 한 단계만 높아져도 TuSimple AI Day에서 확인된 대로 상당한 이점을 제공할 수 있습니다.\n\n# LLM을 사용하여 결정을 내릴 수 있을까요?\n\n<div class=\"content-ad\"></div>\n\n가장 뜨거운 인공 지능 시스템 대표들의 요약을 보면, LLMs는 의사 결정을 수행하도록 설계되지 않았다는 것을 알 수 있습니다. 본질적으로 LLMs는 문서 작성을 위해 훈련되었으며, 심지어 SFT와 일치시킨 LLM 보조 시스템은 대화를 특별한 종류의 문서로 취급합니다(대화 기록 완성).\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_40.png)\n\n최근 LLMs가 느린 시스템(System 2)이라는 주장에 완전히 동의하지는 않습니다. 하드웨어 제약으로 추론에서 불필요하게 느릴 수는 있지만, 그들의 원형인 LLMs는 대안 가능성 확인을 수행할 수 없기 때문에 빠른 시스템입니다. Chain of Thought (CoT)나 Tree of Thoughts (ToT)와 같은 프롬프팅 기술은 실제로 MCTS의 단순화된 형태로, LLMs가 더 느린 시스템처럼 기능하도록 만듭니다.\n\nLLMs에 완전한 MCTS를 통합하려는 많은 연구가 진행 중입니다. 구체적으로, LLM-MCTS(NeurIPS 2023)는 LLM을 상식적인 \"세계 모델\"로 취급하고, LLM으로 인한 정책 행동을 탐색을 안내하는 휴리스틱으로 사용합니다. LLM-MCTS는 복잡하고 새로운 작업에 대해 MCTS만큼이나 LLM에 의한 정책보다 훨씬 우월한 성능을 보입니다. OpenAI의 높은 관심을 받고 있는 Q-star도 LLMs를 MCTS로 강화하는 동일한 접근 방식을 따르는 것으로 보입니다.\n\n<div class=\"content-ad\"></div>\n\n# 진화의 흐름\n\n자율주행에서의 계획 스택이 발전하는 과정을 간략하게 소개해드리겠습니다. 이는 상기된 솔루션이 위에 나열된 것들보다 반드시 더 발전된 것은 아니며, 그들의 등장은 정확한 연대순서를 따르지 않을 수 있기 때문에 초안입니다. 그럼에도 불구하고, 우리는 일반적인 추세를 관찰할 수 있습니다. 산업에서 소개된 대표적인 솔루션들은 다양한 보도 자료를 토대로 제 해석을 통해 나열하였으며, 오류의 가능성이 있음을 알려드립니다.\n\n하나의 추세는 보다 종단간 디자인으로의 이동입니다. 여러 모듈이 하나로 통합된 디자인으로 스택이 경로-속도 분리 계획에서 공간-시간적 공동계획으로 진화되고, 예측 후 계획 시스템에서 공동 예측 및 계획 시스템으로 진화합니다. 다른 하나의 추세는 머신러닝 기반 컴포넌트의 증가로, 특히 마지막 세 단계에서 나타납니다. 이 두 가지 추세는 종단간 뉴럴네트워크(NN) 플래너(인식 없음)로 수렴하거나 심지어 종단간 NN 운전자(인식 포함)로 나아갑니다.\n\n![image](/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_41.png)\n\n<div class=\"content-ad\"></div>\n\n# 핵심 포인트\n\n- ML은 도구로서의 역할: 머신 러닝은 독립적인 해결책이 아닌 도구로서의 역할을 합니다. 현재의 모듈식 설계에도 계획 수립에 도움을 줄 수 있습니다.\n- 완전한 문제 정식화: 문제의 완전한 정식화로 시작한 후 성능과 자원의 균형을 맞추기 위해 합리적인 가정을 하세요. 이는 미래 지향적인 시스템 설계를 만들어주고 자원이 증가함에 따라 개선되도록 합니다. POMDP의 정식화에서 AlphaGo의 MCTS 및 MPDM과 같은 엔지니어링 솔루션으로의 전환을 상기해 보세요.\n- 알고리즘 적응: 이론적으로 아름다운 알고리즘(Dijkstra 및 Value Iteration 등)들은 개념을 이해하는 데에 큰 도움이 되지만 실용적 엔지니어링에 적응이 필요합니다 (Value Iteration을 MCTS로, Dijkstra의 알고리즘을 Hybrid A-star로). \n- 결정론적 vs. 확률적: 계획은 결정론적(필연적으로 정적이지는 않음)인 상황을 해결하는 데 강점을 보입니다. 확률적 상황에서의 결정은 완전 자율주행으로 나아가는 데 가장 어려운 과제입니다.\n- 비상 대비 계획: 여러 가지 미래를 공통 조치로 병합하는 데 도움이 됩니다. 항상 대비 계획으로 되짚을 수 있도록 적극적으로 대응하는 것이 유익합니다.\n- End-to-end 모델: End-to-end 모델이 완전 자율주행을 해결할 수 있는지 여전히 불분명합니다. MCTS와 같은 고전적인 방법이 여전히 필요할 수 있습니다. 신경망은 보조 역할을 다룰 수 있으며, 트리는 에이전트를 관리할 수 있습니다.\n\n# 감사의 글\n\n- 본 블로그 글은 Dr. Wenchao Ding의 Shenlan Xueyuan (深蓝学院)에서의 계획 강좌에 큰 영감을 받았습니다.\n- Naiyan Wang 및 Jingwei Zhao와의 적극적이고 영감을 주는 토론에 감사드립니다. 초기 초안에 중요한 피드백을 주신 论文推土机, Invictus, XXF, PYZ 및 JCL에게 감사드립니다. 학계의 동향에 관한 Insightful한 토론을 했던 버클리 대학의 Wei Zhan 교수에게도 감사드립니다.\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n- 자율 주행의 최종 계획: 산업과 학계에서의 2022-2023, Arxiv 2024\n- BEVGPT: 자율 주행 예측, 의사 결정 및 계획을 위한 대규모 사전 훈련된 모델, AAAI 2024\n- 유체 역학을 활용한 자율 주행을 위한 일반적인 운동 계획에 대한 연구, Arxiv 2024\n- Bilibili에서 영어 자막이 제공되는 중국어로 Tusimple AI day, 2023년 07월\n- Zhihu에서 공개된 중국어에서의 Qcraft의 공간시간 연관 계획 기술 블로그, 2022년 08월\n- Zhihu에 공개된 중국어에서 전체 자율 주행 스택에 대한 리뷰, 2018년 12월\n- Zhihu에 공개된 중국어에서 Tesla AI Day Planning, 2022년 10월\n- Tsinghua AIR이 작성한 중국어 ApolloFM 기술 블로그, 2024년\n- Frenet Frame에서 동적 거리 상황을 위한 최적 궤적 생성, ICRA 2010\n- 이미지 인코딩을 위한 Lift, Splat, Shoot: 임의의 카메라 장치에서 3D로 암시적으로 투영, ECCV 2020\n- CoverNet: 궤적 세트를 사용한 다중 모달 행동 예측, CVPR 2020\n- 2020년 CVPR에서 발표된 NMP: 최종 해석 가능한 신경 움직임 플래너\n- 2021년 CVPR에서 발표된 MP3: 매핑, 인식, 예측 및 계획을 위한 통합 모델\n- Baidu Apollo EM Motion Planner, 2018년, Baidu\n- AlphaGo: 깊은 신경망과 트리 탐색을 통해 바둑을 마스터함, Nature 2016\n- AlphaZero: 자가 대국을 통해 체스, 쇼기 및 바둑을 마스터하는 일반적인 강화 학습 알고리즘, Science 2017\n- MuZero: 배워진 모델을 사용하여 Atari, 바둑, 체스 및 쇼기를 마스터하는 것, Nature 2020\n- NeurIPS 2023 Oral 논문인 ToT: Tree of Thoughts: 대규모 언어 모델을 통한 의도적 문제 해결\n- NeurIPS 2022에서 발표된 CoT: Chain-of-Thought 프롬프팅이 대규모 언어 모델에서 추론을 유도함\n- NeurIPS 2023에서의 LLM-MCTS: 대규모 언어 모델을 통한 상식적 지식의 대규모 작업 계획\n- ICRA 2015의 MPDM: 자율 주행을 위한 동적, 불확실한 환경에서의 다중 정책 의사 결정\n- RSS 2015의 MPDM2: 자율 주행을 위한 Changepoint 기반 행동 예측을 통한 다중 정책 의사 결정\n- RSS 2017의 MPDM3: Changepoint 기반 행동 예측을 통한 자율 주행을 위한 다중 정책 의사 결정: 이론 및 실험\n- ICRA 2020의 EUDM: 안내 분기를 통한 자동주행을 위한 효율적인 불확실성 인식 의사 결정\n- RAL 2023의 MARC: 자율 주행을 위한 다중 정책 및 위험 인지 대비 계획\n- TRO 2021의 EPSILON: 고도 상호 작용 환경에서의 자동차를 위한 효율적인 계획 시스템","ogImage":{"url":"/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_0.png"},"coverImage":"/assets/img/2024-06-30-ACrashCourseofPlanningforPerceptionEngineersinAutonomousDriving_0.png","tag":["Tech"],"readingTime":45},{"title":"자동차 시험 자동 인공지능 기반 테스트 데이터 평가","description":"","date":"2024-06-20 06:51","slug":"2024-06-20-AutomotiveTestingAutomaticAIbasedTestDataEvaluation","content":"\n\n## F1 텔레메트리 데이터 예시: 비지도 학습으로 시계열 전처리하기\n\n# TLDR\n\n차량을 테스트할 때 많은 양의 시계열 데이터가 생성됩니다. AI 방법을 사용하여 이러한 데이터를 전처리하고 중요한 섹션을 자동으로 표시할 수 있습니다. 이는 지도 학습이나 훈련 레이블이 필요하지 않은 비지도 학습 방법을 사용하여 수행할 수 있습니다. 시계열 데이터를 유사성에 기반하여 분석하여 데이터를 구조화하고 사용자에게 대화형 시각화를 제공할 수 있습니다.\n\n애니메이션에서는 Formula 1 레이스의 텔레메트리 데이터를 사용하여 이러한 유사성 기반 분석의 예시가 보여집니다. 각 완료된 랩 후, 이전 랩에서의 모든 데이터가 평가되며 RPM 프로필에 대한 유사성 맵을 기반으로 점수가 계산됩니다. 시간이 지남에 따라 패턴이 보이며, 이를 통해 이상 이벤트를 식별하고 그를 자세히 검토할 수 있는 정보를 얻을 수 있게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 소개: 자동차 시험에서의 도전\n\n안전하고 편안한 차량을 개발하기 위해 테스트는 필수적입니다. 그러나 CAN-Bus로부터 생성된 측정 및 원격 측정 데이터, 그리고 센서 데이터와 오디오 녹음은 채널이 많고 측정 시간이 길고 다양한 시험 변형이 있기 때문에 매우 방대합니다. NVH(소음, 진동 및 단단함), 동력 전달계, E/E 통합(전기 및 전자 통합), ADAS(고급 운전자 지원 시스템) 또는 수동 안전과 같은 다양한 시험 절차로부터의 데이터를 효율적으로 평가하는 것이 신속한 차량 개발에 중요합니다.\n\n# 자동차 시험을 위한 AI 솔루션\n\n때로는 간단한 규칙 기반 방법만 사용하여 데이터를 자동으로 전처리하고 작업 부담을 줄일 수 있습니다. 하지만 보통은 비정상적인 사건을 찾기 위해 수동, 경험 기반 작업이 필요합니다. 이를 자동으로 전처리함으로써 시간을 단축할 수 있습니다. 시험 데이터 평가를 위한 두 가지 AI 접근 방식은 후보 사건을 찾아내고 그 중요도에 따라 정렬하는 데 구분될 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n지도 학습 AI 방법: 이미 발생한 이벤트에 대한 레이블이 지정된 평가 데이터가 있는 경우, 해당 데이터에서 브레이크 괭이와 같은 특정 이벤트를 감지하기 위해 지도 학습 AI 방법을 훈련하는 것이 유용할 수 있습니다.\n\n비지도 학습 AI 방법: 이러한 방법은 레이블링이나 훈련 없이 데이터를 구조화할 수 있습니다.\n\n- 클러스터링: 비슷한 데이터 포인트가 클러스터로 그룹화됩니다. 이를 통해 예를 들어 각 클러스터의 몇 가지 대표적인 멤버만 검토하여 시간을 절약하는 등 데이터의 공통점을 효율적으로 활용할 수 있습니다.\n- 차원 축소: UMAP과 같은 차원 축소 방법을 사용하여 고차원 데이터를 저차원 표현으로 투영할 수 있습니다. 예를 들어 시계열 데이터를 보간하고 UMAP을 사용하여 2D 이미지로 투영하여 시각적인 표현을 만들 수 있습니다. 지역적 및 전역적 구조가 최대한 보존됩니다.\n\n# 자동차 테스트를 위한 차원 축소: F1 텔레메트리 예시\n\n<div class=\"content-ad\"></div>\n\n차원 축소 과정은 몇 줄의 코드로 복제할 수 있어요:\n\n먼저 환경을 설정해보세요: Jupyter Notebook을 시작하고 필요한 Python 패키지를 설치해주세요:\n\n\n!pip install fastf1 pandas umap-learn renumics-spotlight\n\n\n다음 패키지들을 사용할 거에요:\n\n<div class=\"content-ad\"></div>\n\n- FastF1: Python library for easy access to historical F1 data — including telemetry and race results.\n- Pandas: Python library for data analysis.\n- umap-learn: Python library for dimensionality reduction that projects high-dimensional data into low-dimensional representations while preserving local and global data structures.\n- Renumics-Spotlight: Tool for interactive visualization of structured and unstructured data.\n\nFirst, the race data is loaded using the FastF1 interface:\n\n```python\nimport fastf1\nsession = fastf1.get_session(2023, \"Montreal\", \"Race\")\nsession.load(telemetry=True, laps=True)\n```\n\nNow, you can access each lap's data for every driver as a DataFrame. This includes various information.\n\n<div class=\"content-ad\"></div>\n\n***운전자:*** 차량의 운전자  \n***랩 번호:*** 현재 랩 번호  \n***속도 (시계열):*** 속도  \n***엑셀 (시계열):*** 엑셀 위치  \n***브레이크 (시계열):*** 브레이크 사용  \n***RPM (시계열):*** 엔진 속도  \n***X (시계열):*** 트랙 상 차량 위치를 나타내는 X 좌표  \n***Y (시계열):*** 트랙 상 차량 위치를 나타내는 Y 좌표  \n\n그런 다음, 이 데이터는 처음에 다음과 같이 변환됩니다.  \n\n```js\ndef dataframe_to_dict(df):\n    \"\"\"팬더스 DataFrame을 리스트의 딕셔너리로 변환합니다.\n    열이 오직 하나의 고유한 값만을 가지는 경우, 스칼라로 변환됩니다.\"\"\"\n    result = {}\n    for col in df.columns:\n        unique_values = df[col].unique()\n        result[col] = df[col].tolist() if len(unique_values) > 1 else unique_values[0]\n    return result\n```  \n\n텔레메트리 및 일반 정보를 위해 개별적인 딕셔너리로 변환됩니다. 시계열은 리스트로 변환됩니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n# 랩 정보 및 텔레메트리 로드 및 딕셔너리의 목록으로 텔레메트리 로드\ndf_laps_telemetry, laps = [], []\nfor _, lap in session.laps.iterlaps():\n    df_laps_telemetry.append(lap.get_telemetry())\n    laps.append(lap.to_dict())\n```\n\n이제 모든 딕셔너리를 사용하여 만들어진\n\n```js\n# 각 운전자의 각 랩당 하나의 행을 가진 새 DataFrame 만들기\nimport pandas as pd\ndata = [dataframe_to_dict(tele) | lap for lap, tele in zip(laps, df_laps_telemetry)]\ndf = pd.DataFrame(data)\n```\n\n대규모 DataFrame:\n\n<div class=\"content-ad\"></div>\n\n```js\n+----+----------------------+----------+-------------+-----------------+--------------------+----------------+----------------------+---------------------+\n|    | Date                 | Driver   |   LapNumber | Speed           | RPM                | Brake          | X                    | ...                  |\n|----+----------------------+----------+-------------+-----------------+--------------------+----------------+----------------------+---------------------|\n|  0 | [Timestamp('2023-06- | VER      |           1 | [0, 0, 0, ...]  | [9812, 9753, ... ] | [False, False, | [3299, 3300,  ...]   |                     |\n|    | 18, ...]             |          |             |                 |                    | ...]           |                      |                     |\n| 1  | [Timestamp('2023-06- | VER      |           2 | [278, 278, ...] | [11033, 11045,     | [False, False, | [3356, 3374,  ...]   |                     |\n|    | 18, ...]             |          |             |                 | ...]               | ...]           |                      |                     |\n| 2  | [Timestamp('2023-06- | VER      |           3 | [279, 280, ...] | [11008, 11007,     | [False, False, | [3356, 3376,  ...]   |                     |\n|    | 18, ...]             |          |             |                 | ...]               | ...]           |                      |                     |\n...\n+----+----------------------+----------+-------------+-----------------+--------------------+----------------+----------------------+---------------------+\n```\n\nTo simplify further analysis, the data series to be analyzed should all be interpolated to the same length:\n\n```js\nimport numpy as np\ndef interpolate_column(values):\n    \"\"\"This function interpolates a list of values to a fixed length of 882.\"\"\"\n    x = np.linspace(0, 1, 882)\n    xp = np.linspace(0, 1, len(values))\n    return np.interp(x, xp, values)\n```\n\n<div class=\"content-ad\"></div>\n\n\n이후에는 그들의 차원을 줄일 수 있습니다:\n\n```python\nimport umap\nimport numpy as np\nembeddings = np.stack(df[\"Speed_emb\"].to_numpy())\nreducer = umap.UMAP()\nreduced_embedding = reducer.fit_transform(embeddings)\ndf[\"Speed_emb_umap\"] = np.array(reduced_embedding).tolist()\n```\n\n결과는 적절한 시각화 도구를 사용하여 표시 및 탐색에 활용될 수 있습니다. 이 예시에서는 Renumics-Spotlight를 활용했습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\nTo start an interactive visualization of the DataFrame, use the following code:\n\n![Interactive DataFrame Visualization](/assets/img/2024-06-20-AutomotiveTestingAutomaticAIbasedTestDataEvaluation_0.png)\n\nIn the table on the left, the DataFrame is displayed. You can use the “visible columns” button to control which columns are shown in the table. The similarity map is shown in the top right. Selected data points are displayed at the bottom, where the speed profile is plotted.\n\n\n<div class=\"content-ad\"></div>\n\n# Extended Example Online\n\n저희가 Hugging Face의 데모 공간에 만들어 놓은 다른 예시가 있습니다. 시계열뿐만 아니라 시각화된 트랙 레이아웃과 각각의 운전자를 위한 속도와 기어를 색으로 표시한 내용이 포함되어 있어요:\n\n![Track Layout](/assets/img/2024-06-20-AutomotiveTestingAutomaticAIbasedTestDataEvaluation_1.png)\n\n트랙 레이아웃의 시각화를 통해 레이스에서의 차량 데이터 분석이 더 쉬워졌어요. 속도와 기어의 색으로 표시된 것을 통해 트랙 상의 중요 지점과 운전자들의 다양한 전략을 식별할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n# Summary\n\n자동차 산업에서 테스트 데이터를 반자동으로 평가하는 인공지능 방법의 활용은 상당한 장점을 제공합니다. 군집화 및 차원 축소와 같은 감독되지 않은 학습 방법을 통해 대규모 시계열 데이터 세트의 효율적인 분석이 가능해지면서 자동으로 관련 섹션을 표시할 수 있습니다. 이는 이상 사건을 더 빨리 식별하고 개발 프로세스를 가속화하는 데 도움이 됩니다.\n\nF1 텔레미트리 데이터의 예시는 차원 축소를 통해 테스트 데이터를 어떻게 구조화하고 시각적으로 처리할 수 있는지를 보여줍니다.\n\n저는 구조화되지 않은 시계열 데이터의 상호 작용적 탐색을 위한 고급 소프트웨어 솔루션을 만드는 전문가입니다. 데이터를 분석하고 정보에 기반한 결정을 내리기 위해 강력한 시각화 도구를 사용하는 방법에 대해 쓰고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n- McInnes, L., Healy, J., & Melville, J. (2018). **UMAP**: Uniform Manifold Approximation and Projection for Dimension Reduction. arXiv.","ogImage":{"url":"/assets/img/2024-06-20-AutomotiveTestingAutomaticAIbasedTestDataEvaluation_0.png"},"coverImage":"/assets/img/2024-06-20-AutomotiveTestingAutomaticAIbasedTestDataEvaluation_0.png","tag":["Tech"],"readingTime":8},{"title":"반사된 XSS 취약점 발견 마이크로소프트 Xboxcom으로의 여정","description":"","date":"2024-06-20 06:49","slug":"2024-06-20-DiscoveringaReflectedXSSVulnerabilityMyJourneyintoMicrosoftsXboxcom","content":"\n\n# 시작\n\n어느 조용한 오후, 호기심과 사이버 보안에 대한 열정에 불타서 Xbox의 주요 도메인인 https://www.xbox.com/을 탐험하기로 결심했습니다. 그런데 그 탐험은 수많은 사용자에게 잠재적으로 영향을 줄 수 있는 중요한 보안 취약점의 발견으로 이어지리라는 것을 전혀 몰랐죠.\n\n# 탐험\n\nXbox.com으로 이동해 웹사이트의 검색 기능을 사용하여 여정을 시작했습니다. 이것은 제 발견 과정에 대한 자세한 설명입니다:\n\n<div class=\"content-ad\"></div>\n\n## 본 도메인으로 이동하세요:\n\n[이 링크](https://www.xbox.com/)를 클릭해서 본 도메인으로 이동해보세요.\n\n## 검색 필드 테스트:\n\n[여기를 클릭해서](https://www.xbox.com/en-us/search?q=) 검색 필드를 테스트해보세요.\n\n<div class=\"content-ad\"></div>\n\n## 페이로드 주입:\n\n내 #IBRAHIMXSS 도구를 사용하여 다양한 입력값으로 검색 필드를 테스트했습니다. 2500개의 페이로드 중, 도구는 작동하는 페이로드 하나를 식별했습니다: `//j\\javascript:alert(document.domain)`. 이 페이로드는 저에 의해 수동으로 주입된 것이 아니라 #IBRAHIMXSS 도구에 의해 발견되었습니다.\n\n## 결과 관찰:\n\n페이로드가 실행되어 반사된 크로스 사이트 스크립팅(XSS) 취약점의 존재가 확인되었습니다. 이 발견은 #IBRAHIMXSS 도구의 효율성을 강조합니다. 2500개의 페이로드를 수동으로 테스트하는 것은 비현실적이고 매우 시간이 소모되는 작업이겠지만, 내 도구를 사용하니 30초도 걸리지 않고 취약점을 발견했습니다. 이는 도구가 빠르고 정확하게 취약점을 찾을 수 있는 능력을 입증하며, 이를 수동으로 발견하는 것은 그 양이 많기 때문에 놓치거나 발견하는 데 굉장히 많은 시간이 걸릴 수 있음을 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n**최종 URL:**\n\n\nhttps://www.xbox.com/en-us/search?q=%2F%2Fj%5C%5Cjavascript%3Aalert%28document.domain%29\n\n\n![The Discovery](/assets/img/2024-06-20-DiscoveringaReflectedXSSVulnerabilityMyJourneyintoMicrosoftsXboxcom_0.png)\n\n# 발견하기\n\n<div class=\"content-ad\"></div>\n\n**유출된 XSS 취약점**\n\nXbox의 메인 도메인(xbox.com)에서 반사형 크로스사이트 스크립팅(XSS) 취약점을 발견했습니다. 반사된 XSS 공격은 악의적인 스크립트가 웹 응용 프로그램에서 피해자의 브라우저로 반사될 때 발생합니다.\n\n취약점 상세 정보:\n\n- 제목: Xbox.com의 반사형 XSS\n- 취약한 매개변수: q\n- 페이로드: `//j\\javascript:alert(document.domain)`\n\n<div class=\"content-ad\"></div>\n\n### 예이이이이 보너스: 2000달러!\n\n![이미지](/assets/img/2024-06-20-DiscoveringaReflectedXSSVulnerabilityMyJourneyintoMicrosoftsXboxcom_1.png)\n\n#### 영향\n\n이 취약점은 사용자 브라우저 세션에서 스크립트를 실행할 수 있어 다양한 악의적 활동(세션 탈취, 데이터 도용 또는 악의적 리디렉션 등)으로 이어질 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 취약점 보고서\n\n## 증명 자료 (PoC)\n\n이 공격을 재현하는 방법을 보여주는 이미지 및 비디오를 첨부했습니다. PoC에서는 페이로드의 삽입과 해당 알림 스크립트 실행이 명확히 보여집니다.\n\nMicrosoft가 이러한 문제를 신속히 해결함으로써 응용 프로그램의 보안을 향상시킬 수 있고, 사용자를 보호하며 브랜드에 대한 신뢰를 유지할 수 있습니다. 추가 설명을 위해 취약점을 악용하는 이미지와 비디오를 첨부했습니다. 궁금한 점이 있거나 추가 정보가 필요하면 내 Linkedin 프로필을 통해 언제든지 연락 주세요.\n\n<div class=\"content-ad\"></div>\n\n새로운 가능성을 열다: IBRAHIMXSS 도구 소개\n\n🚀 IBRAHIMXSS로 XSS 취약점 감지의 힘을 발휘하세요! 🚀\n#IBRAHIMXSS의 첨단 기능을 발견하세요:\n다음과 같은 기능이 있습니다:\n\n✅ 거짓 양성 케이스 제로\n💡 독특한 혁신\n🎯 유연한 감지 모드\n🔗 POST 및 GET 요청\n🌐 DOM 기반 XSS\n🔍 경로 기반 분석\n📱 JSON 웹 앱\n📊 내보낼 수 있는 보고서\n🔓 WAF 우회\n🕵️‍♂️ 숨은 모드\n💼 효율성\n💥 2500개 이상의 인코딩된 Payload\n🛠️ 실험실에서 시험된 및 현장 준비 완료\n🔄 멀티 스레딩\n⏳ 사용자 정의 가능한 지연\n⚡️ 단 15초 동안 1URL에 2500개의 Payload를 스캔합니다! ⚡️🔥\n🔌 모든 종류의 익스텐션으로 XSS\n🔒 안전하고 신뢰성 있는\n🌟 지속적인 업데이트\n📈 높은 성능\n🔄 자동 스캔\n🔍 정확한 탐지 알고리즘\n🔧 쉬운 구성\n📂 다양한 웹 기술 지원\n🚀 신속한 배포\n🔎 고급 검색 및 필터 옵션\n🔧 사용자 정의 가능한 Payloads\n\n<div class=\"content-ad\"></div>\n\n## ✅ 거짓 양성 없음\n\n잡음과 작별하세요. #IBRAHIMXSS Tool은 거짓 양성을 전달하지 않도록 설계되어 실제 위협인 경보만을 보장합니다. 그 정확성을 믿고 소중한 시간을 절약하세요. 진짜 취약점에만 집중하세요.\n\n## 💡 독특한 혁신\n\n#IBRAHIMXSS Tool을 주도하는 독특한 혁신의 힘을 활용하세요. 다른 곳에서는 찾아볼 수 없는 고급 알고리즘과 기술을 통합하여 XSS 취약점을 식별하고 완화하는 데有기하는 절강한 장점을 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n**🎯 유연한 탐지 모드**\n\n다양한 상황에 적응할 수 있는 유연한 탐지 모드로 조정하세요. 신속하게 검사할지, 깊이 있는 분석을 수행할지 여부에 상관없이 #IBRAHIMXSS 도구는 사용자 정의 옵션을 제공하여 특정 요구 사항에 맞게 조정하고 포괄적인 보호를 보장합니다.\n\n**🔗 POST 및 GET 요청**\n\nPOST 및 GET 요청을 지원하여 웹 애플리케이션을 철저히 테스트하세요. 이를 통해 XSS 공격의 모든 잠재적인 출입구가 검토되어 웹 자산에 강력한 보안이 제공됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 🌐 DOM-Based XSS\n\nKeep up with the latest security measures by spotting DOM-based XSS vulnerabilities early on. The **IBRAHIMXSS Tool** is a reliable resource for inspecting client-side scripts and uncovering potential risks that regular tools might overlook.\n\n## 🔍 Path-Based Analysis\n\nTake advantage of path-based analysis to monitor the data flow within your application. This method ensures thorough scanning for vulnerabilities along critical paths, leaving no stone unturned in safeguarding your system.\n\n<div class=\"content-ad\"></div>\n\n## 📱 JSON 웹 앱\n\n동적 웹 응용 프로그램 시대에는 #IBRAHIMXSS 도구가 JSON 웹 앱을 스캔하는 데 능숙합니다. 이 도구는 JSON을 이해하고 파싱하여 최신 웹 아키텍처의 취약점을 탐지합니다.\n\n## 📊 내보낼 수 있는 보고서\n\n내보낼 수 있는 보고서로 발견한 내용을 효과적으로 전달하세요. 보안 노력의 철저함과 효과를 입증하는 세심한 전문 보고서를 이해관계자와 공유하세요.\n\n<div class=\"content-ad\"></div>\n\n## 🔓 WAF 바이패스\n\n웹 애플리케이션 방화벽의 장벽을 WAF 바이패스 기능으로 극복하세요. #IBRAHIMXSS 도구는 WAF 보호를 우회하여 웹 보안의 진정한 평가를 보장합니다.\n\n## 🕵️‍♂️ 은신 모드\n\n은신 모드로 주변을 은밀하게 활동하세요. 잠복하여 스캔을 수행하고 잠재적 침입자에게 경고하지 않고 은밀하게 작업하여 기습과 보안을 유지하세요.\n\n<div class=\"content-ad\"></div>\n\n## 💼 효율성\n\n보안 프로세스에서 전례없는 효율성을 경험해보세요. #IBRAHIMXSS 도구는 생산성을 극대화하여 응용 프로그램을 더 빠르고 더 정확하게 보호할 수 있게 해줍니다.\n\n## 💥 2500개 이상의 인코딩된 Payload\n\n2500개가 넘는 인코딩된 페이로드의 파워를 활용하여 다양한 XSS 공격 벡터를 테스트해보세요. 이 포괄적인 방법은 보안 평가에서 한 돌도 빠짐없이 살펴보도록 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n## 🛠️ Lab-Tested and Field-Ready\n\n이 도구는 실험실에서 테스트되고 현장에서 사용할 수 있는 준비가 되어 있습니다. #IBRAHIMXSS 도구는 통제된 환경과 실제 상황에서 엄격하게 시험되어 신뢰성과 효과를 보장합니다.\n\n## 🔄 Multi-threading\n\n멀티스레딩으로 스캔 프로세스 속도를 높여보세요. #IBRAHIMXSS 도구는 시스템 자원을 효율적으로 활용하여 동시에 스캔하고 빠른 결과를 얻을 수 있도록 지원합니다.\n\n<div class=\"content-ad\"></div>\n\n## ⏳ 개인 맞춤형 지연 시간\n\n당신의 스캔을 맞춤 설정할 수 있는 지연 시간 설정입니다. 테스트의 진행 속도를 제어하여 특정 환경과 요구 사항에 맞게 맞춤화하고 최적의 성능과 정확도를 보장하세요.\n\n## ⚡️ 1 URL에 2500개의 페이로드를 15초 만에 스캔! ⚡️🔥\n\n1 URL에 2500개의 페이로드를 단 15초 만에 스캔할 수 있는 전례 없는 속도를 달성하세요. 이 빠른 성능은 웹 보안의 새로운 표준을 제시하여 신속하고 철저한 평가를 가능하게 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 🔌 모든 종류의 확장자에 XSS 공격하기🔌\n\n보안 범위를 확장하여 모든 종류의 URL 확장자에 대한 XSS 감지를 할 수 있습니다. #IBRAHIMXSS 도구를 사용하여 다양한 URL 확장자에서 XSS 취약점을 테스트할 수 있습니다. 예를 들어, login.php를 'payload'.php와 같은 payload로 변경하여 테스트할 수 있습니다. 이를 통해 서로 다른 파일 유형과 URL 구조에 대한 포괄적인 테스트를 보장할 수 있습니다.\n\n## 🔒 안전하고 신뢰할 수 있음🔒\n\n보안과 신뢰성을 핵심으로 하는 도구를 신뢰하세요. #IBRAHIMXSS 도구는 강력한 보안 조치를 채택하여 데이터와 프로세스가 보호되도록 보장합니다. 취약점을 테스트하는 동안 안심하고 사용할 수 있도록 지원합니다.\n\n<div class=\"content-ad\"></div>\n\n## 🌟 지속적인 업데이트 🌟\n\n지속적인 업데이트로 변화하는 위협에 항상 준비하세요. #IBRAHIMXSS Tool은 최신 기술과 payloads로 정기적으로 업데이트되어 있어 최신 취약점과 공격 경로에 효과적으로 대응할 수 있습니다.\n\n## 📈 높은 성능 📈\n\n#IBRAHIMXSS Tool로 최고 수준의 성능을 경험하세요. 속도와 효율성을 최적화하여 빠르고 정확한 결과를 제공하며, 성능을 희생하지 않고 애플리케이션을 안전하게 보호할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 🔄 자동 스캐닝 🔄\n\n보안 프로세스를 쉽게 자동화하세요. #IBRAHIMXSS 도구는 완전 자동화된 스캐닝을 지원하여 정기적인 스캔 일정을 예약하고 최소한의 수동 개입으로 지속적인 보안 모니터링을 유지할 수 있도록 돕습니다.\n\n## 🔍 정확한 탐지 알고리즘 🔍\n\n정확하고 신뢰할 수 있는 취약점 탐지를 경험해보세요. #IBRAHIMXSS 도구는 고급 알고리즘을 사용하여 XSS 취약점을 정확하게 식별함으로써 잘못된 양성 결과를 최소화하고 철저한 보안 커버리지를 확보합니다.\n\n<div class=\"content-ad\"></div>\n\n## 🔧 쉬운 구성 🔧\n\n빠르게 설정하고 스캔을 시작하세요. #IBRAHIMXSS 도구는 사용자 친화적인 설정과 직관적인 컨트롤을 제공하여, 웹 보안 테스트에 새로 온 사람들도 쉽게 사용할 수 있습니다.\n\n## 📂 다양한 웹 기술 지원 📂\n\n다양한 플랫폼에서 포괄적인 보안을 확보하세요. #IBRAHIMXSS 도구는 다양한 웹 기술을 지원하여, 각기 다른 웹 환경에 대한 다재다능한 스캔 기능을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n## 🚀 빠른 배포 🚀\n\n#IBRAHIMXSS 도구를 신속하고 효율적으로 배포하세요. 간단한 설치 프로세스와 최소한의 설정 요구사항 덕분에 애플리케이션 보안을 신속히 시작할 수 있습니다.\n\n## 🔎 고급 검색 및 필터 옵션 🔎\n\n고급 검색 및 필터 옵션으로 분석을 간소화하세요. #IBRAHIMXSS 도구를 사용하여 특정 취약점을 신속하게 찾아내고 가장 중요한 문제에 집중함으로써 생산성과 효율성을 향상시킬 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 🔧 커스터마이즈 가능한 페이로드🔧\n\n테스트를 원하는 대로 커스터마이즈하세요. #IBRAHIMXSS 도구는 사용자 정의 페이로드의 생성과 사용을 지원하여 스캔을 특정 요구 사항과 시나리오에 맞게 조정하여 더 정확한 취약성 탐지가 가능합니다.\n\n# 버그 바운티 플랫폼에서 입증된 성능\n\n#IBRAHIMXSS 도구는 Microsoft를 포함한 수십 개의 버그 바운티 플랫폼에서 입증되었습니다. 이 도구를 사용하여 2개월 만에 30개 이상의 XSS 취약점을 발견했습니다. 잠재적인 수입을 상상해보세요: 버그 바운티 플랫폼에서는 XSS 발견에 대해 500달러에서 3000달러를 지급합니다. 이 도구에 20달러에서 70달러 정도의 작은 금액을 투자하여 수천 달러를 버십시오. 수동 수입에 대한 스마트한 투자입니다. URL을 수집하고 도구를 하룻밤 돌려놓기만 하면, 아침에 결과가 나옵니다. 저는 그렇게 해왔고, 이제 여러분도 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n**웹 보안의 미래를 포착하세요!**\n\n얼마나 많은 버그 보상 플랫폼이 있는지 기억하고 계시나요? 이러한 플랫폼 각각에서 하나의 XSS 취약점만 찾는다 해도, 모든 입력 및 필드를 명확히 검사하고 집중한다면, 연간 수십만 달러를 벌 수 있습니다. 이 도구가 XSS 취약점을 찾아줄 것임을 확신하실 수 있습니다. 찾아줄 것이라는 것을 확실하게 믿으셔도 좋습니다.\n\n**#IBRAHIMXSS** 도구로 취약성 검출을 새로운 차원으로 끌어올리세요! 웹 응용 프로그램을 보호하는 데 그치지 말고, 최고 수준의 XSS 도구를 활용해 영토를 지배하세요.","ogImage":{"url":"/assets/img/2024-06-20-DiscoveringaReflectedXSSVulnerabilityMyJourneyintoMicrosoftsXboxcom_0.png"},"coverImage":"/assets/img/2024-06-20-DiscoveringaReflectedXSSVulnerabilityMyJourneyintoMicrosoftsXboxcom_0.png","tag":["Tech"],"readingTime":8},{"title":"사회, 문화, 증강 현실","description":"","date":"2024-06-20 06:47","slug":"2024-06-20-SocietyCultureAugmentedReality","content":"\n\n![SocietyCultureAugmentedReality](/assets/img/2024-06-20-SocietyCultureAugmentedReality_0.png)\n\n가끔은 혁신적인 기술이 대중 사회에 등장하면 강력한 반발을 받을 수도 있고, 수용될 수도 있습니다. 이것이 문화가 작용하는 방식입니다. 그러나 해당 기술이 꽤 우수하다면, 처음에는 특정 시장 기회를 찾아 나서고, 몇 년, 심지어 수십 년 동안 천천히 진화한 뒤 다시 넓은 사회로 확대될 것입니다.\n\n이와 같은 상황이 블록체인, 웹3, 가상현실(VR), 증강현실(AR) 및 인공지능(AI)에 해당됩니다. 클로드, ChatGPT 및 여러 개의 오픈 소스 AI 도구를 통해 생성적 AI(GAI)가 도래함으로써 AI가 몇 십 년 동안 존재했음에도 불구하고 폭넓은 대중층으로 선보이게 되었습니다.\n\n이제 애플의 비전 프로가 AR과 VR을 결합한 혁신이 나왔습니다. 놀랍게도, 사람들은 이 헤드셋을 이상한 방식으로 사용하고 있습니다. 사람들은 기술과 놀기를 즐깁니다. 이는 그들이 진화하고 사회문화적으로 수용되는 방식의 중요한 부분입니다. 애플의 비전 프로가 시장에서 어떻게 획득되는지는 아직 알 수 없습니다. 그러나 우리는 새로운 AR 안경이 많이 출시되는 것을 보게 될 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n만약 이것이 사실이라면, 이는 인류에게 중요한 사회문화적 순간을 시사합니다. 이것은, 우리 사회가 이전보다도 더 두 개의 세계에서 동시에 생활하는 데 보다 깊은 흥미를 느끼고 있다는 것을 나타냅니다.\n\n구글은 AR 안경을 대중 시장으로 처음으로 이끌어냈습니다. 그것을 쓴 사람들은 빠르게 \"글라스홀\"이라 레이블이 붙게 되었습니다. 그것은 빠르게 소비자 시장에서 철회되었습니다. 지금은 제조업과 의료 분야와 같은 소수 시장에서 채택되어 유용하게 사용되고 있습니다.\n\n만약 우리가 디지털 세계와 물리적 세계와 더 깊게 얽힌 새로운 시대로 나아가고 있다면, 그렇다면 어떤 영향이 있을까요? 확실히 개인용 AI 에이전트와 같은 AI 도구들이 내장될 것입니다. 우리를 대신해 행동을 취할 수 있는 개인용 AI 에이전트 등이 있을 것입니다.\n\n## 일상 생활에서 증강 현실의 사회문화적 영향\n\n<div class=\"content-ad\"></div>\n\n인간들은 언제나 두 개의 세계에서 살아왔어요. 모두가 각자의 내적 현실을 가지고 있고, 또한 물리적 세계를 탐험해야 해요. 이 두 개의 세계에서 어떻게 살아남을 방법을 찾은 건 언어와 이야기를 통해였어요. 이렇게 함으로써 우리는 사회적 그룹을 형성하고 내적 현실에서 상상한 기술을 발전시킬 공통점을 찾았어요.\n\n그 다음 우리는 정치적, 경제적 시스템, 군대, 미학(문학, 미술, 건축), 규범, 종교, 전통 및 관습을 포함한 문화를 창조했어요. 문화는 계속해서 진화하고 변화하지만, 우리의 생존과 협력하는 방식에 있어서 기본적이에요.\n\n증강 현실은 이 두 개의 세계에서 살아가는 방식에 완전히 새로운 층을 추가해요. 아마도 물리적 세계와 디지털 사이에 제 3의 가장자리 공간을 만들어내는 것 같아요. 우리는 주변의 물리적 세계를 이해하는 동안 특정한 흔한 활동을 외부로 옮길 수도 있을지도 몰라요.\n\n이것은 인간들에게 새로운 것이에요. 따라서 AR을 사용하는 사람들은 인공지능, 영상 및 오디오 캡처 및 기타 도구와 결합되어 어떤 형태의 사회적 우위를 가졌다고 인식될 수 있기 때문에 많은 질문을 던지게 되죠.\n\n<div class=\"content-ad\"></div>\n\n사회적인 모임에서 AR 안경을 쓰는 사람들에 대해 어떻게 느낄까요? 특히 집 파티나 직장 모임과 같은 더 친밀한 경험에서는 어떨까요? 누군가 이벤트를 녹화하고 그것을 나중에 공개적인 수치감으로 사용하거나 더 나아가 불청객을 위협할 수 있는 리스크를 우리는 의심하게 될까요?\n\nAR 안경을 가지고 있지 않은 사람들과의 디지털 격차가 더 커질까요? 그렇다면 불평등함을 느끼게 될까요? 그로 인해 놓치게 되는 것이 더 많아질까요?\n\n직장이나 다른 사회적인 모임에서 AR 안경을 쓰고 있는 사람에게 말을 거는 사람들은 즉각적인 정보에 액세스하여 통찰력을 제공할 수 있는 이점을 가지고 있다고 느낄까요?\n\n현실 세계에서 협상에서 우세한 입장을 차지하기 위해 AR 안경을 사용해 상대방의 신체 언어를 읽을 수 있을까요? 그게 윤리적인 것인가요? 우리 문화적인 규범은 이에 대해 어떻게 생각할까요?\n\n<div class=\"content-ad\"></div>\n\n우리의 두 가지 세계에서 오랜 기간을 동시에 살아가는 것을 우리의 뇌, 우리의 심리가 실제로 다룰 수 있을까요? 현재 충분한 연구들이 우리의 뇌가 VR 헤드셋을 한 시간 이상 다룰 만큼 적응되어 있지 않다는 것을 보여줍니다.\n\n만약 AR 안경을 사용하고 뇌 칩이 이식되어 있다면 어떻게 될까요? 이 칩이 우리에게 그 모든 정보를 다루고 두 개의 세계에서 살아가는 문제들을 더 잘 다루게 도와줄까요? 현재까지 우리는 이에 대해 전혀 모른다는 것입니다.\n\n우리는 기술을 우리의 신체에 더 가깝게 가져와 우리의 인지 능력을 향상시키는 초기 단계에 있습니다. 아직 우리가 알지 못하는 것은 문화가 이것을 우리 종족의 생존을 발전시키는 도구로서 충분히 가치 있다고 인식하는지 여부입니다.\n\n이 장치들을 만드는 기업들은 의도하지 않은 결과들을 고려하는 것을 싫어하며, 인식된 이점에만 집중하는 편입니다. 그리고 지금, 그들은 인지되는 것뿐이지 실제로 알려진 것은 아닙니다. 왜냐하면 인간들은 새로운 기술들을 통해 하는 인간다운 일들을 아직 해보지 않았기 때문입니다. 이것은 언제나 좋은 일과 나쁜 일이 모두 포함된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n현실증강 기술에 대한 우수한 활용 사례들이 많이 나타나고 있으며 앞으로도 더욱 성장할 것입니다. 어떤 기술이든 불가피하게 좋은 일과 함께 나쁜 일도 발생할 수 있습니다. 아직 알아야 할 중요한 질문은 어떻게 사회가 이 기술을 받아들이고 수용하며 두 개의 세계에서 더욱 일관되게 살아가는 방식을 어떻게 변화시킬 것인가입니다. 우리는 이전에 인터넷을 사용했지만 이제는 인터넷이 더욱 개인적으로 접근해오고 있습니다.\n\n여러 동안 현실증강 기술은 조용해져 말썽을 부리는 범날타오르는 재 생성질소 같았습니다. 하지만 이제 그것은 화재처럼 불타고 있습니다. 시장 안팎에 더 많은 현실증강 안경들이 등장하고 있습니다. 이러한 기술에 사회문화적으로 어떻게 적응해 나갈지 지켜보는 것이 확실히 흥미로울 것입니다.","ogImage":{"url":"/assets/img/2024-06-20-SocietyCultureAugmentedReality_0.png"},"coverImage":"/assets/img/2024-06-20-SocietyCultureAugmentedReality_0.png","tag":["Tech"],"readingTime":4},{"title":"PS5가 500 사기로 변하는 과정","description":"","date":"2024-06-20 06:46","slug":"2024-06-20-HowthePS5Becamea500Scam","content":"\n\n![img](/assets/img/2024-06-20-HowthePS5Becamea500Scam_0.png)\n\nRemember when the PS5 was first released? It felt like a moment filled with anticipation and promise. The hype around it was massive, with promises of it surpassing the beloved PS4. If you were a dedicated gamer, you couldn't afford to miss out on this next-gen console—or so they said.\n\nBut then reality hit hard. The turbulent COVID years wreaked havoc on almost everything, and the PS5 was no exception. Production issues, scalpers snatching up scarce units for resale—it was a mess. Looking back, it was like the universe was trying to signal that all was not well. I was just like those folks who fell for bizarre schemes like buying gamer girl bathwater. I had high hopes for the PS5, especially as a longtime Ratchet and Clank fan eagerly awaiting the latest installment.\n\nThat sinking feeling in the pit of your stomach when things start going south? Yup, that was me when the Breath of the Wild lookalike game dropped on Steam. I could've sworn it was a Sony exclusive from a first-party studio. What a surprise! And here we had this 2017 PS4 title suddenly fitting right into the PC gaming scene. Despite the setbacks, there were still some promising titles lined up for the PS5. Well, there were until delays and cancellations started piling up. Some highly anticipated games remain in the shadows, and unfortunately, it seems like some may never see the light of day...\n\n<div class=\"content-ad\"></div>\n\n하지만 그때 이상한 일이 벌어졌어요. 어느 순간에는 Steam에서 \"PS독점작\"이 점점 더 많이 나오기 시작했어요. 그래서 저는 중고 PS4 Pro를 반값 이하로 사면 놓칠 것이 없다는 걸 깨달았어요. 몇 가지 게임을 놓칠 수는 있겠지만, PC에서 기술적으로 플레이할 수 있으니까요. 그리고 최종 판타지 리버스 같은 게임을 몇 년 기다리면 아마 Steam에도 출시될 거예요.\n\n내 기분이 매우 기분 나빴다고 느낄 수 있겠죠. 산에 들어간 콘솔 게이머 중 하나는 아니지만, 기쁜 경험을 놓친 것 같아서 그래요. 만일 이런 일이 벌어질 줄 알았다면 7년 된 GTX1050를 고통의 방에서 구해줄 거였고, PS5를 사지 않을 거예요. 한 가지는 분명해요, 한 쪽이 더 똑똑한 구매였다는 거죠. 그리고 작년에 Steam으로 Rift Apart가 출시된 게 최종적인 결정이었어요. 이것이 제가 PS5를 샀던 가장 큰 이유였어요. PS5의 기술적 재능을 전부 보여줄 벽람의 시니처 출시 타이틀이었거든요. 그것이 소니의 야심작이었어요. 그런데, 이 기사가 결국 맞았네요.\n\n제 질문은, 소니는 무엇을 생각하고 있었던 걸까요? 하지만 그에 대해 이야기하겠기 전에, 게임 산업의 현재 상태부터 시작해보죠. 세 마디로 말하자면: 혼란스럽다. 올해 수십 개의 회사가 해고를 발표했거나 문을 닫았으며, 많은 훌륭한 게임 스튜디오가 매우 혐오받는 무료 플레이 비즈니스 모델로 전환하고 실패했어요. also 많은 출판사들이 스튜디오에 더 많은 돈을 벌어달라 압박했을 것입니다 (아마도 그렇죠), 혹은 게임을 만드는 오래된 방식이 지속불가능한 것일지도 모르죠. 하나는 분명한데, 적은 수의 대기업이 열정 프로젝트를 목표로 하고 더 많은 수의 대기업이 그래프를 예쁘게 만드는 데 주력하고 있다는 것이죠.\n\n그리고 다시 소니로 돌아와서, 어쩌면 그들의 재정 상황이 사실 놀라울 정도로 대단하게 보인다고 하죠. 그들의 2023년 매출이 얼마나 성장했는지 정말 믿을 수 없었어요; 소니의 1자 PlayStation 게임 목록은 상당히 얇아 보였죠. 그러나 이 기사가 소니의 게임 계획을 아름답게 요약하고 있어요: \"플랫폼 홀더는 비-1자 매출이 증가하고 1자 매출이 감소할 것으로 예상하면서, PlayStation의 대대적인 프랜차이즈에 새로운 엔트리가 없을 것이라는 사실 때문에 그럴 수밖에 없습니다.\" 그래서 이것은 2023년과 2024년의 수익이 비디오 게임 산업에 엄청 많이 의존하고 있다는 것이죠. 많은 좋은 게임이 출시되면, 거기에서는 놀랄만한 해가 될 거에요. 그렇지 않으면, 주주들을 만족시키기 위해 패닉을 하는 척할 거에요. 어떻게 행동할지 궁금하네요.\n\n<div class=\"content-ad\"></div>\n\n소니가 현재 수익에 대한 제어력이 적다는 점 때문에, 그들은 제어할 수 있는 부분에 올인하려고 합니다. 이를 \"저위험, 중득\" 비즈니스라고 부르죠. 그것은 감원과 포트를 말합니다. 올해 Steam으로 나오는 이 모든 대작을 봐. 이게 우연이라고는 말할 수 없어요.\n\n하지만, 그렇다면 소니가 무엇을 생각하고 있는 걸까요? 이미 저렴한 예산으로 플레이스테이션을 사는 것은 어리석은 아이디어라는 것을 증명해 버림으로써 자신들의 발을 쏘고 말았는데 말이에요? 몇 년을 기다려서 게임을 할지라도 죽지는 않을 테니까 말이에요. 이미 설치하지도 않은 게임이 톤만큼 있어. 소니가 자신들이 뛌어난 점을 잊어버린 것 같아요. Xbox는 최근 헤일로 게임이 망하고 오히려 흥행하는 플레이스테이션 독점 타이틀 덕분에 고전했습니다. 그들이 독점을 포기한다면, 스위치처럼 해야 할 것이고(안타깝게도 PS Vita와 PSP), 그렇지 않으면 플레이스테이션이 현명한 구입이 아닐 수도 있다는 걸 사람들이 알게 될 거에요. 그럼... (최적화가 나쁘다는 평가 디스플레이) 알았어요? 아마도 현명한 결정이었을 지도 몰라요.\n\n읽어 주셔서 감사합니다. 즐거운 하루 보내세요.\n\n비디오 버전도 확인해보세요:\n\n","ogImage":{"url":"/assets/img/2024-06-20-HowthePS5Becamea500Scam_0.png"},"coverImage":"/assets/img/2024-06-20-HowthePS5Becamea500Scam_0.png","tag":["Tech"],"readingTime":4}],"page":"1","totalPageCount":17,"totalPageGroupCount":1,"lastPageGroup":17,"currentPageGroup":0},"__N_SSG":true}