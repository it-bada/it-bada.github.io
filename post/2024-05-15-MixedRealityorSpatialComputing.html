<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>혼합 현실 또는 공간 컴퓨팅 | it-bada</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://it-bada.github.io///post/2024-05-15-MixedRealityorSpatialComputing" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="혼합 현실 또는 공간 컴퓨팅 | it-bada" data-gatsby-head="true"/><meta property="og:title" content="혼합 현실 또는 공간 컴퓨팅 | it-bada" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://it-bada.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://it-bada.github.io///post/2024-05-15-MixedRealityorSpatialComputing" data-gatsby-head="true"/><meta name="twitter:title" content="혼합 현실 또는 공간 컴퓨팅 | it-bada" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | it-bada" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-15 19:35" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PDYZ2R0CH9"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-PDYZ2R0CH9');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-90e194c785348efe.js" defer=""></script><script src="/_next/static/pS12KbT5cDEZt16dno2Ez/_buildManifest.js" defer=""></script><script src="/_next/static/pS12KbT5cDEZt16dno2Ez/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Bada</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">혼합 현실 또는 공간 컴퓨팅</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="혼합 현실 또는 공간 컴퓨팅" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Bada</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 15, 2024</span><span class="posts_reading_time__f7YPP">8<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-15-MixedRealityorSpatialComputing&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>매력적으로 함축적인 매체 언어 - 과거와 현재</p>
<p><img src="/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png" alt="image"></p>
<p>최근 기자들이 자주 묻는 질문이 있어요: 공간 컴퓨팅과 혼합 현실의 차이는 뭔가요? 대답하자마자 더 많은 질문이 나오며 현실적인 매체의 언어와 오늘날 사용되는 다양한 문구에 대한 이해가 필요하다고 느껴져요. 혼란을 줄이기 위해, 핵심적인 용어들의 역사와 인지적 의미를 살펴보는 것이 도움이 된다고 생각해요.</p>
<p>저는 개인적으로 애플의 공간 컴퓨팅이라는 표현을 좋아하고 Vision Pro가 공간 컴퓨터라고 동의합니다. 하지만, 이로 인해 혼란이 더해졌어요. 결국 대부분의 사람들이 Vision Pro를 혼합 현실 헤드셋이라고 부르지만, 애플만 아닐 뿐이에요. 또한, 개발자들은 Vision Pro 앱을 가상 현실, 혼합 현실 또는 증강 현실을 활성화하는 것으로 설명할 수 없어요. 이는 마케팅 상의 이유를 이해하고, 이러한 언어 제한이 시간이 흐르면 사라질 것으로 예상하지만, 애플이 특정 단어를 금지하는 것은 지나친 것으로 보여요.</p>
<p>아마도 난 그냥 향수에 젖어 있는 걸 수도 있지만, 처음 분야를 시작했을 때 가상 현실이라는 문구가 몇 년 전에 나왔을 뿐인데도 이미 큰 관심을 불러일으켰어요. 저는 NASA에서 VR 실험을 수행하는 젊은 연구원이었고, 위의 사진은 저가 일하고 있던 연구소에 걸려 있던 포스터였어요. 저에게는 그가 제시하는 완전한 약속을 담은 깊은 영감을 주는 이미지였어요.</p>
<p>게다가, 해당 NASA 사진에 나타난 인간 경험은 거의 40년 동안 가상 현실로 불려 왔어요. 만약 Vision Pro 개발자이고 완전히 시뮬레이트된 몰입형 경험을 만든다면, 그것을 가상 현실로 설명하는 것이 정말 죄인일까요? 결국, 위에 보이는 VR 헤드셋은 지금 스미스소니안 박물관에 전시되어 있어요. 이것은 우리의 역사이면서 우리 문화입니다.</p>
<p>물론, Vision Pro는 NASA 헤드셋에 비해 훨씬 정교하며 놀라운 선명도 뿐만 아니라 완전히 새로운 기능을 추가했기 때문에 더욱 우수해요. Vision Pro의 가장 중요한 기능은 현실 세계와 공간적으로 투사된 가상 내용을 원활하게 결합하여 단일 통합 경험을 만들어내는 능력입니다. 이를 확장 현실 또는 복합 현실이라고 부르며 기능에 따라 두 용어는 학계와 산업에서 오랜 역사를 갖고 있어요.</p>
<p>그렇다면, AR과 MR의 차이점은 무엇일까요?</p>
<p>세계적인 가상현실 산업에서 가장 오해받는 문제 중 하나일 것 같아요. 그래서 오늘날의 분화가 어떻게 생겨났는지 설명하기 위해 과거로 돌아가는 것은 가치가 있어요. 초기에는 '증강현실'이라는 한 마디만으로 충분했지만, 2010년대에는 마케터들이 더 간단한 시스템들을 그 이름 아래로 푼 것 때문에 그 정의가 희석되었죠. 미래에는 진자가 다시 돌아갈 것으로 생각되지만, 현재로서는 두 용어 모두 유용해요. 그 이유를 이해하려면 사용자의 현실을 확실하고 진실되게 증강하는 데 필요한 지각 요건에 대해 깊게 파고들어야 해요.</p>
<p>제 배경을 말씀드리자면, 1991년에 현실과 가상을 융합하는 작업을 시작했는데, 그 당시에는 그러한 결합 경험을 설명할 언어조차 없었어요. 스탠포드 대학, NASA, 미국 공군에서의 초기 연구는 물리적이고 가상적인 통합 지각현실을 만들기 위해 필요한 기본 심리물리학적 요소들을 탐색하기 위한 것이었어요. 이 새로운 추구를 "지각 디자인"이라고 불렀고(매우 매력적이진 않죠), 가상 물체들을 "지각 오버레이"라고 명명했어요(이것 역시 매력적이진 않아요). 그 당시의 진짜와 믿을 만한 혼합 현실을 만드는 데 필요한 핵심 지각 요소들을 설명한 것이 아래와 같아요:</p>
<ul>
<li>지각 오버레이: "지각 오버레이의 성질 또는 내용에 제한을 두지 않으려 합니다. 단 한 가지 요구할 건, 작용자의 신경 운동 활동(efference)과 그 뒤에 오는 지각 오버레이에 포함된 감각의 변화(afference) 사이에 자연스럽고 예측 가능한 관계가 존재해야 한다는 것뿐입니다. 이 하나의 제약 조건만으로도 원격 속성 부여를 촉진합니다. 그 결과, 원격 속성 부여로 인해 작용자는 오버레이된 지각을 주변 현실의 실제적이고 만질 수 있는 부분으로 받아들입니다. 다시 말해, 작용자는 오버레이된 지각 정보에 대한 존재감을 느낄 것입니다. 따라서, 작용자는 가상 지각을 환경의 진짜 특성이나 속성으로 받아들일 것입니다." (스탠포드, 로젠버그, 1993)</li>
</ul>
<p>이 부분은 다소 어렵게 보일 수 있지만, "원격 속성 부여"라는 핵심 구절이 중요해요. 이는 새로운 지각 정보가 뇌로 들어와 그것을 주변 환경의 진짜 일부로 통합하는 과정을 말해요. 따라서 위의 지침은 가상 물체가 주변 현실의 진짜 일부로 인식되려면 상호작용적 경험을 가능케 해야 한다고 설명하고 있어요. 수동적 관찰만으로는 충분하지 않습니다. 왜냐하면 그것은 작용과 반응(즉, 행동과 반응) 사이의 정신적 루프를 닫지 않기 때문이에요. 이것이 왜 특정 위치에서 촬영된 360도 가상현실 영화가 현실같지 않게 느껴지는지에 대한 이유입니다. 머리를 돌리고 깊이 지각을 할 수 있더라도 움직이거나 손을 뻗는 등 상호작용할 수 없기 때문에 뇌는 그것을 시야에 있는 장식으로 인식하고 진짜 현실로 인식하지 않는 것이죠.</p>
<p><img src="/assets/img/2024-05-15-MixedRealityorSpatialComputing_1.png" alt="Image"></p>
<p>믹스 리얼리티(Mixed Reality)를 통합하는 데 필수 요소인 원격 속성을 식별하는 것은 도움이 되었지만, 실제와 가상을 현실적으로 융합하기 위해 충족되어야 하는 추가적인 지각 요구사항에 직면하게 되었습니다. 이 요구사항은 다음과 같이 요약할 수 있습니다: (a) 완전한 3D 공간에서 정확한 공간 정렬, (b) 실제와 가상 모두와 동시 상호작용, 그리고 (c) 실제와 가상 간 양방향 상호작용. 각각에 대해 설명해보겠습니다:</p>
<p>우선, 실제와 가상은 인간 지각의 한계를 벗어난 정밀도로 3차원 공간에서 정렬되어야 합니다. 심지어 미묘한 결함은 환상을 파괴하고 당신의 두뇌는 실제와 가상을 분리된 인지로 인식할 것입니다. 두 영역은 또한 시간상으로 정렬되어야 하며, 이는 단순해 보이지만 컴퓨터 랙(특히 예전처럼) 때문에 종종 어려운 과제입니다.</p>
<p>그 다음, 두 영역은 동시에 상호작용해야 합니다. 이것은 사용자가 실제와 가상을 자연스럽게 동시에 상호작용할 수 있어야 한다는 것을 의미하며, 디지털 콘텐츠가 물리적 환경의 진정한 부분임을 보장하는 것입니다. 실제로, 물리적 상호작용(특히 손으로 상호작용)이 가장 설득력 있을 수 있다고 합니다. 예를 들어, 실제 물체를 잡고 가상 물체에 대해 자연스럽게 움직인다면, 환상이 굳게 성사됩니다. 제 추측으로는 눈은 쉽게 속일 수 있지만 우리의 두뇌는 좀 더 회의적이므로 두 세계를 수동적으로 조작하고 지각 일관성을 유지한다면, 두 세계를 두뇌가 하나로 연결시킬 수 있습니다.</p>
<p>그리고 마지막으로, 현실과 가상이 서로 상호 작용해야 하는 필요성이 실현되어야 합니다. 그 둘 간의 일관성이 없을 경우, 그 환상은 손상될 수 있습니다. 가상의 책을 가져와서 실제 탁자 위에 올려 놓았는데 투명하게 꿰뚫리면, 이는 단일 현실로 인식되지 않고 현실감을 잃어버리게 됩니다. 그러나 환상을 유지한다면, 당신의 두뇌는 수용체가 되어 당신은 단일 현실 안에 자신을 발견할 것입니다. 이것은 굉장히 납득이 가는 혼합 현실이며, 너무나 설득력이 있어 당신은 무엇이 실제이고 무엇이 가상인지에 대해 고민을 멈출 것입니다. 그것은 오직 단 한 가지의 현실뿐입니다.</p>
<p>Wright Patterson 공군기지(1991-1994)에서 개발된 Virtual Fixtures 플랫폼은 이런 지각적 요구사항을 처음으로 충족했고, 사용자들이 가상 물체(가상 가구)를 실제 세계에 유입되는 진정한 추가물로 인식할 수 있도록 했습니다. 오늘날 기준으로는 매우 초보적이지만, 원격 소유(disital attribution), 수동 상호작용, 양방향 상호작용, 3D 햅틱스와 3D 오디오를 통해 실시간 피드백을 제공하여 사용자들에게 최초의 혼합 현실 경험을 제공했습니다(즉, 통합된 지각 현실). 아래의 시스템은 1993년 실험 중에 사용된 것으로, 공간적으로 등록된 지각적 오버레이를 사용하여 사용자가 민첩한 실제 세계 작업을 수행하는 데 도움을 주었습니다.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:554/1*MurjNHOuRJQ6pnkIYD3_9w.gif" alt="이미지 업로드"></p>
<p>저는 원격 소유(disital attribution), 3D 등록, 동시 상호작용, 양방향 상호작용 등 지각적 요구사항을 언급했는데, 이것들은 Vision Pro가 얼마나 놀라운 장치인지를 설명하는 데 도움이 됩니다. 이는 이러한 기능을 극도의 정밀성으로 처음으로 구현한 제품으로서, 사용자에게 향후 경험을 방해할 결함 없이 장시간 동안 환상을 유지하는데 성공한 첫 제품입니다. 위에 나와 있는 공군의 프로토타입은 사용자에게 많은 제약을 가했으며 특정 작업을 위해 환상을 유지할 수밖에 없었습니다.</p>
<p>이제 언어로 돌아가서 — 현실과 가상이 결합된 두 가지 용어인 증강현실과 혼합현실이 어떻게 생겨났는지 알아볼까요? 저는 위의 비디오를 촬영할 때, 이 분야를 지칭하는 언어는 아직 없었습니다. 다행히도 증강현실이라는 용어가 Boeing에서 곧 나와 목표를 명확히 반영했습니다 — 가상 콘텐츠를 현실 환경에 추가하여 두 세계가 정확하게 정렬되고 자연스럽게 통합되어 마음속에서 하나로 합쳐지도록 하는 것이죠. 20년 동안 그게 바로 AR이 의미하는 것이었어요 (간단히 시야를 단순히 꾸미거나 주석을 달았던 장치는 원시적인 연결성 없이 기기로 글쎄, 전방 표시 장치로 불렸습니다).</p>
<p>그런데 2013년에 구글 글래스가 등장했죠. 저는 해당 제품을 깊이 존중하며 혁신적이라고 생각해요. 안타깝게도 언론은 잘못해서 그것을 증강현실이라고 착각했죠. 사실 그것은 아니었어요. 그것은 가상 콘텐츠를 현실 세계에 몰입적으로 공간적으로 등록되게 넣어주는 것이 아니었습니다. 반면에 그것은 우리가 지금 스마트 글라스라고 부르는 것, AI가 이 제품에 통합되면 더욱 더 유용해질 것이지만, 그것은 AR이 아니었습니다.</p>
<p>그래도 2010년대에는 증강현실이 약해졌어요. 구글 글래스 때문뿐만 아니라 스마트폰 제작사들이 간단한 시각적 오버레이를 "증강현실"로 추진했기 때문이죠, 비록 그것들이 몰입형이 아니었고 현실 세계와 진정한 3D 등록 기능이 없었습니다. 또한 사용자 상호 작용과 현실과 가상 사이의 양방향 상호 작용이 부족했어요. 이것은 LiDAR 및 다른 공간 매핑 기술이 스마트폰에 추가되기 전이었는데, 이것이 증가 수준의 3D 공간 등록 및 상호 작용을 가능케했어요. 오늘날의 스마트폰은 훨씬 더 나아졌지만 AR 용어는 퇴색되었어요.</p>
<p>결과적으로, 마이크로소프트가 통합된 지각현실을 육성하는 첫 상용 제품 (홀로렌즈)을 출시할 때, 그들은 이 장치를 이전 시스템의 언어에서 멀리하고자 했을 것으로 생각해요. 홀로렌즈를 출시하면서 마이크로소프트가 마케팅을 혼합현실이라는 단어로 집중했던 것은 아마도 그 때문일 거에요. 이 용어는 1990년대부터 존재했지만 홀로렌즈 출시를 계기로 언어가 정말로 확산되었어요. 이 용어는 사실상 진정한 증강현실을 만들거나, 내가 좀 더 엄밀히 설명하자면 — 현실과 가상을 통합된 지각현실로 만드는 것을 의미하도록 되었어요.</p>
<p>그리고 이제 우리는 사용자의 환경을 공간적으로 등록된 가상 콘텐츠로 보강하는 서로 다른 수준을 설명하는 두 가지 용어를 갖게 되었습니다. AR, MR 및 VR의 차이를 명확히 하기 위해, 우리는 미국 정부 감사청(GAO)이 2022년에 발표한 정의를 살펴볼 수 있습니다. GAO는 정부 계약이 VR, AR 또는 MR 장치에 대한 지불을 하는지 명확하게 하기 위해 이러한 차이에 신경 쓰는 것으로 추정됩니다. 이에 대응하여 GAO는 아래에 간단한 이미지가 포함된 공개 문서를 공개했습니다. 저는 그들의 구상을 좋아합니다. 그것은 원격 속성에 중점을 두어 중요한 상호 작용 문제에 접근합니다.</p>
<p><img src="/assets/img/2024-05-15-MixedRealityorSpatialComputing_2.png" alt="이미지"></p>
<p>AR와 MR의 차이가 하드웨어와 관련이 없고 지각 경험에만 얽혀 있다는 점은 주목할 가치가 있습니다. 많은 사람들이 잘못되게 AR 하드웨어가 사용자가 통과할 수 있는 투명 화면을 통해 엿볼 수 있는 안경을 의미하고, MR 하드웨어가 "투과 카메라"를 사용하여 실제 세계를 촬영하고 내부 화면에 사용자에게 보여준다고 잘못 믿고 있습니다. 하지만 이것은 사실이 아닙니다. 예를 들어, 1992년에 가상 픽스처 플랫폼을 개발할 때 투과 카메라가 사용되었습니다. 이 설계 선택은 실제와 가상을 더 높은 정밀도로 등록하기 쉽게 만들기 위한 것이었고, 사용자 경험을 바꾸기 위한 것이 아니었습니다. 게다가, 간단한 폰 기반 AR도 카메라를 사용하므로 이것이 차별화 요소가 아닙니다.</p>
<p>이것이 다시 Apple Vision Pro로 이어지게 됩니다. 그것은 혼합 현실 헤드셋입니다. 투과 카메라를 사용하기 때문이 아니라, 사용자가 실제와 가상의 통합된 지각 현실을 경험할 수 있기 때문입니다. 그리고 혼합 현실이 슈퍼셋 기능임으로, Vision Pro는 보다 간단한 증강 현실 경험과 완전히 시뮬레이션된 가상 현실 경험도 제공할 수 있습니다. 그리고 VR, AR 및 MR 모두에 대해, Vision Pro는 어느 가격으로도 만들어진 장치를 뛰어넘는 몰입형 경험으로 소비자들을 놀라게 할 수 있습니다. 이것은 Apple에게 진정한 혁신이며, 이를 실현시킨 엔지니어 팀에 대한 업적입니다.</p>
<p><img src="/assets/img/2024-05-15-MixedRealityorSpatialComputing_3.png" alt="2024-05-15-MixedRealityorSpatialComputing_3"></p>
<p>비전 프로(Vision Pro)는 사용자의 시선 방향을 입력으로 사용하는 공간 운영 시스템(visionOS)과 같은 완전히 독특한 능력을 제공하여 새로운 영역을 개척합니다. 다시 말해, 저는 비전 프로가 혼합 현실 헤드셋뿐만 아니라 공간 컴퓨터이자 사실상 예술 작품이라고 동의합니다. 또한 저는 증강 현실, 혼합 현실, 가상 현실을 비롯한 3D 영화와 원격 존재감과 같은 다른 몰입형 경험을 포함하여 AR, MR, VR과 같은 경이로운 용어에 대한 범용 용어인 공간 컴퓨팅이 훌륭한 용어라고 믿습니다. 제 유일한 권고는 모든 기업이 이 분야의 역사적이고 받아들여진 언어를 받아들이는 것입니다. 공간 컴퓨팅은 유용한 용어지만, 증강 현실, 혼합 현실, 가상 현실도 모두 우리의 역사와 문화의 일부입니다.</p>
<p>Louis Rosenberg 박사는 가상 현실, 증강 현실, 인공지능 분야의 오랜 연구자입니다. 그는 1993년 Immersion Corporation (IMMR: Nasdaq)와 2014년 Unanimous AI를 창립하고 공군 연구소에서 혼합 현실 개발하는 데로 알려져 있습니다. 그의 새 책인 Our Next Reality는 Hachette로부터 예약 구매 가능합니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"혼합 현실 또는 공간 컴퓨팅","description":"","date":"2024-05-15 19:35","slug":"2024-05-15-MixedRealityorSpatialComputing","content":"\n\n매력적으로 함축적인 매체 언어 - 과거와 현재\n\n![image](/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png)\n\n최근 기자들이 자주 묻는 질문이 있어요: 공간 컴퓨팅과 혼합 현실의 차이는 뭔가요? 대답하자마자 더 많은 질문이 나오며 현실적인 매체의 언어와 오늘날 사용되는 다양한 문구에 대한 이해가 필요하다고 느껴져요. 혼란을 줄이기 위해, 핵심적인 용어들의 역사와 인지적 의미를 살펴보는 것이 도움이 된다고 생각해요.\n\n저는 개인적으로 애플의 공간 컴퓨팅이라는 표현을 좋아하고 Vision Pro가 공간 컴퓨터라고 동의합니다. 하지만, 이로 인해 혼란이 더해졌어요. 결국 대부분의 사람들이 Vision Pro를 혼합 현실 헤드셋이라고 부르지만, 애플만 아닐 뿐이에요. 또한, 개발자들은 Vision Pro 앱을 가상 현실, 혼합 현실 또는 증강 현실을 활성화하는 것으로 설명할 수 없어요. 이는 마케팅 상의 이유를 이해하고, 이러한 언어 제한이 시간이 흐르면 사라질 것으로 예상하지만, 애플이 특정 단어를 금지하는 것은 지나친 것으로 보여요.\n\n\n\n아마도 난 그냥 향수에 젖어 있는 걸 수도 있지만, 처음 분야를 시작했을 때 가상 현실이라는 문구가 몇 년 전에 나왔을 뿐인데도 이미 큰 관심을 불러일으켰어요. 저는 NASA에서 VR 실험을 수행하는 젊은 연구원이었고, 위의 사진은 저가 일하고 있던 연구소에 걸려 있던 포스터였어요. 저에게는 그가 제시하는 완전한 약속을 담은 깊은 영감을 주는 이미지였어요.\n\n게다가, 해당 NASA 사진에 나타난 인간 경험은 거의 40년 동안 가상 현실로 불려 왔어요. 만약 Vision Pro 개발자이고 완전히 시뮬레이트된 몰입형 경험을 만든다면, 그것을 가상 현실로 설명하는 것이 정말 죄인일까요? 결국, 위에 보이는 VR 헤드셋은 지금 스미스소니안 박물관에 전시되어 있어요. 이것은 우리의 역사이면서 우리 문화입니다.\n\n물론, Vision Pro는 NASA 헤드셋에 비해 훨씬 정교하며 놀라운 선명도 뿐만 아니라 완전히 새로운 기능을 추가했기 때문에 더욱 우수해요. Vision Pro의 가장 중요한 기능은 현실 세계와 공간적으로 투사된 가상 내용을 원활하게 결합하여 단일 통합 경험을 만들어내는 능력입니다. 이를 확장 현실 또는 복합 현실이라고 부르며 기능에 따라 두 용어는 학계와 산업에서 오랜 역사를 갖고 있어요.\n\n그렇다면, AR과 MR의 차이점은 무엇일까요?\n\n\n\n세계적인 가상현실 산업에서 가장 오해받는 문제 중 하나일 것 같아요. 그래서 오늘날의 분화가 어떻게 생겨났는지 설명하기 위해 과거로 돌아가는 것은 가치가 있어요. 초기에는 '증강현실'이라는 한 마디만으로 충분했지만, 2010년대에는 마케터들이 더 간단한 시스템들을 그 이름 아래로 푼 것 때문에 그 정의가 희석되었죠. 미래에는 진자가 다시 돌아갈 것으로 생각되지만, 현재로서는 두 용어 모두 유용해요. 그 이유를 이해하려면 사용자의 현실을 확실하고 진실되게 증강하는 데 필요한 지각 요건에 대해 깊게 파고들어야 해요.\n\n제 배경을 말씀드리자면, 1991년에 현실과 가상을 융합하는 작업을 시작했는데, 그 당시에는 그러한 결합 경험을 설명할 언어조차 없었어요. 스탠포드 대학, NASA, 미국 공군에서의 초기 연구는 물리적이고 가상적인 통합 지각현실을 만들기 위해 필요한 기본 심리물리학적 요소들을 탐색하기 위한 것이었어요. 이 새로운 추구를 \"지각 디자인\"이라고 불렀고(매우 매력적이진 않죠), 가상 물체들을 \"지각 오버레이\"라고 명명했어요(이것 역시 매력적이진 않아요). 그 당시의 진짜와 믿을 만한 혼합 현실을 만드는 데 필요한 핵심 지각 요소들을 설명한 것이 아래와 같아요:\n\n- 지각 오버레이: \"지각 오버레이의 성질 또는 내용에 제한을 두지 않으려 합니다. 단 한 가지 요구할 건, 작용자의 신경 운동 활동(efference)과 그 뒤에 오는 지각 오버레이에 포함된 감각의 변화(afference) 사이에 자연스럽고 예측 가능한 관계가 존재해야 한다는 것뿐입니다. 이 하나의 제약 조건만으로도 원격 속성 부여를 촉진합니다. 그 결과, 원격 속성 부여로 인해 작용자는 오버레이된 지각을 주변 현실의 실제적이고 만질 수 있는 부분으로 받아들입니다. 다시 말해, 작용자는 오버레이된 지각 정보에 대한 존재감을 느낄 것입니다. 따라서, 작용자는 가상 지각을 환경의 진짜 특성이나 속성으로 받아들일 것입니다.\" (스탠포드, 로젠버그, 1993)\n\n이 부분은 다소 어렵게 보일 수 있지만, \"원격 속성 부여\"라는 핵심 구절이 중요해요. 이는 새로운 지각 정보가 뇌로 들어와 그것을 주변 환경의 진짜 일부로 통합하는 과정을 말해요. 따라서 위의 지침은 가상 물체가 주변 현실의 진짜 일부로 인식되려면 상호작용적 경험을 가능케 해야 한다고 설명하고 있어요. 수동적 관찰만으로는 충분하지 않습니다. 왜냐하면 그것은 작용과 반응(즉, 행동과 반응) 사이의 정신적 루프를 닫지 않기 때문이에요. 이것이 왜 특정 위치에서 촬영된 360도 가상현실 영화가 현실같지 않게 느껴지는지에 대한 이유입니다. 머리를 돌리고 깊이 지각을 할 수 있더라도 움직이거나 손을 뻗는 등 상호작용할 수 없기 때문에 뇌는 그것을 시야에 있는 장식으로 인식하고 진짜 현실로 인식하지 않는 것이죠.\n\n\n\n![Image](/assets/img/2024-05-15-MixedRealityorSpatialComputing_1.png)\n\n믹스 리얼리티(Mixed Reality)를 통합하는 데 필수 요소인 원격 속성을 식별하는 것은 도움이 되었지만, 실제와 가상을 현실적으로 융합하기 위해 충족되어야 하는 추가적인 지각 요구사항에 직면하게 되었습니다. 이 요구사항은 다음과 같이 요약할 수 있습니다: (a) 완전한 3D 공간에서 정확한 공간 정렬, (b) 실제와 가상 모두와 동시 상호작용, 그리고 (c) 실제와 가상 간 양방향 상호작용. 각각에 대해 설명해보겠습니다:\n\n우선, 실제와 가상은 인간 지각의 한계를 벗어난 정밀도로 3차원 공간에서 정렬되어야 합니다. 심지어 미묘한 결함은 환상을 파괴하고 당신의 두뇌는 실제와 가상을 분리된 인지로 인식할 것입니다. 두 영역은 또한 시간상으로 정렬되어야 하며, 이는 단순해 보이지만 컴퓨터 랙(특히 예전처럼) 때문에 종종 어려운 과제입니다.\n\n그 다음, 두 영역은 동시에 상호작용해야 합니다. 이것은 사용자가 실제와 가상을 자연스럽게 동시에 상호작용할 수 있어야 한다는 것을 의미하며, 디지털 콘텐츠가 물리적 환경의 진정한 부분임을 보장하는 것입니다. 실제로, 물리적 상호작용(특히 손으로 상호작용)이 가장 설득력 있을 수 있다고 합니다. 예를 들어, 실제 물체를 잡고 가상 물체에 대해 자연스럽게 움직인다면, 환상이 굳게 성사됩니다. 제 추측으로는 눈은 쉽게 속일 수 있지만 우리의 두뇌는 좀 더 회의적이므로 두 세계를 수동적으로 조작하고 지각 일관성을 유지한다면, 두 세계를 두뇌가 하나로 연결시킬 수 있습니다.\n\n\n\n그리고 마지막으로, 현실과 가상이 서로 상호 작용해야 하는 필요성이 실현되어야 합니다. 그 둘 간의 일관성이 없을 경우, 그 환상은 손상될 수 있습니다. 가상의 책을 가져와서 실제 탁자 위에 올려 놓았는데 투명하게 꿰뚫리면, 이는 단일 현실로 인식되지 않고 현실감을 잃어버리게 됩니다. 그러나 환상을 유지한다면, 당신의 두뇌는 수용체가 되어 당신은 단일 현실 안에 자신을 발견할 것입니다. 이것은 굉장히 납득이 가는 혼합 현실이며, 너무나 설득력이 있어 당신은 무엇이 실제이고 무엇이 가상인지에 대해 고민을 멈출 것입니다. 그것은 오직 단 한 가지의 현실뿐입니다.\n\nWright Patterson 공군기지(1991-1994)에서 개발된 Virtual Fixtures 플랫폼은 이런 지각적 요구사항을 처음으로 충족했고, 사용자들이 가상 물체(가상 가구)를 실제 세계에 유입되는 진정한 추가물로 인식할 수 있도록 했습니다. 오늘날 기준으로는 매우 초보적이지만, 원격 소유(disital attribution), 수동 상호작용, 양방향 상호작용, 3D 햅틱스와 3D 오디오를 통해 실시간 피드백을 제공하여 사용자들에게 최초의 혼합 현실 경험을 제공했습니다(즉, 통합된 지각 현실). 아래의 시스템은 1993년 실험 중에 사용된 것으로, 공간적으로 등록된 지각적 오버레이를 사용하여 사용자가 민첩한 실제 세계 작업을 수행하는 데 도움을 주었습니다.\n\n![이미지 업로드](https://miro.medium.com/v2/resize:fit:554/1*MurjNHOuRJQ6pnkIYD3_9w.gif)\n\n저는 원격 소유(disital attribution), 3D 등록, 동시 상호작용, 양방향 상호작용 등 지각적 요구사항을 언급했는데, 이것들은 Vision Pro가 얼마나 놀라운 장치인지를 설명하는 데 도움이 됩니다. 이는 이러한 기능을 극도의 정밀성으로 처음으로 구현한 제품으로서, 사용자에게 향후 경험을 방해할 결함 없이 장시간 동안 환상을 유지하는데 성공한 첫 제품입니다. 위에 나와 있는 공군의 프로토타입은 사용자에게 많은 제약을 가했으며 특정 작업을 위해 환상을 유지할 수밖에 없었습니다.\n\n\n\n이제 언어로 돌아가서 — 현실과 가상이 결합된 두 가지 용어인 증강현실과 혼합현실이 어떻게 생겨났는지 알아볼까요? 저는 위의 비디오를 촬영할 때, 이 분야를 지칭하는 언어는 아직 없었습니다. 다행히도 증강현실이라는 용어가 Boeing에서 곧 나와 목표를 명확히 반영했습니다 — 가상 콘텐츠를 현실 환경에 추가하여 두 세계가 정확하게 정렬되고 자연스럽게 통합되어 마음속에서 하나로 합쳐지도록 하는 것이죠. 20년 동안 그게 바로 AR이 의미하는 것이었어요 (간단히 시야를 단순히 꾸미거나 주석을 달았던 장치는 원시적인 연결성 없이 기기로 글쎄, 전방 표시 장치로 불렸습니다).\n\n그런데 2013년에 구글 글래스가 등장했죠. 저는 해당 제품을 깊이 존중하며 혁신적이라고 생각해요. 안타깝게도 언론은 잘못해서 그것을 증강현실이라고 착각했죠. 사실 그것은 아니었어요. 그것은 가상 콘텐츠를 현실 세계에 몰입적으로 공간적으로 등록되게 넣어주는 것이 아니었습니다. 반면에 그것은 우리가 지금 스마트 글라스라고 부르는 것, AI가 이 제품에 통합되면 더욱 더 유용해질 것이지만, 그것은 AR이 아니었습니다.\n\n그래도 2010년대에는 증강현실이 약해졌어요. 구글 글래스 때문뿐만 아니라 스마트폰 제작사들이 간단한 시각적 오버레이를 \"증강현실\"로 추진했기 때문이죠, 비록 그것들이 몰입형이 아니었고 현실 세계와 진정한 3D 등록 기능이 없었습니다. 또한 사용자 상호 작용과 현실과 가상 사이의 양방향 상호 작용이 부족했어요. 이것은 LiDAR 및 다른 공간 매핑 기술이 스마트폰에 추가되기 전이었는데, 이것이 증가 수준의 3D 공간 등록 및 상호 작용을 가능케했어요. 오늘날의 스마트폰은 훨씬 더 나아졌지만 AR 용어는 퇴색되었어요.\n\n결과적으로, 마이크로소프트가 통합된 지각현실을 육성하는 첫 상용 제품 (홀로렌즈)을 출시할 때, 그들은 이 장치를 이전 시스템의 언어에서 멀리하고자 했을 것으로 생각해요. 홀로렌즈를 출시하면서 마이크로소프트가 마케팅을 혼합현실이라는 단어로 집중했던 것은 아마도 그 때문일 거에요. 이 용어는 1990년대부터 존재했지만 홀로렌즈 출시를 계기로 언어가 정말로 확산되었어요. 이 용어는 사실상 진정한 증강현실을 만들거나, 내가 좀 더 엄밀히 설명하자면 — 현실과 가상을 통합된 지각현실로 만드는 것을 의미하도록 되었어요.\n\n\n\n그리고 이제 우리는 사용자의 환경을 공간적으로 등록된 가상 콘텐츠로 보강하는 서로 다른 수준을 설명하는 두 가지 용어를 갖게 되었습니다. AR, MR 및 VR의 차이를 명확히 하기 위해, 우리는 미국 정부 감사청(GAO)이 2022년에 발표한 정의를 살펴볼 수 있습니다. GAO는 정부 계약이 VR, AR 또는 MR 장치에 대한 지불을 하는지 명확하게 하기 위해 이러한 차이에 신경 쓰는 것으로 추정됩니다. 이에 대응하여 GAO는 아래에 간단한 이미지가 포함된 공개 문서를 공개했습니다. 저는 그들의 구상을 좋아합니다. 그것은 원격 속성에 중점을 두어 중요한 상호 작용 문제에 접근합니다.\n\n![이미지](/assets/img/2024-05-15-MixedRealityorSpatialComputing_2.png)\n\nAR와 MR의 차이가 하드웨어와 관련이 없고 지각 경험에만 얽혀 있다는 점은 주목할 가치가 있습니다. 많은 사람들이 잘못되게 AR 하드웨어가 사용자가 통과할 수 있는 투명 화면을 통해 엿볼 수 있는 안경을 의미하고, MR 하드웨어가 \"투과 카메라\"를 사용하여 실제 세계를 촬영하고 내부 화면에 사용자에게 보여준다고 잘못 믿고 있습니다. 하지만 이것은 사실이 아닙니다. 예를 들어, 1992년에 가상 픽스처 플랫폼을 개발할 때 투과 카메라가 사용되었습니다. 이 설계 선택은 실제와 가상을 더 높은 정밀도로 등록하기 쉽게 만들기 위한 것이었고, 사용자 경험을 바꾸기 위한 것이 아니었습니다. 게다가, 간단한 폰 기반 AR도 카메라를 사용하므로 이것이 차별화 요소가 아닙니다.\n\n이것이 다시 Apple Vision Pro로 이어지게 됩니다. 그것은 혼합 현실 헤드셋입니다. 투과 카메라를 사용하기 때문이 아니라, 사용자가 실제와 가상의 통합된 지각 현실을 경험할 수 있기 때문입니다. 그리고 혼합 현실이 슈퍼셋 기능임으로, Vision Pro는 보다 간단한 증강 현실 경험과 완전히 시뮬레이션된 가상 현실 경험도 제공할 수 있습니다. 그리고 VR, AR 및 MR 모두에 대해, Vision Pro는 어느 가격으로도 만들어진 장치를 뛰어넘는 몰입형 경험으로 소비자들을 놀라게 할 수 있습니다. 이것은 Apple에게 진정한 혁신이며, 이를 실현시킨 엔지니어 팀에 대한 업적입니다.\n\n\n\n![2024-05-15-MixedRealityorSpatialComputing_3](/assets/img/2024-05-15-MixedRealityorSpatialComputing_3.png)\n\n비전 프로(Vision Pro)는 사용자의 시선 방향을 입력으로 사용하는 공간 운영 시스템(visionOS)과 같은 완전히 독특한 능력을 제공하여 새로운 영역을 개척합니다. 다시 말해, 저는 비전 프로가 혼합 현실 헤드셋뿐만 아니라 공간 컴퓨터이자 사실상 예술 작품이라고 동의합니다. 또한 저는 증강 현실, 혼합 현실, 가상 현실을 비롯한 3D 영화와 원격 존재감과 같은 다른 몰입형 경험을 포함하여 AR, MR, VR과 같은 경이로운 용어에 대한 범용 용어인 공간 컴퓨팅이 훌륭한 용어라고 믿습니다. 제 유일한 권고는 모든 기업이 이 분야의 역사적이고 받아들여진 언어를 받아들이는 것입니다. 공간 컴퓨팅은 유용한 용어지만, 증강 현실, 혼합 현실, 가상 현실도 모두 우리의 역사와 문화의 일부입니다.\n\nLouis Rosenberg 박사는 가상 현실, 증강 현실, 인공지능 분야의 오랜 연구자입니다. 그는 1993년 Immersion Corporation (IMMR: Nasdaq)와 2014년 Unanimous AI를 창립하고 공군 연구소에서 혼합 현실 개발하는 데로 알려져 있습니다. 그의 새 책인 Our Next Reality는 Hachette로부터 예약 구매 가능합니다.","ogImage":{"url":"/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png"},"coverImage":"/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png","tag":["Tech"],"readingTime":8},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e매력적으로 함축적인 매체 언어 - 과거와 현재\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-MixedRealityorSpatialComputing_0.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e최근 기자들이 자주 묻는 질문이 있어요: 공간 컴퓨팅과 혼합 현실의 차이는 뭔가요? 대답하자마자 더 많은 질문이 나오며 현실적인 매체의 언어와 오늘날 사용되는 다양한 문구에 대한 이해가 필요하다고 느껴져요. 혼란을 줄이기 위해, 핵심적인 용어들의 역사와 인지적 의미를 살펴보는 것이 도움이 된다고 생각해요.\u003c/p\u003e\n\u003cp\u003e저는 개인적으로 애플의 공간 컴퓨팅이라는 표현을 좋아하고 Vision Pro가 공간 컴퓨터라고 동의합니다. 하지만, 이로 인해 혼란이 더해졌어요. 결국 대부분의 사람들이 Vision Pro를 혼합 현실 헤드셋이라고 부르지만, 애플만 아닐 뿐이에요. 또한, 개발자들은 Vision Pro 앱을 가상 현실, 혼합 현실 또는 증강 현실을 활성화하는 것으로 설명할 수 없어요. 이는 마케팅 상의 이유를 이해하고, 이러한 언어 제한이 시간이 흐르면 사라질 것으로 예상하지만, 애플이 특정 단어를 금지하는 것은 지나친 것으로 보여요.\u003c/p\u003e\n\u003cp\u003e아마도 난 그냥 향수에 젖어 있는 걸 수도 있지만, 처음 분야를 시작했을 때 가상 현실이라는 문구가 몇 년 전에 나왔을 뿐인데도 이미 큰 관심을 불러일으켰어요. 저는 NASA에서 VR 실험을 수행하는 젊은 연구원이었고, 위의 사진은 저가 일하고 있던 연구소에 걸려 있던 포스터였어요. 저에게는 그가 제시하는 완전한 약속을 담은 깊은 영감을 주는 이미지였어요.\u003c/p\u003e\n\u003cp\u003e게다가, 해당 NASA 사진에 나타난 인간 경험은 거의 40년 동안 가상 현실로 불려 왔어요. 만약 Vision Pro 개발자이고 완전히 시뮬레이트된 몰입형 경험을 만든다면, 그것을 가상 현실로 설명하는 것이 정말 죄인일까요? 결국, 위에 보이는 VR 헤드셋은 지금 스미스소니안 박물관에 전시되어 있어요. 이것은 우리의 역사이면서 우리 문화입니다.\u003c/p\u003e\n\u003cp\u003e물론, Vision Pro는 NASA 헤드셋에 비해 훨씬 정교하며 놀라운 선명도 뿐만 아니라 완전히 새로운 기능을 추가했기 때문에 더욱 우수해요. Vision Pro의 가장 중요한 기능은 현실 세계와 공간적으로 투사된 가상 내용을 원활하게 결합하여 단일 통합 경험을 만들어내는 능력입니다. 이를 확장 현실 또는 복합 현실이라고 부르며 기능에 따라 두 용어는 학계와 산업에서 오랜 역사를 갖고 있어요.\u003c/p\u003e\n\u003cp\u003e그렇다면, AR과 MR의 차이점은 무엇일까요?\u003c/p\u003e\n\u003cp\u003e세계적인 가상현실 산업에서 가장 오해받는 문제 중 하나일 것 같아요. 그래서 오늘날의 분화가 어떻게 생겨났는지 설명하기 위해 과거로 돌아가는 것은 가치가 있어요. 초기에는 '증강현실'이라는 한 마디만으로 충분했지만, 2010년대에는 마케터들이 더 간단한 시스템들을 그 이름 아래로 푼 것 때문에 그 정의가 희석되었죠. 미래에는 진자가 다시 돌아갈 것으로 생각되지만, 현재로서는 두 용어 모두 유용해요. 그 이유를 이해하려면 사용자의 현실을 확실하고 진실되게 증강하는 데 필요한 지각 요건에 대해 깊게 파고들어야 해요.\u003c/p\u003e\n\u003cp\u003e제 배경을 말씀드리자면, 1991년에 현실과 가상을 융합하는 작업을 시작했는데, 그 당시에는 그러한 결합 경험을 설명할 언어조차 없었어요. 스탠포드 대학, NASA, 미국 공군에서의 초기 연구는 물리적이고 가상적인 통합 지각현실을 만들기 위해 필요한 기본 심리물리학적 요소들을 탐색하기 위한 것이었어요. 이 새로운 추구를 \"지각 디자인\"이라고 불렀고(매우 매력적이진 않죠), 가상 물체들을 \"지각 오버레이\"라고 명명했어요(이것 역시 매력적이진 않아요). 그 당시의 진짜와 믿을 만한 혼합 현실을 만드는 데 필요한 핵심 지각 요소들을 설명한 것이 아래와 같아요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e지각 오버레이: \"지각 오버레이의 성질 또는 내용에 제한을 두지 않으려 합니다. 단 한 가지 요구할 건, 작용자의 신경 운동 활동(efference)과 그 뒤에 오는 지각 오버레이에 포함된 감각의 변화(afference) 사이에 자연스럽고 예측 가능한 관계가 존재해야 한다는 것뿐입니다. 이 하나의 제약 조건만으로도 원격 속성 부여를 촉진합니다. 그 결과, 원격 속성 부여로 인해 작용자는 오버레이된 지각을 주변 현실의 실제적이고 만질 수 있는 부분으로 받아들입니다. 다시 말해, 작용자는 오버레이된 지각 정보에 대한 존재감을 느낄 것입니다. 따라서, 작용자는 가상 지각을 환경의 진짜 특성이나 속성으로 받아들일 것입니다.\" (스탠포드, 로젠버그, 1993)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 부분은 다소 어렵게 보일 수 있지만, \"원격 속성 부여\"라는 핵심 구절이 중요해요. 이는 새로운 지각 정보가 뇌로 들어와 그것을 주변 환경의 진짜 일부로 통합하는 과정을 말해요. 따라서 위의 지침은 가상 물체가 주변 현실의 진짜 일부로 인식되려면 상호작용적 경험을 가능케 해야 한다고 설명하고 있어요. 수동적 관찰만으로는 충분하지 않습니다. 왜냐하면 그것은 작용과 반응(즉, 행동과 반응) 사이의 정신적 루프를 닫지 않기 때문이에요. 이것이 왜 특정 위치에서 촬영된 360도 가상현실 영화가 현실같지 않게 느껴지는지에 대한 이유입니다. 머리를 돌리고 깊이 지각을 할 수 있더라도 움직이거나 손을 뻗는 등 상호작용할 수 없기 때문에 뇌는 그것을 시야에 있는 장식으로 인식하고 진짜 현실로 인식하지 않는 것이죠.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-MixedRealityorSpatialComputing_1.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e믹스 리얼리티(Mixed Reality)를 통합하는 데 필수 요소인 원격 속성을 식별하는 것은 도움이 되었지만, 실제와 가상을 현실적으로 융합하기 위해 충족되어야 하는 추가적인 지각 요구사항에 직면하게 되었습니다. 이 요구사항은 다음과 같이 요약할 수 있습니다: (a) 완전한 3D 공간에서 정확한 공간 정렬, (b) 실제와 가상 모두와 동시 상호작용, 그리고 (c) 실제와 가상 간 양방향 상호작용. 각각에 대해 설명해보겠습니다:\u003c/p\u003e\n\u003cp\u003e우선, 실제와 가상은 인간 지각의 한계를 벗어난 정밀도로 3차원 공간에서 정렬되어야 합니다. 심지어 미묘한 결함은 환상을 파괴하고 당신의 두뇌는 실제와 가상을 분리된 인지로 인식할 것입니다. 두 영역은 또한 시간상으로 정렬되어야 하며, 이는 단순해 보이지만 컴퓨터 랙(특히 예전처럼) 때문에 종종 어려운 과제입니다.\u003c/p\u003e\n\u003cp\u003e그 다음, 두 영역은 동시에 상호작용해야 합니다. 이것은 사용자가 실제와 가상을 자연스럽게 동시에 상호작용할 수 있어야 한다는 것을 의미하며, 디지털 콘텐츠가 물리적 환경의 진정한 부분임을 보장하는 것입니다. 실제로, 물리적 상호작용(특히 손으로 상호작용)이 가장 설득력 있을 수 있다고 합니다. 예를 들어, 실제 물체를 잡고 가상 물체에 대해 자연스럽게 움직인다면, 환상이 굳게 성사됩니다. 제 추측으로는 눈은 쉽게 속일 수 있지만 우리의 두뇌는 좀 더 회의적이므로 두 세계를 수동적으로 조작하고 지각 일관성을 유지한다면, 두 세계를 두뇌가 하나로 연결시킬 수 있습니다.\u003c/p\u003e\n\u003cp\u003e그리고 마지막으로, 현실과 가상이 서로 상호 작용해야 하는 필요성이 실현되어야 합니다. 그 둘 간의 일관성이 없을 경우, 그 환상은 손상될 수 있습니다. 가상의 책을 가져와서 실제 탁자 위에 올려 놓았는데 투명하게 꿰뚫리면, 이는 단일 현실로 인식되지 않고 현실감을 잃어버리게 됩니다. 그러나 환상을 유지한다면, 당신의 두뇌는 수용체가 되어 당신은 단일 현실 안에 자신을 발견할 것입니다. 이것은 굉장히 납득이 가는 혼합 현실이며, 너무나 설득력이 있어 당신은 무엇이 실제이고 무엇이 가상인지에 대해 고민을 멈출 것입니다. 그것은 오직 단 한 가지의 현실뿐입니다.\u003c/p\u003e\n\u003cp\u003eWright Patterson 공군기지(1991-1994)에서 개발된 Virtual Fixtures 플랫폼은 이런 지각적 요구사항을 처음으로 충족했고, 사용자들이 가상 물체(가상 가구)를 실제 세계에 유입되는 진정한 추가물로 인식할 수 있도록 했습니다. 오늘날 기준으로는 매우 초보적이지만, 원격 소유(disital attribution), 수동 상호작용, 양방향 상호작용, 3D 햅틱스와 3D 오디오를 통해 실시간 피드백을 제공하여 사용자들에게 최초의 혼합 현실 경험을 제공했습니다(즉, 통합된 지각 현실). 아래의 시스템은 1993년 실험 중에 사용된 것으로, 공간적으로 등록된 지각적 오버레이를 사용하여 사용자가 민첩한 실제 세계 작업을 수행하는 데 도움을 주었습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:554/1*MurjNHOuRJQ6pnkIYD3_9w.gif\" alt=\"이미지 업로드\"\u003e\u003c/p\u003e\n\u003cp\u003e저는 원격 소유(disital attribution), 3D 등록, 동시 상호작용, 양방향 상호작용 등 지각적 요구사항을 언급했는데, 이것들은 Vision Pro가 얼마나 놀라운 장치인지를 설명하는 데 도움이 됩니다. 이는 이러한 기능을 극도의 정밀성으로 처음으로 구현한 제품으로서, 사용자에게 향후 경험을 방해할 결함 없이 장시간 동안 환상을 유지하는데 성공한 첫 제품입니다. 위에 나와 있는 공군의 프로토타입은 사용자에게 많은 제약을 가했으며 특정 작업을 위해 환상을 유지할 수밖에 없었습니다.\u003c/p\u003e\n\u003cp\u003e이제 언어로 돌아가서 — 현실과 가상이 결합된 두 가지 용어인 증강현실과 혼합현실이 어떻게 생겨났는지 알아볼까요? 저는 위의 비디오를 촬영할 때, 이 분야를 지칭하는 언어는 아직 없었습니다. 다행히도 증강현실이라는 용어가 Boeing에서 곧 나와 목표를 명확히 반영했습니다 — 가상 콘텐츠를 현실 환경에 추가하여 두 세계가 정확하게 정렬되고 자연스럽게 통합되어 마음속에서 하나로 합쳐지도록 하는 것이죠. 20년 동안 그게 바로 AR이 의미하는 것이었어요 (간단히 시야를 단순히 꾸미거나 주석을 달았던 장치는 원시적인 연결성 없이 기기로 글쎄, 전방 표시 장치로 불렸습니다).\u003c/p\u003e\n\u003cp\u003e그런데 2013년에 구글 글래스가 등장했죠. 저는 해당 제품을 깊이 존중하며 혁신적이라고 생각해요. 안타깝게도 언론은 잘못해서 그것을 증강현실이라고 착각했죠. 사실 그것은 아니었어요. 그것은 가상 콘텐츠를 현실 세계에 몰입적으로 공간적으로 등록되게 넣어주는 것이 아니었습니다. 반면에 그것은 우리가 지금 스마트 글라스라고 부르는 것, AI가 이 제품에 통합되면 더욱 더 유용해질 것이지만, 그것은 AR이 아니었습니다.\u003c/p\u003e\n\u003cp\u003e그래도 2010년대에는 증강현실이 약해졌어요. 구글 글래스 때문뿐만 아니라 스마트폰 제작사들이 간단한 시각적 오버레이를 \"증강현실\"로 추진했기 때문이죠, 비록 그것들이 몰입형이 아니었고 현실 세계와 진정한 3D 등록 기능이 없었습니다. 또한 사용자 상호 작용과 현실과 가상 사이의 양방향 상호 작용이 부족했어요. 이것은 LiDAR 및 다른 공간 매핑 기술이 스마트폰에 추가되기 전이었는데, 이것이 증가 수준의 3D 공간 등록 및 상호 작용을 가능케했어요. 오늘날의 스마트폰은 훨씬 더 나아졌지만 AR 용어는 퇴색되었어요.\u003c/p\u003e\n\u003cp\u003e결과적으로, 마이크로소프트가 통합된 지각현실을 육성하는 첫 상용 제품 (홀로렌즈)을 출시할 때, 그들은 이 장치를 이전 시스템의 언어에서 멀리하고자 했을 것으로 생각해요. 홀로렌즈를 출시하면서 마이크로소프트가 마케팅을 혼합현실이라는 단어로 집중했던 것은 아마도 그 때문일 거에요. 이 용어는 1990년대부터 존재했지만 홀로렌즈 출시를 계기로 언어가 정말로 확산되었어요. 이 용어는 사실상 진정한 증강현실을 만들거나, 내가 좀 더 엄밀히 설명하자면 — 현실과 가상을 통합된 지각현실로 만드는 것을 의미하도록 되었어요.\u003c/p\u003e\n\u003cp\u003e그리고 이제 우리는 사용자의 환경을 공간적으로 등록된 가상 콘텐츠로 보강하는 서로 다른 수준을 설명하는 두 가지 용어를 갖게 되었습니다. AR, MR 및 VR의 차이를 명확히 하기 위해, 우리는 미국 정부 감사청(GAO)이 2022년에 발표한 정의를 살펴볼 수 있습니다. GAO는 정부 계약이 VR, AR 또는 MR 장치에 대한 지불을 하는지 명확하게 하기 위해 이러한 차이에 신경 쓰는 것으로 추정됩니다. 이에 대응하여 GAO는 아래에 간단한 이미지가 포함된 공개 문서를 공개했습니다. 저는 그들의 구상을 좋아합니다. 그것은 원격 속성에 중점을 두어 중요한 상호 작용 문제에 접근합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-MixedRealityorSpatialComputing_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eAR와 MR의 차이가 하드웨어와 관련이 없고 지각 경험에만 얽혀 있다는 점은 주목할 가치가 있습니다. 많은 사람들이 잘못되게 AR 하드웨어가 사용자가 통과할 수 있는 투명 화면을 통해 엿볼 수 있는 안경을 의미하고, MR 하드웨어가 \"투과 카메라\"를 사용하여 실제 세계를 촬영하고 내부 화면에 사용자에게 보여준다고 잘못 믿고 있습니다. 하지만 이것은 사실이 아닙니다. 예를 들어, 1992년에 가상 픽스처 플랫폼을 개발할 때 투과 카메라가 사용되었습니다. 이 설계 선택은 실제와 가상을 더 높은 정밀도로 등록하기 쉽게 만들기 위한 것이었고, 사용자 경험을 바꾸기 위한 것이 아니었습니다. 게다가, 간단한 폰 기반 AR도 카메라를 사용하므로 이것이 차별화 요소가 아닙니다.\u003c/p\u003e\n\u003cp\u003e이것이 다시 Apple Vision Pro로 이어지게 됩니다. 그것은 혼합 현실 헤드셋입니다. 투과 카메라를 사용하기 때문이 아니라, 사용자가 실제와 가상의 통합된 지각 현실을 경험할 수 있기 때문입니다. 그리고 혼합 현실이 슈퍼셋 기능임으로, Vision Pro는 보다 간단한 증강 현실 경험과 완전히 시뮬레이션된 가상 현실 경험도 제공할 수 있습니다. 그리고 VR, AR 및 MR 모두에 대해, Vision Pro는 어느 가격으로도 만들어진 장치를 뛰어넘는 몰입형 경험으로 소비자들을 놀라게 할 수 있습니다. 이것은 Apple에게 진정한 혁신이며, 이를 실현시킨 엔지니어 팀에 대한 업적입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-MixedRealityorSpatialComputing_3.png\" alt=\"2024-05-15-MixedRealityorSpatialComputing_3\"\u003e\u003c/p\u003e\n\u003cp\u003e비전 프로(Vision Pro)는 사용자의 시선 방향을 입력으로 사용하는 공간 운영 시스템(visionOS)과 같은 완전히 독특한 능력을 제공하여 새로운 영역을 개척합니다. 다시 말해, 저는 비전 프로가 혼합 현실 헤드셋뿐만 아니라 공간 컴퓨터이자 사실상 예술 작품이라고 동의합니다. 또한 저는 증강 현실, 혼합 현실, 가상 현실을 비롯한 3D 영화와 원격 존재감과 같은 다른 몰입형 경험을 포함하여 AR, MR, VR과 같은 경이로운 용어에 대한 범용 용어인 공간 컴퓨팅이 훌륭한 용어라고 믿습니다. 제 유일한 권고는 모든 기업이 이 분야의 역사적이고 받아들여진 언어를 받아들이는 것입니다. 공간 컴퓨팅은 유용한 용어지만, 증강 현실, 혼합 현실, 가상 현실도 모두 우리의 역사와 문화의 일부입니다.\u003c/p\u003e\n\u003cp\u003eLouis Rosenberg 박사는 가상 현실, 증강 현실, 인공지능 분야의 오랜 연구자입니다. 그는 1993년 Immersion Corporation (IMMR: Nasdaq)와 2014년 Unanimous AI를 창립하고 공군 연구소에서 혼합 현실 개발하는 데로 알려져 있습니다. 그의 새 책인 Our Next Reality는 Hachette로부터 예약 구매 가능합니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-15-MixedRealityorSpatialComputing"},"buildId":"pS12KbT5cDEZt16dno2Ez","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>