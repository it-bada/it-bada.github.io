<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다 | it-bada</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://it-bada.github.io///post/2024-05-21-AISpeakingtoussoftlyRTZ359" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다 | it-bada" data-gatsby-head="true"/><meta property="og:title" content="음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다 | it-bada" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://it-bada.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://it-bada.github.io///post/2024-05-21-AISpeakingtoussoftlyRTZ359" data-gatsby-head="true"/><meta name="twitter:title" content="음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다 | it-bada" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | it-bada" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-21 00:02" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PDYZ2R0CH9"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-PDYZ2R0CH9');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-1b0cb1352029e0fa.js" defer=""></script><script src="/_next/static/nioF9Z6grcTd-jO-HEtuA/_buildManifest.js" defer=""></script><script src="/_next/static/nioF9Z6grcTd-jO-HEtuA/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Bada</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Bada</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 21, 2024</span><span class="posts_reading_time__f7YPP">4<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-21-AISpeakingtoussoftlyRTZ359&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p>… 음성 AI의 위험과 잠재력에 대해 더 알아보세요</p>
<p><img src="https://miro.medium.com/v2/resize:fit:600/0*FZ3c-vQQmlBXEweQ.gif" alt="이미지"/></p>
<p>어제, OpenAI의 GPT-4 &#x27;Omni&#x27;, 구글의 Astra, 애플의 Siri, Meta의 Meta AI 등을 포함한 대규모와 소규모 LLM AI 기업이 수십억 규모의 대중을 대상으로 음성을 주요 AI 사용자 인터페이스로 채택하고 있음을 설명했습니다. 우리는 AI 기술의 초창기 단계에 있어 수십억 명의 사용자를 빠르게 &#x27;마법같은&#x27; AI 적용 프로그램의 능력에 참여시킬 필요가 있는 단계에 있습니다. 위의 OpenAI 음성 인터페이스는 오늘날의 Microsoft Windows처럼 우리에게 상징적 일 수도 있습니다.</p>
<p>그리고 음성은 우리의 감정적인 뇌에 직접 작용합니다. 이는 내가 지적한 AI의 가장 큰 위험 중 하나인 인간들이 AI를 쉽게 &#x27;응인간화&#x27;하는 성향을 가속화하는 것으로 여겨집니다. 그리고 그들은 그렇게 할 것입니다. 그들이 더 나은 방법을 배울 때까지요.</p>
<div class="content-ad"></div>
<p><img src="https://miro.medium.com/v2/resize:fit:1200/0*VtKX063HMAErXQu8.gif" alt="image"/></p>
<p>하지만 약속도 많이 있어요. 칸 아카데미 창립자 살 칸이 최근 출시된 OpenAI의 GPT-4o를 활용해 아들에게 수학을 가르치는 모습을 보세요. 3분 만에 AI의 약속에 대한 인식이 달라질 거예요.</p>
<p>또한 LinkedIn 창립자이자 마이크로소프트 이사 멤버인 리드 호프만이, Voice AI 회사 ElevenLabs가 만든 자신의 &#x27;디지털 트윈&#x27; AI와 인터뷰하는 모습을 보세요. 심지어 그의 말을 클링온어로 번역하고 영어로 다시 번역해 줍니다. 이 화려한 14분 동안 놓치지 마세요. 더 보고 싶다면, 디지턄 트윈과 REID가 시청자 질문에 답하는 10분짜리 영상도 있어요.</p>
<p>그리고 이 두 가지 예시가 제가본 이 기술의 최악의 모습입니다. 많은 &#x27;음성 비서&#x27;들이 몇 년 전까지 그랬던 것처럼요. 이제 모두 LLM/생성적 AI로 업그레이드되고 있습니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png" alt="Voice AI toothpaste"/></p>
<p>안녕하세요! Voice AI 치약이 튜브에서 나왔어요. 엄청난 수의 회사들이 자사의 AI 응용 프로그램과 서비스에 Voice를 추가하기 위해 서로 경쟁하고 있어요.</p>
<p>한 번의 변화로, AI Voice 특별한 놀라움, ElevenLabs가 오픈 AI의 Voice 보조 GPT 4o에 대한 견해를 드릴게요. 월요일에 공식 소개되기 전에요:</p>
<p>“OpenAI는 새로운 제품으로 포트폴리오를 확장하고 있는데, 그 중 가장 많이 언급된 것 중 하나가 Voice Assistant 기술입니다. 음성을 통해 기계와 상호 작용하는 방법을 혁신할 것으로 예상되지만, 넓은 배포에 대한 많은 부분은 아직 비공개로 남아 있어요.”</p>
<div class="content-ad"></div>
<p>&quot;OpenAI은 음성, 텍스트, 이미지 인식 능력을 하나의 제품으로 통합하는 기술을 개발 중이라고 합니다.&quot;</p>
<p><img src="/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_1.png" alt="OpenAI Voice Assistant"/></p>
<p>&quot;OpenAI의 음성 어시스턴트란?&quot;</p>
<p>소문에 의하면 음성 어시스턴트는 사용자와 자연스럽게 대화하는 데 사용되는 기술입니다. 자동 음성 인식(ASR), 대형 언어 모델(LLM), 텍스트 음성 변환(TTS) 시스템의 발전을 활용합니다. 이러한 기술들의 통합을 통해 음성 어시스턴트는 말로 된 입력을 이해하고 정보를 문맥에 맞게 처리하며 자연스럽고 인간과 같은 목소리로 대답할 수 있습니다.&quot;</p>
<div class="content-ad"></div>
<p>그들은 그들이 다양한 기술적 요령과 함께 공개된 기술적 마법에 대한 높은 수준의 소개를 제공하며, 우수한 결과를 이끌어내기 위해 기술적 마법 이상이 필요하다고 설명합니다:</p>
<p>&quot;거의 모든 음성 AI 시스템은 세 단계를 따릅니다:</p>
<ul>
<li>&quot;음성 인식(&quot;ASR&quot;): 이는 발화된 오디오를 텍스트로 변환합니다. 예시 기술로는 Whisper가 있습니다.&quot;</li>
<li>&quot;언어 모델 처리: 여기서 언어 모델은 적절한 응답을 결정하여 초기 텍스트를 응답 텍스트로 변환합니다.&quot;</li>
<li>&quot;음성 합성(&quot;TTS&quot;): 이 단계는 응답 텍스트를 다시 발화된 오디오로 변환하며, 이 단계에는 ElevenLabs나 VALL-E와 같은 기술이 사용됩니다.&quot;</li>
</ul>
<p>&quot;이 세 단계를 엄격하게 준수하는 것은 상당한 지연을 초래할 수 있습니다. 사용자가 각 응답을 기다리는 데 5초가 걸리면 상호작용이 번거롭고 자연스럽지 않아지며, 음성이 현실적으로 들리더라도 사용자 경험을 저하시킵니다.&quot;</p>
<div class="content-ad"></div>
<p>&quot;효과적인 자연 대화는 순차적으로 작동하지 않아요:</p>
<ul>
<li>우리는 동시에 생각하고 듣고 말합니다.</li>
<li>“예”나 “음”과 같은 확언을 자연스럽게 삽입합니다.</li>
<li>상대방이 말을 마치는 걸 예상하고 즉각적으로 응답합니다.</li>
<li>공격적이지 않은 방식으로 말을 가로채거나 말을 끼웁니다.</li>
<li>가로챔 또는 중단하는 상황을 부드럽게 처리합니다.</li>
<li>여러 사람이 참여하는 대화에 손쉽게 참여합니다.&quot;</li>
</ul>
<p>&quot;실시간 대화를 향상시키는 것은 각 신경망 프로세스를 가속화하는 데 그치지 않아요. 그것은 전체 시스템의 근본적인 재설계를 필요로 해요. 우리는 이러한 구성 요소들의 중첩을 최대화하고 실시간 조정을 효과적으로 하는 법을 배워야 해요.&quot;</p>
<p>그리고 물론, ElevenLabs가 어떻게 더 다르게 하는지를 제시하세요:&quot;</p>
<div class="content-ad"></div>
<p>&quot;일레븐랩스 보이스 AI&quot;</p>
<p>&quot;모든 고급 음성 어시스턴트에는 최첨단 음성 AI가 반드시 포함되어야 한다는 것은 확실합니다. 일레븐랩스 모델은 문맥 인식과 고압축을 결합하여 감정과 언어 범위에 걸쳐 초현실적이고 생생한 음성을 전달합니다. 저희 문맥적 텍스트 음성 모델은 단어 간 관계를 이해하고 맥락에 기반하여 전달을 조절하는 데 사용됩니다. 또한 하드코딩된 기능이 없어 수 천 가지 음성 특성을 동적으로 예측하면서 음성을 생성할 수 있습니다. 저희 모델은 장문 및 다국어 음성 생성 또는 지연에 민감한 작업과 같은 특정 응용 프로그램에 최적화되어 있습니다.&quot;</p>
<p><img src="/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_2.png" alt="Link"/></p>
<p>전 며칠 전에 언급했듯이, 애플은 OpenAI의 GPT 기술을 Siri에 통합하는 거래를 완료했다는 루머가 있습니다. 이를 통해 OpenAI 기술이 20억 대 이상의 애플 기기로 가져와질 것으로 예상됩니다. 또한 구글이 이미 애플 기기에서 구글 검색을 기본값으로 만들기 위해 매년 200억 달러를 지급하고 있으며, 구글이 곧 Gemini AI 통합을 구글 검색에 발표할 예정이라는 것을 고려하면 애플이 곧 사용자를 위해 두 가지 유형의 AI 서비스를 갖게 될 것입니다.&quot;</p>
<div class="content-ad"></div>
<p>몇 달 전에 언급한 대로, 음성 인공지능에는 장단점이 있습니다. 그리고 어제 개요한 것처럼, 그들은 아마도 주류로 AI를 처음으로 접하게 될 큰 방법일 것입니다.</p>
<p>여기에 궁극적인 잠재력은 질문을 하고 답변을 듣는 것 이상으로 나아갑니다. 이 &#x27;다중 모달&#x27; &#x27;스마트 에이전트 및 에이전틱&#x27; 음성 인공지능 전환은 우리와 우리 사회를 실질적으로 더 나아지게 변화시킬 것으로 예상됩니다. 계속 주목해 주세요.</p>
<p>(참고: 여기서의 토론은 정보 제공 목적으로만 진행되었으며 언제든지 투자 조언으로 인식되어서는 안 됩니다. 함께해 주셔서 감사합니다)</p>
<p>(이처럼 더 많은 콘텐츠를 원하시면 무료로 &quot;AI: A Reset to Zero&quot; 뉴스레터를 구독하세요. Substack에서 구독하실 수 있습니다.)</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"음성으로 부드럽게 대화하는 AI 에 대한 이야기입니다 오늘의 테마는 RTZ 359 입니다","description":"","date":"2024-05-21 00:02","slug":"2024-05-21-AISpeakingtoussoftlyRTZ359","content":"\n\n… 음성 AI의 위험과 잠재력에 대해 더 알아보세요\n\n![이미지](https://miro.medium.com/v2/resize:fit:600/0*FZ3c-vQQmlBXEweQ.gif)\n\n어제, OpenAI의 GPT-4 'Omni', 구글의 Astra, 애플의 Siri, Meta의 Meta AI 등을 포함한 대규모와 소규모 LLM AI 기업이 수십억 규모의 대중을 대상으로 음성을 주요 AI 사용자 인터페이스로 채택하고 있음을 설명했습니다. 우리는 AI 기술의 초창기 단계에 있어 수십억 명의 사용자를 빠르게 '마법같은' AI 적용 프로그램의 능력에 참여시킬 필요가 있는 단계에 있습니다. 위의 OpenAI 음성 인터페이스는 오늘날의 Microsoft Windows처럼 우리에게 상징적 일 수도 있습니다.\n\n그리고 음성은 우리의 감정적인 뇌에 직접 작용합니다. 이는 내가 지적한 AI의 가장 큰 위험 중 하나인 인간들이 AI를 쉽게 '응인간화'하는 성향을 가속화하는 것으로 여겨집니다. 그리고 그들은 그렇게 할 것입니다. 그들이 더 나은 방법을 배울 때까지요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](https://miro.medium.com/v2/resize:fit:1200/0*VtKX063HMAErXQu8.gif)\n\n하지만 약속도 많이 있어요. 칸 아카데미 창립자 살 칸이 최근 출시된 OpenAI의 GPT-4o를 활용해 아들에게 수학을 가르치는 모습을 보세요. 3분 만에 AI의 약속에 대한 인식이 달라질 거예요.\n\n또한 LinkedIn 창립자이자 마이크로소프트 이사 멤버인 리드 호프만이, Voice AI 회사 ElevenLabs가 만든 자신의 '디지털 트윈' AI와 인터뷰하는 모습을 보세요. 심지어 그의 말을 클링온어로 번역하고 영어로 다시 번역해 줍니다. 이 화려한 14분 동안 놓치지 마세요. 더 보고 싶다면, 디지턄 트윈과 REID가 시청자 질문에 답하는 10분짜리 영상도 있어요.\n\n그리고 이 두 가지 예시가 제가본 이 기술의 최악의 모습입니다. 많은 '음성 비서'들이 몇 년 전까지 그랬던 것처럼요. 이제 모두 LLM/생성적 AI로 업그레이드되고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Voice AI toothpaste](/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png)\n\n안녕하세요! Voice AI 치약이 튜브에서 나왔어요. 엄청난 수의 회사들이 자사의 AI 응용 프로그램과 서비스에 Voice를 추가하기 위해 서로 경쟁하고 있어요.\n\n한 번의 변화로, AI Voice 특별한 놀라움, ElevenLabs가 오픈 AI의 Voice 보조 GPT 4o에 대한 견해를 드릴게요. 월요일에 공식 소개되기 전에요:\n\n“OpenAI는 새로운 제품으로 포트폴리오를 확장하고 있는데, 그 중 가장 많이 언급된 것 중 하나가 Voice Assistant 기술입니다. 음성을 통해 기계와 상호 작용하는 방법을 혁신할 것으로 예상되지만, 넓은 배포에 대한 많은 부분은 아직 비공개로 남아 있어요.”\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"OpenAI은 음성, 텍스트, 이미지 인식 능력을 하나의 제품으로 통합하는 기술을 개발 중이라고 합니다.\"\n\n![OpenAI Voice Assistant](/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_1.png)\n\n\"OpenAI의 음성 어시스턴트란?\"\n\n소문에 의하면 음성 어시스턴트는 사용자와 자연스럽게 대화하는 데 사용되는 기술입니다. 자동 음성 인식(ASR), 대형 언어 모델(LLM), 텍스트 음성 변환(TTS) 시스템의 발전을 활용합니다. 이러한 기술들의 통합을 통해 음성 어시스턴트는 말로 된 입력을 이해하고 정보를 문맥에 맞게 처리하며 자연스럽고 인간과 같은 목소리로 대답할 수 있습니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그들은 그들이 다양한 기술적 요령과 함께 공개된 기술적 마법에 대한 높은 수준의 소개를 제공하며, 우수한 결과를 이끌어내기 위해 기술적 마법 이상이 필요하다고 설명합니다:\n\n\"거의 모든 음성 AI 시스템은 세 단계를 따릅니다:\n\n- \"음성 인식(\"ASR\"): 이는 발화된 오디오를 텍스트로 변환합니다. 예시 기술로는 Whisper가 있습니다.\"\n- \"언어 모델 처리: 여기서 언어 모델은 적절한 응답을 결정하여 초기 텍스트를 응답 텍스트로 변환합니다.\"\n- \"음성 합성(\"TTS\"): 이 단계는 응답 텍스트를 다시 발화된 오디오로 변환하며, 이 단계에는 ElevenLabs나 VALL-E와 같은 기술이 사용됩니다.\"\n\n\"이 세 단계를 엄격하게 준수하는 것은 상당한 지연을 초래할 수 있습니다. 사용자가 각 응답을 기다리는 데 5초가 걸리면 상호작용이 번거롭고 자연스럽지 않아지며, 음성이 현실적으로 들리더라도 사용자 경험을 저하시킵니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"효과적인 자연 대화는 순차적으로 작동하지 않아요:\n\n- 우리는 동시에 생각하고 듣고 말합니다.\n- “예”나 “음”과 같은 확언을 자연스럽게 삽입합니다.\n- 상대방이 말을 마치는 걸 예상하고 즉각적으로 응답합니다.\n- 공격적이지 않은 방식으로 말을 가로채거나 말을 끼웁니다.\n- 가로챔 또는 중단하는 상황을 부드럽게 처리합니다.\n- 여러 사람이 참여하는 대화에 손쉽게 참여합니다.\"\n\n\"실시간 대화를 향상시키는 것은 각 신경망 프로세스를 가속화하는 데 그치지 않아요. 그것은 전체 시스템의 근본적인 재설계를 필요로 해요. 우리는 이러한 구성 요소들의 중첩을 최대화하고 실시간 조정을 효과적으로 하는 법을 배워야 해요.\"\n\n그리고 물론, ElevenLabs가 어떻게 더 다르게 하는지를 제시하세요:\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"일레븐랩스 보이스 AI\"\n\n\"모든 고급 음성 어시스턴트에는 최첨단 음성 AI가 반드시 포함되어야 한다는 것은 확실합니다. 일레븐랩스 모델은 문맥 인식과 고압축을 결합하여 감정과 언어 범위에 걸쳐 초현실적이고 생생한 음성을 전달합니다. 저희 문맥적 텍스트 음성 모델은 단어 간 관계를 이해하고 맥락에 기반하여 전달을 조절하는 데 사용됩니다. 또한 하드코딩된 기능이 없어 수 천 가지 음성 특성을 동적으로 예측하면서 음성을 생성할 수 있습니다. 저희 모델은 장문 및 다국어 음성 생성 또는 지연에 민감한 작업과 같은 특정 응용 프로그램에 최적화되어 있습니다.\"\n\n![Link](/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_2.png)\n\n전 며칠 전에 언급했듯이, 애플은 OpenAI의 GPT 기술을 Siri에 통합하는 거래를 완료했다는 루머가 있습니다. 이를 통해 OpenAI 기술이 20억 대 이상의 애플 기기로 가져와질 것으로 예상됩니다. 또한 구글이 이미 애플 기기에서 구글 검색을 기본값으로 만들기 위해 매년 200억 달러를 지급하고 있으며, 구글이 곧 Gemini AI 통합을 구글 검색에 발표할 예정이라는 것을 고려하면 애플이 곧 사용자를 위해 두 가지 유형의 AI 서비스를 갖게 될 것입니다.\"  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n몇 달 전에 언급한 대로, 음성 인공지능에는 장단점이 있습니다. 그리고 어제 개요한 것처럼, 그들은 아마도 주류로 AI를 처음으로 접하게 될 큰 방법일 것입니다.\n\n여기에 궁극적인 잠재력은 질문을 하고 답변을 듣는 것 이상으로 나아갑니다. 이 '다중 모달' '스마트 에이전트 및 에이전틱' 음성 인공지능 전환은 우리와 우리 사회를 실질적으로 더 나아지게 변화시킬 것으로 예상됩니다. 계속 주목해 주세요.\n\n(참고: 여기서의 토론은 정보 제공 목적으로만 진행되었으며 언제든지 투자 조언으로 인식되어서는 안 됩니다. 함께해 주셔서 감사합니다)\n\n(이처럼 더 많은 콘텐츠를 원하시면 무료로 \"AI: A Reset to Zero\" 뉴스레터를 구독하세요. Substack에서 구독하실 수 있습니다.)","ogImage":{"url":"/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png"},"coverImage":"/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png","tag":["Tech"],"readingTime":4},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"… 음성 AI의 위험과 잠재력에 대해 더 알아보세요\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:600/0*FZ3c-vQQmlBXEweQ.gif\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"어제, OpenAI의 GPT-4 'Omni', 구글의 Astra, 애플의 Siri, Meta의 Meta AI 등을 포함한 대규모와 소규모 LLM AI 기업이 수십억 규모의 대중을 대상으로 음성을 주요 AI 사용자 인터페이스로 채택하고 있음을 설명했습니다. 우리는 AI 기술의 초창기 단계에 있어 수십억 명의 사용자를 빠르게 '마법같은' AI 적용 프로그램의 능력에 참여시킬 필요가 있는 단계에 있습니다. 위의 OpenAI 음성 인터페이스는 오늘날의 Microsoft Windows처럼 우리에게 상징적 일 수도 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그리고 음성은 우리의 감정적인 뇌에 직접 작용합니다. 이는 내가 지적한 AI의 가장 큰 위험 중 하나인 인간들이 AI를 쉽게 '응인간화'하는 성향을 가속화하는 것으로 여겨집니다. 그리고 그들은 그렇게 할 것입니다. 그들이 더 나은 방법을 배울 때까지요.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1200/0*VtKX063HMAErXQu8.gif\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 약속도 많이 있어요. 칸 아카데미 창립자 살 칸이 최근 출시된 OpenAI의 GPT-4o를 활용해 아들에게 수학을 가르치는 모습을 보세요. 3분 만에 AI의 약속에 대한 인식이 달라질 거예요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"또한 LinkedIn 창립자이자 마이크로소프트 이사 멤버인 리드 호프만이, Voice AI 회사 ElevenLabs가 만든 자신의 '디지털 트윈' AI와 인터뷰하는 모습을 보세요. 심지어 그의 말을 클링온어로 번역하고 영어로 다시 번역해 줍니다. 이 화려한 14분 동안 놓치지 마세요. 더 보고 싶다면, 디지턄 트윈과 REID가 시청자 질문에 답하는 10분짜리 영상도 있어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그리고 이 두 가지 예시가 제가본 이 기술의 최악의 모습입니다. 많은 '음성 비서'들이 몇 년 전까지 그랬던 것처럼요. 이제 모두 LLM/생성적 AI로 업그레이드되고 있습니다.\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_0.png\",\n        alt: \"Voice AI toothpaste\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"안녕하세요! Voice AI 치약이 튜브에서 나왔어요. 엄청난 수의 회사들이 자사의 AI 응용 프로그램과 서비스에 Voice를 추가하기 위해 서로 경쟁하고 있어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"한 번의 변화로, AI Voice 특별한 놀라움, ElevenLabs가 오픈 AI의 Voice 보조 GPT 4o에 대한 견해를 드릴게요. 월요일에 공식 소개되기 전에요:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"“OpenAI는 새로운 제품으로 포트폴리오를 확장하고 있는데, 그 중 가장 많이 언급된 것 중 하나가 Voice Assistant 기술입니다. 음성을 통해 기계와 상호 작용하는 방법을 혁신할 것으로 예상되지만, 넓은 배포에 대한 많은 부분은 아직 비공개로 남아 있어요.”\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"OpenAI은 음성, 텍스트, 이미지 인식 능력을 하나의 제품으로 통합하는 기술을 개발 중이라고 합니다.\\\"\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_1.png\",\n        alt: \"OpenAI Voice Assistant\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"OpenAI의 음성 어시스턴트란?\\\"\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"소문에 의하면 음성 어시스턴트는 사용자와 자연스럽게 대화하는 데 사용되는 기술입니다. 자동 음성 인식(ASR), 대형 언어 모델(LLM), 텍스트 음성 변환(TTS) 시스템의 발전을 활용합니다. 이러한 기술들의 통합을 통해 음성 어시스턴트는 말로 된 입력을 이해하고 정보를 문맥에 맞게 처리하며 자연스럽고 인간과 같은 목소리로 대답할 수 있습니다.\\\"\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그들은 그들이 다양한 기술적 요령과 함께 공개된 기술적 마법에 대한 높은 수준의 소개를 제공하며, 우수한 결과를 이끌어내기 위해 기술적 마법 이상이 필요하다고 설명합니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"거의 모든 음성 AI 시스템은 세 단계를 따릅니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"\\\"음성 인식(\\\"ASR\\\"): 이는 발화된 오디오를 텍스트로 변환합니다. 예시 기술로는 Whisper가 있습니다.\\\"\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"\\\"언어 모델 처리: 여기서 언어 모델은 적절한 응답을 결정하여 초기 텍스트를 응답 텍스트로 변환합니다.\\\"\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"\\\"음성 합성(\\\"TTS\\\"): 이 단계는 응답 텍스트를 다시 발화된 오디오로 변환하며, 이 단계에는 ElevenLabs나 VALL-E와 같은 기술이 사용됩니다.\\\"\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"이 세 단계를 엄격하게 준수하는 것은 상당한 지연을 초래할 수 있습니다. 사용자가 각 응답을 기다리는 데 5초가 걸리면 상호작용이 번거롭고 자연스럽지 않아지며, 음성이 현실적으로 들리더라도 사용자 경험을 저하시킵니다.\\\"\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"효과적인 자연 대화는 순차적으로 작동하지 않아요:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"우리는 동시에 생각하고 듣고 말합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"“예”나 “음”과 같은 확언을 자연스럽게 삽입합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"상대방이 말을 마치는 걸 예상하고 즉각적으로 응답합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"공격적이지 않은 방식으로 말을 가로채거나 말을 끼웁니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"가로챔 또는 중단하는 상황을 부드럽게 처리합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"여러 사람이 참여하는 대화에 손쉽게 참여합니다.\\\"\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"실시간 대화를 향상시키는 것은 각 신경망 프로세스를 가속화하는 데 그치지 않아요. 그것은 전체 시스템의 근본적인 재설계를 필요로 해요. 우리는 이러한 구성 요소들의 중첩을 최대화하고 실시간 조정을 효과적으로 하는 법을 배워야 해요.\\\"\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그리고 물론, ElevenLabs가 어떻게 더 다르게 하는지를 제시하세요:\\\"\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"일레븐랩스 보이스 AI\\\"\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"\\\"모든 고급 음성 어시스턴트에는 최첨단 음성 AI가 반드시 포함되어야 한다는 것은 확실합니다. 일레븐랩스 모델은 문맥 인식과 고압축을 결합하여 감정과 언어 범위에 걸쳐 초현실적이고 생생한 음성을 전달합니다. 저희 문맥적 텍스트 음성 모델은 단어 간 관계를 이해하고 맥락에 기반하여 전달을 조절하는 데 사용됩니다. 또한 하드코딩된 기능이 없어 수 천 가지 음성 특성을 동적으로 예측하면서 음성을 생성할 수 있습니다. 저희 모델은 장문 및 다국어 음성 생성 또는 지연에 민감한 작업과 같은 특정 응용 프로그램에 최적화되어 있습니다.\\\"\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-21-AISpeakingtoussoftlyRTZ359_2.png\",\n        alt: \"Link\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"전 며칠 전에 언급했듯이, 애플은 OpenAI의 GPT 기술을 Siri에 통합하는 거래를 완료했다는 루머가 있습니다. 이를 통해 OpenAI 기술이 20억 대 이상의 애플 기기로 가져와질 것으로 예상됩니다. 또한 구글이 이미 애플 기기에서 구글 검색을 기본값으로 만들기 위해 매년 200억 달러를 지급하고 있으며, 구글이 곧 Gemini AI 통합을 구글 검색에 발표할 예정이라는 것을 고려하면 애플이 곧 사용자를 위해 두 가지 유형의 AI 서비스를 갖게 될 것입니다.\\\"\"\n    }), \"\\n\", _jsx(\"div\", {\n      class: \"content-ad\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"몇 달 전에 언급한 대로, 음성 인공지능에는 장단점이 있습니다. 그리고 어제 개요한 것처럼, 그들은 아마도 주류로 AI를 처음으로 접하게 될 큰 방법일 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기에 궁극적인 잠재력은 질문을 하고 답변을 듣는 것 이상으로 나아갑니다. 이 '다중 모달' '스마트 에이전트 및 에이전틱' 음성 인공지능 전환은 우리와 우리 사회를 실질적으로 더 나아지게 변화시킬 것으로 예상됩니다. 계속 주목해 주세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"(참고: 여기서의 토론은 정보 제공 목적으로만 진행되었으며 언제든지 투자 조언으로 인식되어서는 안 됩니다. 함께해 주셔서 감사합니다)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"(이처럼 더 많은 콘텐츠를 원하시면 무료로 \\\"AI: A Reset to Zero\\\" 뉴스레터를 구독하세요. Substack에서 구독하실 수 있습니다.)\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-21-AISpeakingtoussoftlyRTZ359"},"buildId":"nioF9Z6grcTd-jO-HEtuA","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>