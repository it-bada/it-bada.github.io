<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가 | it-bada</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://it-bada.github.io///post/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가 | it-bada" data-gatsby-head="true"/><meta property="og:title" content="FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가 | it-bada" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://it-bada.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://it-bada.github.io///post/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach" data-gatsby-head="true"/><meta name="twitter:title" content="FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가 | it-bada" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | it-bada" data-gatsby-head="true"/><meta name="article:published_time" content="2024-07-01 00:01" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PDYZ2R0CH9"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-PDYZ2R0CH9');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-90e194c785348efe.js" defer=""></script><script src="/_next/static/pS12KbT5cDEZt16dno2Ez/_buildManifest.js" defer=""></script><script src="/_next/static/pS12KbT5cDEZt16dno2Ez/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Bada</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Bada</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jul 1, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이미지 경로: <a href="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png">2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png</a></p>
<h1>소개</h1>
<p>기술이 발전함에 따라 흥미로운 점은 대부분의 사람들이 좋은 디자인으로 판단되는 것에 수렴한다는 것입니다.</p>
<p>예를 들어 프롬프트 엔지니어링의 경우, 프롬프트가 템플릿으로 진화되어 변수가 주입될 수 있는 자리 표시자가 있는 것을 볼 수 있습니다.</p>
<div class="content-ad"></div>
<p>이제 이것은 프롬프트 체이닝으로 진전되었고, 결국 여러 도구를 가진 자율 에이전트로 발전했습니다.</p>
<p>그래서 RAG는 매우 비슷한 궤적을 통과하고 있어요...초반에는 RAG 그 자체로 충분하다고 여겨졌어요. 그러나 이제 RAG 스택에 추가적인 지식이 추가되고, RAG 아키텍처의 일부를 형성하는 여러 요소들과 함께 구성될 예정이에요.</p>
<h1>네 가지 초기 고려 사항</h1>
<p>먼저, 아래 기사에서 보시는 대로 프롬프트 구조가 RAG 아키텍처에서 점점 더 중요해지고 있으며, 연상 기술로 Chain-of-Thought와 같은 프롬프팅 기술이 도입되고 있어요.</p>
<div class="content-ad"></div>
<p>최근에는 단순히 상황 참조 데이터를 주입하는 것만으로는 충분하지 않습니다. 텍스트를 최적화하기 위해 문구가 활용되고 있습니다.</p>
<p>또한 RAG가 두 가지 측면에서 정적임을 인식하고 있습니다. 첫 번째로, RAG가 대화의 맥락을 고려하지 않거나 최소한 다수의 대화 턴에 걸친 맥락을 고려하지 않을 수 있다는 것입니다. 이에 더해, 데이터를 검색할지 말지 결정하는 것은 종종 유연성이 없는 일련의 정적 규칙에 기반하고 있습니다.</p>
<p>세 번째로, 불필요한 오버헤드를 고려하고 있으며, 불필요하고 최적화되지 않은 검색, 추가 텍스트가 추가되어 원치 않는 비용 및 추론 지연을 초래할 수 있습니다.</p>
<p>네 번째로, 최적의 응답을 선택하기 위한 다단계 접근법과 분류기를 사용하거나 다수의 데이터 스토어를 활용하거나 단순히 사용자 요청을 분류하는 데 사용됩니다. 이러한 분류기는 주로 이 특수화된 작업을 위해 모델을 훈련하는 데 사용되는 주석이 달린 데이터에 의존합니다.</p>
<div class="content-ad"></div>
<p>그리고 이전에 언급한 대로, RAG는 라마인덱스가 에이젼틱 RAG로 지칭하는 상태로 나아가고 있습니다. 여기서 RAG 기반 요소는 여러 하위 에이전트나 도구를 활용하여 데이터 검색을 관리하는 데 사용됩니다.</p>
<h2>FIT-RAG</h2>
<p>FIT-RAG 연구는 LLM과 사실 데이터를 고려할 때 두 가지 문제를 식별합니다...</p>
<p>사실 데이터 부족: LLM의 원하는 문서에는 특정 쿼리에 필요한 사실 정보가 부족할 수 있으며, 이는 검색기를 오도하고 블랙박스 RAG의 효과를 약화시킬 수 있습니다.</p>
<div class="content-ad"></div>
<p>Token Overload: 모든 검색된 문서를 무차별적으로 병합하면 LLM에 사용된 토큰이 과도하게 많아져서 블랙박스 RAG의 효율성이 저하됩니다.</p>
<p>FIT-RAG는 사실적 정보를 고려하여 이중 레이블 문서 점수 판별기를 고안하는 것으로, 이 점수 판별기는 사실적 정보와 LLM 선호도를 구분된 레이블로 통합합니다.</p>
<p>또한 FIT-RAG는 자기-인식 인지기와 하위 문서 수준 토큰 축소기를 포함한 토큰 축소 전략을 구현합니다. 이러한 혁신들은 불필요한 증강을 최소화하고 증강 토큰을 크게 감소시켜 FIT-RAG의 효율성을 향상시키기 위해 설계되었습니다.</p>
<h1>FIT-RAG의 구성요소</h1>
<div class="content-ad"></div>
<p>아래 이미지를 고려하면 FIT-RAG는 다섯 가지의 핵심 요소로 구성되어 있습니다:</p>
<ul>
<li>유사성 기반 검색기,</li>
<li>이중 레이블 문서 평가자,</li>
<li>이중 면 성 자기 인식 기능,</li>
<li>하위 문서 수준 토큰 축소기,</li>
<li>프롬프트 구성 모듈.</li>
</ul>
<p>특히, 이중 레이블 문서 평가자는 LLM 기호와 사실적 정보 모두와의 조화를 능숙하게 포착하기 위해 설계되었으며, 사실적 무지의 위험을 경감시킵니다.</p>
<p>또한, 이중 면 성 자기 인식기와 하위 문서 수준 토큰 축소기는 입력 토큰 최소화에 중요한 역할을 하여 토큰 낭비를 방지합니다.</p>
<div class="content-ad"></div>
<p>The bi-label document scorer is trained using bi-label learning, which involves two labels:</p>
<ul>
<li>Factual information (Has_Answer) and</li>
<li>LLM preference (LLM_Prefer).</li>
</ul>
<p>The "Has_Answer" label tells us if the document contains the answer to the question, while "LLM_Prefer" indicates if the document helps the LLM generate an accurate response.</p>
<p>Yet, there's a noticeable disparity in data distribution between these labels, potentially affecting the efficiency of bi-label learning. To tackle this issue, the paper introduces a data-imbalance-aware bi-label learning technique.</p>
<div class="content-ad"></div>
<p>이 방법은 데이터에 서로 다른 가중치를 할당하며, 하이퍼 그레이디언트 디센트를 사용하여 자동으로 학습합니다. 이 접근 방식은 데이터 불균형 문제를 효과적으로 다루어서, 바이-라벨 문서 점수기가 검색된 문서를 종합적으로 평가할 수 있도록 합니다.</p>
<p>바이-파셋트 셀프-지식 인식기는 LLM이 외부 지식이 필요한지를 평가하여 두 가지 측면을 고려합니다: 질문이 장기적이거나 오래된 정보에 관련되는지 여부, 그리고 질문의 가장 가까운 대응이 자체 지식을 갖고 있는지 여부.</p>
<p>한편, 서브-문서 레벨의 토큰 축소기는 중복되는 서브-문서를 제거함으로써, 검색된 문서들 중 서브-문서가 적지만 여전히 LLM의 정확한 답변 제공 능력을 향상시킬 수 있는 조합들을 선택합니다.</p>
<h1>FIT-RAG 프롬프트하기</h1>
<div class="content-ad"></div>
<p>아래 이미지는 프롬프트 문구가 최적화된 모습을 보여줍니다...</p>
<h1>결론</h1>
<p>RAG(견주-리더-생성자) 파이프라인에 주체적 능력을 통합하면 복잡한 질문과 추론 작업에 대처하는 능력이 크게 향상될 수 있습니다. 주체적 능력을 파이프라인에 추가함으로써, 더 넓은 범위의 복잡한 질문과 시나리오를 다룰 수 있게 됩니다.</p>
<p>그러나 주체적 능력을 가진 에이전트가 직면하는 중요한 도전 과제 중 하나는 의사 결정 프로세스에서 조작성 및 투명성이 부족하다는 것입니다. 사용자 쿼리에 직면했을 때, 에이전트는 생각의 연쇄나 계획 접근을 채택할 수 있으며, 이는 문제 공간을 효과적으로 탐색하기 위해 대형 언어 모델(Large Language Models, LLMs)과 반복 상호 작용이 필요할 수 있습니다.</p>
<div class="content-ad"></div>
<p>LLMs(대형 언어 모델)과의 반복 상호작용에 의존하는 것은 컴퓨팅 부담을 초래할 뿐만 아니라, 에이전트가 결정에 대해 명확한 설명을 제공하는 것을 방해합니다.</p>
<p>그 결과, 에이전트 시스템의 조종 가능성과 투명성을 향상시키는 메커니즘을 개발해야 하는 절박한 필요성이 제기됩니다. 이는 사용자가 그들의 행동을 더 잘 이해하고 영향을 미치도록 하는 것을 가능하게 할 것입니다.</p>
<p>이러한 고통을 해소함으로써, 에이전트 시스템의 효율성과 효과성을 향상시키는데 그치지 않고, 복잡한 작업 및 문제 해결 시나리오에 대한 사람과 AI 에이전트 간의 신뢰와 협력을 촉진할 것입니다.</p>
<p>⭐️ LinkedIn에서 대형 언어 모델의 업데이트를 받아보세요! ⭐️</p>
<div class="content-ad"></div>
<p><strong>이미지1</strong>:<br>
<img src="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_1.png" alt="Image 1"></p>
<p>저는 현재 코어 AI의 최고 전도사입니다. 인공지능과 언어가 교차하는 모든 것에 대해 탐구하고 쓰고 있습니다. LLM, 챗봇, 음성 봇, 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제를 다루고 있습니다.</p>
<p><strong>이미지2</strong>:<br>
<img src="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_2.png" alt="Image 2"></p>
<p><strong>이미지3</strong>:<br>
<img src="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_3.png" alt="Image 3"></p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_4.png" alt="Image"></p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"FIT-RAG RAG 아키텍처가 표준화된 접근 방식을 채택하고 있는가","description":"","date":"2024-07-01 00:01","slug":"2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach","content":"\n\n이미지 경로: [2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png)\n\n# 소개\n\n기술이 발전함에 따라 흥미로운 점은 대부분의 사람들이 좋은 디자인으로 판단되는 것에 수렴한다는 것입니다.\n\n예를 들어 프롬프트 엔지니어링의 경우, 프롬프트가 템플릿으로 진화되어 변수가 주입될 수 있는 자리 표시자가 있는 것을 볼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 이것은 프롬프트 체이닝으로 진전되었고, 결국 여러 도구를 가진 자율 에이전트로 발전했습니다.\n\n그래서 RAG는 매우 비슷한 궤적을 통과하고 있어요...초반에는 RAG 그 자체로 충분하다고 여겨졌어요. 그러나 이제 RAG 스택에 추가적인 지식이 추가되고, RAG 아키텍처의 일부를 형성하는 여러 요소들과 함께 구성될 예정이에요.\n\n# 네 가지 초기 고려 사항\n\n먼저, 아래 기사에서 보시는 대로 프롬프트 구조가 RAG 아키텍처에서 점점 더 중요해지고 있으며, 연상 기술로 Chain-of-Thought와 같은 프롬프팅 기술이 도입되고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최근에는 단순히 상황 참조 데이터를 주입하는 것만으로는 충분하지 않습니다. 텍스트를 최적화하기 위해 문구가 활용되고 있습니다.\n\n또한 RAG가 두 가지 측면에서 정적임을 인식하고 있습니다. 첫 번째로, RAG가 대화의 맥락을 고려하지 않거나 최소한 다수의 대화 턴에 걸친 맥락을 고려하지 않을 수 있다는 것입니다. 이에 더해, 데이터를 검색할지 말지 결정하는 것은 종종 유연성이 없는 일련의 정적 규칙에 기반하고 있습니다.\n\n세 번째로, 불필요한 오버헤드를 고려하고 있으며, 불필요하고 최적화되지 않은 검색, 추가 텍스트가 추가되어 원치 않는 비용 및 추론 지연을 초래할 수 있습니다.\n\n네 번째로, 최적의 응답을 선택하기 위한 다단계 접근법과 분류기를 사용하거나 다수의 데이터 스토어를 활용하거나 단순히 사용자 요청을 분류하는 데 사용됩니다. 이러한 분류기는 주로 이 특수화된 작업을 위해 모델을 훈련하는 데 사용되는 주석이 달린 데이터에 의존합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 이전에 언급한 대로, RAG는 라마인덱스가 에이젼틱 RAG로 지칭하는 상태로 나아가고 있습니다. 여기서 RAG 기반 요소는 여러 하위 에이전트나 도구를 활용하여 데이터 검색을 관리하는 데 사용됩니다.\n\n## FIT-RAG\n\nFIT-RAG 연구는 LLM과 사실 데이터를 고려할 때 두 가지 문제를 식별합니다...\n\n사실 데이터 부족: LLM의 원하는 문서에는 특정 쿼리에 필요한 사실 정보가 부족할 수 있으며, 이는 검색기를 오도하고 블랙박스 RAG의 효과를 약화시킬 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nToken Overload: 모든 검색된 문서를 무차별적으로 병합하면 LLM에 사용된 토큰이 과도하게 많아져서 블랙박스 RAG의 효율성이 저하됩니다.\n\nFIT-RAG는 사실적 정보를 고려하여 이중 레이블 문서 점수 판별기를 고안하는 것으로, 이 점수 판별기는 사실적 정보와 LLM 선호도를 구분된 레이블로 통합합니다.\n\n또한 FIT-RAG는 자기-인식 인지기와 하위 문서 수준 토큰 축소기를 포함한 토큰 축소 전략을 구현합니다. 이러한 혁신들은 불필요한 증강을 최소화하고 증강 토큰을 크게 감소시켜 FIT-RAG의 효율성을 향상시키기 위해 설계되었습니다.\n\n# FIT-RAG의 구성요소\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 이미지를 고려하면 FIT-RAG는 다섯 가지의 핵심 요소로 구성되어 있습니다:\n\n- 유사성 기반 검색기,\n- 이중 레이블 문서 평가자,\n- 이중 면 성 자기 인식 기능,\n- 하위 문서 수준 토큰 축소기,\n- 프롬프트 구성 모듈.\n\n특히, 이중 레이블 문서 평가자는 LLM 기호와 사실적 정보 모두와의 조화를 능숙하게 포착하기 위해 설계되었으며, 사실적 무지의 위험을 경감시킵니다.\n\n또한, 이중 면 성 자기 인식기와 하위 문서 수준 토큰 축소기는 입력 토큰 최소화에 중요한 역할을 하여 토큰 낭비를 방지합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nThe bi-label document scorer is trained using bi-label learning, which involves two labels:\n\n- Factual information (Has_Answer) and\n- LLM preference (LLM_Prefer).\n\nThe \"Has_Answer\" label tells us if the document contains the answer to the question, while \"LLM_Prefer\" indicates if the document helps the LLM generate an accurate response.\n\nYet, there's a noticeable disparity in data distribution between these labels, potentially affecting the efficiency of bi-label learning. To tackle this issue, the paper introduces a data-imbalance-aware bi-label learning technique.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 데이터에 서로 다른 가중치를 할당하며, 하이퍼 그레이디언트 디센트를 사용하여 자동으로 학습합니다. 이 접근 방식은 데이터 불균형 문제를 효과적으로 다루어서, 바이-라벨 문서 점수기가 검색된 문서를 종합적으로 평가할 수 있도록 합니다.\n\n바이-파셋트 셀프-지식 인식기는 LLM이 외부 지식이 필요한지를 평가하여 두 가지 측면을 고려합니다: 질문이 장기적이거나 오래된 정보에 관련되는지 여부, 그리고 질문의 가장 가까운 대응이 자체 지식을 갖고 있는지 여부.\n\n한편, 서브-문서 레벨의 토큰 축소기는 중복되는 서브-문서를 제거함으로써, 검색된 문서들 중 서브-문서가 적지만 여전히 LLM의 정확한 답변 제공 능력을 향상시킬 수 있는 조합들을 선택합니다.\n\n# FIT-RAG 프롬프트하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 이미지는 프롬프트 문구가 최적화된 모습을 보여줍니다...\n\n# 결론\n\nRAG(견주-리더-생성자) 파이프라인에 주체적 능력을 통합하면 복잡한 질문과 추론 작업에 대처하는 능력이 크게 향상될 수 있습니다. 주체적 능력을 파이프라인에 추가함으로써, 더 넓은 범위의 복잡한 질문과 시나리오를 다룰 수 있게 됩니다.\n\n그러나 주체적 능력을 가진 에이전트가 직면하는 중요한 도전 과제 중 하나는 의사 결정 프로세스에서 조작성 및 투명성이 부족하다는 것입니다. 사용자 쿼리에 직면했을 때, 에이전트는 생각의 연쇄나 계획 접근을 채택할 수 있으며, 이는 문제 공간을 효과적으로 탐색하기 위해 대형 언어 모델(Large Language Models, LLMs)과 반복 상호 작용이 필요할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLMs(대형 언어 모델)과의 반복 상호작용에 의존하는 것은 컴퓨팅 부담을 초래할 뿐만 아니라, 에이전트가 결정에 대해 명확한 설명을 제공하는 것을 방해합니다.\n\n그 결과, 에이전트 시스템의 조종 가능성과 투명성을 향상시키는 메커니즘을 개발해야 하는 절박한 필요성이 제기됩니다. 이는 사용자가 그들의 행동을 더 잘 이해하고 영향을 미치도록 하는 것을 가능하게 할 것입니다.\n\n이러한 고통을 해소함으로써, 에이전트 시스템의 효율성과 효과성을 향상시키는데 그치지 않고, 복잡한 작업 및 문제 해결 시나리오에 대한 사람과 AI 에이전트 간의 신뢰와 협력을 촉진할 것입니다.\n\n⭐️ LinkedIn에서 대형 언어 모델의 업데이트를 받아보세요! ⭐️\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**이미지1**:  \n![Image 1](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_1.png)\n\n저는 현재 코어 AI의 최고 전도사입니다. 인공지능과 언어가 교차하는 모든 것에 대해 탐구하고 쓰고 있습니다. LLM, 챗봇, 음성 봇, 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제를 다루고 있습니다.\n\n**이미지2**:  \n![Image 2](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_2.png)\n\n**이미지3**:  \n![Image 3](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Image](/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_4.png)","ogImage":{"url":"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png"},"coverImage":"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이미지 경로: \u003ca href=\"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png\"\u003e2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_0.png\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e소개\u003c/h1\u003e\n\u003cp\u003e기술이 발전함에 따라 흥미로운 점은 대부분의 사람들이 좋은 디자인으로 판단되는 것에 수렴한다는 것입니다.\u003c/p\u003e\n\u003cp\u003e예를 들어 프롬프트 엔지니어링의 경우, 프롬프트가 템플릿으로 진화되어 변수가 주입될 수 있는 자리 표시자가 있는 것을 볼 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이제 이것은 프롬프트 체이닝으로 진전되었고, 결국 여러 도구를 가진 자율 에이전트로 발전했습니다.\u003c/p\u003e\n\u003cp\u003e그래서 RAG는 매우 비슷한 궤적을 통과하고 있어요...초반에는 RAG 그 자체로 충분하다고 여겨졌어요. 그러나 이제 RAG 스택에 추가적인 지식이 추가되고, RAG 아키텍처의 일부를 형성하는 여러 요소들과 함께 구성될 예정이에요.\u003c/p\u003e\n\u003ch1\u003e네 가지 초기 고려 사항\u003c/h1\u003e\n\u003cp\u003e먼저, 아래 기사에서 보시는 대로 프롬프트 구조가 RAG 아키텍처에서 점점 더 중요해지고 있으며, 연상 기술로 Chain-of-Thought와 같은 프롬프팅 기술이 도입되고 있어요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e최근에는 단순히 상황 참조 데이터를 주입하는 것만으로는 충분하지 않습니다. 텍스트를 최적화하기 위해 문구가 활용되고 있습니다.\u003c/p\u003e\n\u003cp\u003e또한 RAG가 두 가지 측면에서 정적임을 인식하고 있습니다. 첫 번째로, RAG가 대화의 맥락을 고려하지 않거나 최소한 다수의 대화 턴에 걸친 맥락을 고려하지 않을 수 있다는 것입니다. 이에 더해, 데이터를 검색할지 말지 결정하는 것은 종종 유연성이 없는 일련의 정적 규칙에 기반하고 있습니다.\u003c/p\u003e\n\u003cp\u003e세 번째로, 불필요한 오버헤드를 고려하고 있으며, 불필요하고 최적화되지 않은 검색, 추가 텍스트가 추가되어 원치 않는 비용 및 추론 지연을 초래할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e네 번째로, 최적의 응답을 선택하기 위한 다단계 접근법과 분류기를 사용하거나 다수의 데이터 스토어를 활용하거나 단순히 사용자 요청을 분류하는 데 사용됩니다. 이러한 분류기는 주로 이 특수화된 작업을 위해 모델을 훈련하는 데 사용되는 주석이 달린 데이터에 의존합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그리고 이전에 언급한 대로, RAG는 라마인덱스가 에이젼틱 RAG로 지칭하는 상태로 나아가고 있습니다. 여기서 RAG 기반 요소는 여러 하위 에이전트나 도구를 활용하여 데이터 검색을 관리하는 데 사용됩니다.\u003c/p\u003e\n\u003ch2\u003eFIT-RAG\u003c/h2\u003e\n\u003cp\u003eFIT-RAG 연구는 LLM과 사실 데이터를 고려할 때 두 가지 문제를 식별합니다...\u003c/p\u003e\n\u003cp\u003e사실 데이터 부족: LLM의 원하는 문서에는 특정 쿼리에 필요한 사실 정보가 부족할 수 있으며, 이는 검색기를 오도하고 블랙박스 RAG의 효과를 약화시킬 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eToken Overload: 모든 검색된 문서를 무차별적으로 병합하면 LLM에 사용된 토큰이 과도하게 많아져서 블랙박스 RAG의 효율성이 저하됩니다.\u003c/p\u003e\n\u003cp\u003eFIT-RAG는 사실적 정보를 고려하여 이중 레이블 문서 점수 판별기를 고안하는 것으로, 이 점수 판별기는 사실적 정보와 LLM 선호도를 구분된 레이블로 통합합니다.\u003c/p\u003e\n\u003cp\u003e또한 FIT-RAG는 자기-인식 인지기와 하위 문서 수준 토큰 축소기를 포함한 토큰 축소 전략을 구현합니다. 이러한 혁신들은 불필요한 증강을 최소화하고 증강 토큰을 크게 감소시켜 FIT-RAG의 효율성을 향상시키기 위해 설계되었습니다.\u003c/p\u003e\n\u003ch1\u003eFIT-RAG의 구성요소\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래 이미지를 고려하면 FIT-RAG는 다섯 가지의 핵심 요소로 구성되어 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e유사성 기반 검색기,\u003c/li\u003e\n\u003cli\u003e이중 레이블 문서 평가자,\u003c/li\u003e\n\u003cli\u003e이중 면 성 자기 인식 기능,\u003c/li\u003e\n\u003cli\u003e하위 문서 수준 토큰 축소기,\u003c/li\u003e\n\u003cli\u003e프롬프트 구성 모듈.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e특히, 이중 레이블 문서 평가자는 LLM 기호와 사실적 정보 모두와의 조화를 능숙하게 포착하기 위해 설계되었으며, 사실적 무지의 위험을 경감시킵니다.\u003c/p\u003e\n\u003cp\u003e또한, 이중 면 성 자기 인식기와 하위 문서 수준 토큰 축소기는 입력 토큰 최소화에 중요한 역할을 하여 토큰 낭비를 방지합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eThe bi-label document scorer is trained using bi-label learning, which involves two labels:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFactual information (Has_Answer) and\u003c/li\u003e\n\u003cli\u003eLLM preference (LLM_Prefer).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe \"Has_Answer\" label tells us if the document contains the answer to the question, while \"LLM_Prefer\" indicates if the document helps the LLM generate an accurate response.\u003c/p\u003e\n\u003cp\u003eYet, there's a noticeable disparity in data distribution between these labels, potentially affecting the efficiency of bi-label learning. To tackle this issue, the paper introduces a data-imbalance-aware bi-label learning technique.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 방법은 데이터에 서로 다른 가중치를 할당하며, 하이퍼 그레이디언트 디센트를 사용하여 자동으로 학습합니다. 이 접근 방식은 데이터 불균형 문제를 효과적으로 다루어서, 바이-라벨 문서 점수기가 검색된 문서를 종합적으로 평가할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e바이-파셋트 셀프-지식 인식기는 LLM이 외부 지식이 필요한지를 평가하여 두 가지 측면을 고려합니다: 질문이 장기적이거나 오래된 정보에 관련되는지 여부, 그리고 질문의 가장 가까운 대응이 자체 지식을 갖고 있는지 여부.\u003c/p\u003e\n\u003cp\u003e한편, 서브-문서 레벨의 토큰 축소기는 중복되는 서브-문서를 제거함으로써, 검색된 문서들 중 서브-문서가 적지만 여전히 LLM의 정확한 답변 제공 능력을 향상시킬 수 있는 조합들을 선택합니다.\u003c/p\u003e\n\u003ch1\u003eFIT-RAG 프롬프트하기\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래 이미지는 프롬프트 문구가 최적화된 모습을 보여줍니다...\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003eRAG(견주-리더-생성자) 파이프라인에 주체적 능력을 통합하면 복잡한 질문과 추론 작업에 대처하는 능력이 크게 향상될 수 있습니다. 주체적 능력을 파이프라인에 추가함으로써, 더 넓은 범위의 복잡한 질문과 시나리오를 다룰 수 있게 됩니다.\u003c/p\u003e\n\u003cp\u003e그러나 주체적 능력을 가진 에이전트가 직면하는 중요한 도전 과제 중 하나는 의사 결정 프로세스에서 조작성 및 투명성이 부족하다는 것입니다. 사용자 쿼리에 직면했을 때, 에이전트는 생각의 연쇄나 계획 접근을 채택할 수 있으며, 이는 문제 공간을 효과적으로 탐색하기 위해 대형 언어 모델(Large Language Models, LLMs)과 반복 상호 작용이 필요할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eLLMs(대형 언어 모델)과의 반복 상호작용에 의존하는 것은 컴퓨팅 부담을 초래할 뿐만 아니라, 에이전트가 결정에 대해 명확한 설명을 제공하는 것을 방해합니다.\u003c/p\u003e\n\u003cp\u003e그 결과, 에이전트 시스템의 조종 가능성과 투명성을 향상시키는 메커니즘을 개발해야 하는 절박한 필요성이 제기됩니다. 이는 사용자가 그들의 행동을 더 잘 이해하고 영향을 미치도록 하는 것을 가능하게 할 것입니다.\u003c/p\u003e\n\u003cp\u003e이러한 고통을 해소함으로써, 에이전트 시스템의 효율성과 효과성을 향상시키는데 그치지 않고, 복잡한 작업 및 문제 해결 시나리오에 대한 사람과 AI 에이전트 간의 신뢰와 협력을 촉진할 것입니다.\u003c/p\u003e\n\u003cp\u003e⭐️ LinkedIn에서 대형 언어 모델의 업데이트를 받아보세요! ⭐️\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003e이미지1\u003c/strong\u003e:\u003cbr\u003e\n\u003cimg src=\"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_1.png\" alt=\"Image 1\"\u003e\u003c/p\u003e\n\u003cp\u003e저는 현재 코어 AI의 최고 전도사입니다. 인공지능과 언어가 교차하는 모든 것에 대해 탐구하고 쓰고 있습니다. LLM, 챗봇, 음성 봇, 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제를 다루고 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e이미지2\u003c/strong\u003e:\u003cbr\u003e\n\u003cimg src=\"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_2.png\" alt=\"Image 2\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e이미지3\u003c/strong\u003e:\u003cbr\u003e\n\u003cimg src=\"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_3.png\" alt=\"Image 3\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach_4.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-07-01-FIT-RAGAreRAGArchitecturesSettlingOnAStandardisedApproach"},"buildId":"pS12KbT5cDEZt16dno2Ez","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4877378276818686","strategy":"lazyOnload","crossOrigin":"anonymous"}]}</script></body></html>