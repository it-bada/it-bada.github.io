<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>상태 및 행동 이유론 | it-bada</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://it-bada.github.io///post/2024-05-15-StateandActionReasoning" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="상태 및 행동 이유론 | it-bada" data-gatsby-head="true"/><meta property="og:title" content="상태 및 행동 이유론 | it-bada" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-15-StateandActionReasoning_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://it-bada.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://it-bada.github.io///post/2024-05-15-StateandActionReasoning" data-gatsby-head="true"/><meta name="twitter:title" content="상태 및 행동 이유론 | it-bada" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-15-StateandActionReasoning_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | it-bada" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-15 23:57" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-1b0cb1352029e0fa.js" defer=""></script><script src="/_next/static/ZCLw62NtQD8-xdhHOoU4Q/_buildManifest.js" defer=""></script><script src="/_next/static/ZCLw62NtQD8-xdhHOoU4Q/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Bada</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">상태 및 행동 이유론</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="상태 및 행동 이유론" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Bada</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 15, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-15-StateandActionReasoning&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p><img src="/assets/img/2024-05-15-StateandActionReasoning_0.png" alt="image"/></p>
<p>안녕하세요! 이번 블로그 포스트에서는 Nuro의 다중 모달 대형 언어 모델 (MLLM)인 LAMBDA를 소개합니다. LAMBDA는 Nuro 운전자의 자율 주행 시스템인 The Nuro Driver’s™ 내장 자율성 스택의 일부로 질문에 답하고, 저희의 자율 주행 차량 플랫폼 내부 하드웨어에서 실시간으로 실행됩니다. LAMBDA는 L4 드라이버리스 시스템이 다뤄야 하는 다양한 어려운 상황에 대해 추론하는 데 매우 뛰어나다는 것을 입증했습니다. 자율 주행 차량에서 이 시스템을 실시간으로 실행하는 것은 The Nuro Driver’s™ 자율성 결정에 이 추론을 활용하는 중요한 이정표입니다.</p>
<p>대규모 배포 시 자율 주행은 다양한 상황을 대면해야 하기 때문에 어려운 과제입니다. 인간들은 세계 지식과 삶의 경험으로 배운 상식 추론을 사용하여 &quot;long-tail&quot; 도전 과제에 대해 추론할 수 있습니다. 대형 언어 모델 (LLMs)은 방대한 양의 데이터와 일련의 과제에 대해 훈련되었으며, 그 중 일부는 운전에 직접적인 이점을 제공해주진 않지만 운전 데이터만을 사용하는 것보다 넓은 인간 경험에 더 가까운 일반적인 의미론적 관계가 포함됩니다. 이러한 일반적인 언어 모델을 활용함으로써 자율 시스템이 방대한 운전 훈련 말뭉치에도 보이지 않을 수도 있는 시나리오에 대해 더 나은 추론을 할 수 있다고 믿습니다.</p>
<p>추론 및 상식 능력 외에도, LLMs와 MLLMs는 구체적이거나 서면 언어를 통해 구현된 AI 시스템과 자연스럽게 상호 작용하는 방법을 제공합니다. 이는 MLLMs와 통합된 자율 시스템이 실시간 지침을 받거나 수행된 작업에 대해 설명을 작성할 수 있게 해줍니다. 또한 이것은 텍스트 설명 형태의 교육 데이터를 확보하여 자율 시스템을 개선하는 새로운 방법을 제공합니다. 이는 도로 주행 데이터 수집에 비해 더 확장 가능하고 몇 가지 측면에서 더 풍부한 보완이 될 수 있습니다.</p>
<p>Nuro에서는 언어 기반 자율 주행 스택에는 많은 잠재적인 사용 사례가 있다고 믿습니다. 그래서 우리는 LAMBDA를 구축했으며, 이는 차량 내 경험, 자율 결정 및 그 외 여러 가지에 이점을 제공할 다목적 언어 모델로서 개발되었습니다.</p>
<p>이 블로그 포스트에서는 우리가 LAMBDA의 첫 도로 시승 시연을 공유하며, 이를 통해 승객들에게 세계 상황 및 자율 결정에 대한 관찰을 설명할 수 있는 코멘터리 시스템으로 어떻게 활용할 수 있는지 확인하겠습니다.</p>
<h1>상태 및 조치 추론</h1>
<p>LAMBDA는 다양한 작업을 수행할 수 있는 능력을 갖추고 있으며, 다양한 질문에 응답할 수 있습니다. 복잡한 도로 상황에서 실시간 결정을 내리는 데 LAMBDA를 활용하고, 상황에 맞는 최선의 조치를 고려하기 위해서는 자율 주행 차량의 현재 상태와 그 주변 환경을 깊이 이해하도록 가르쳐야 합니다. 우리는 LAMBDA를 이해력 깊은 훈련을 통해 자율 주행 차량의 현재 상황과 환경 사이의 관련성을 설명하는 자연어 질문에 응답할 수 있도록 했습니다. 구체적으로, LAMBDA는 기본 질문에 대답합니다:</p>
<p>무슨 일을 하고 있고 왜그래요?</p>
<p>일반적인 위치 및 상황에 관한 일반적인 설명을 제외하고도, LAMBDA는 Nuro의 인식 스택에서 할당된 고유한 ID를 사용하여 특정 도로 사용자를 가리킬 수 있습니다. 이 ID를 통해 LAMBDA는 개별 도로 사용자에 대해 명확하고 모호하지 않은 방식으로 추론할 수 있으며, 특정 도로 사용자에 관한 후속 질문도 가능합니다. 다음 예에서 자율 주행 차량은 좌측 장면에서 두 명의 자전거 타는 사람에 양보하고, 우측 장면에서 오는 차량에도 양보하고 있습니다. 양 케이스 모두, LAMBDA는 그들의 고유 ID를 올바르게 응답에 사용합니다.</p>
<p>LAMBDA는 Nuro의 인식 스택에서 할당된 고유한 ID에 따라 도로 사용자를 가리킬 수 있습니다.</p>
<p>LAMBDA는 현재 시나리오의 컨텍스트, 다른 에이전트들의 잠재적 사고에 관한 질문, 그리고 그들이 Nuro의 자율 주행 차량과 어떻게 상호 작용하는지에 대해 추론할 필요가 있는 지능적인 운전자가 해야 할 다양한 질문에 적응할 수 있습니다.</p>
<h1>람다(LAMBDA)의 아키텍처</h1>
<p>람다는 우리의 자율 주행 스택과 통합된 다중 모달 LLM으로, 자율 주행 차량 및 그 환경인 세계 상태에 접근할 수 있습니다. 이는 Nuro 차량에 대한 정보(차량의 이력, 경로 및 운동학을 포함), 에이전트 기능(주변 도로 사용자에 대한 정보) 및 맵 및 인식 모듈에서 제공되는 장면 수준 정보를 포함한 다른 맥락 기능을 포함합니다. 행동 기반 모델은 세계 상태 특징을 연속 토큰 표현으로 인코딩하여 LLM이 효율적으로 처리할 수 있도록 합니다.</p>
<p>LLM과 행동 기반 모델 모두 사전 훈련된 기본 모델을 사용하며, 후자는 수억 개의 주행 예시를 포함한 데이터셋에서 사전 훈련됩니다. 결합된 람다 모델은 자동 및 수동 라벨링을 통해 수집된 다양한 데이터 및 작업에 대해 세밀하게 조정됩니다.</p>
<p>람다는 자율 주행 차량의 기내 하드웨어 플랫폼에서 최적화되어 배포되며 운영에는 원격 연결이 필요하지 않습니다. 승객을 위한 상호 작용 인터페이스를 제공하기 위해 태블릿이 기내 플랫폼에 연결되어 사용자 질문과 람다의 응답을 소통합니다.</p>
<p><img src="/assets/img/2024-05-15-StateandActionReasoning_1.png" alt="image"/></p>
<h1>LAMBDA를 향한 실시간 결정 제어</h1>
<p>LLM과 MLLM의 탁월한 특성은 자율 시스템을 새로운 환경과 일반적이지 않은 도로 사건(롱테일 사건)에 적용하여 확장시키는 데 뛰어난 후보로 만듭니다. 그러나, 이러한 모델들이 롱테일 운전 상황에서의 의사 결정에 효과적으로 활용되기 위해서는 극복해야 할 여러 가지 도전 과제가 있습니다.</p>
<ul>
<li>의사 결정에 필수적인 요소들에 대해 신뢰할 수 있는 추론을 진행해야 합니다. 기본적인 MLLM은 운전 의사 결정에까지 이어지는 강력한 추론과 상식 능력을 갖추고 있지만, 롱테일 주행 배포에 필요한 안전성과 범위를 보장하기 위해서는 추가적인 적응이 필요합니다. 롱테일 의사 결정에 필요한 모든 중요한 요소들이 효과적이고 정확하게 입력에서 포착되도록 강력한 장면 이해가 중요합니다. 현재 LAMBDA는 다양한 도로 상황에서 고급 이해와 추론을 보여주며, 확장 가능한 데이터 수집, 모델 교육 및 평가 파이프라인을 구축함으로써 정확성을 향상시키고 있습니다.</li>
<li>운전 결정 시 LLM의 인터넷 규모의 지식과 추론을 활용해야 합니다. LLM은 운전 계획을 직접적으로 생성하여 자율 시스템의 제어 시스템이 행동으로 실행할 수 있도록 훈련될 수 있지만, 핵심 과제는 LLM 내부에 내재된 지식 및 추론 능력을 활용하는 것입니다. 고수준 운전 계획의 형태로 자연어 생성을 통해 이러한 능력을 명시적으로 활용할 수 있을 수 있습니다. 그러나, 이러한 시스템의 성공적인 실현은 고수준 계획 구성에서 여러 디자인 요소의 균형에 크게 의존합니다. 이는 롱테일 의사 결정을 허용하기 위한 유연성, 신뢰할 수 있는 하위 계층 변환을 위한 구체성, 하위 계획의 미묘한 뉘앙스를 제어하기 위한 세분성 및 실시간 의사 결정에 필요한 계산 제한을 포함합니다.</li>
<li>통합 자율 시스템의 안전성과 보안을 보장해야 합니다. LLM은 가끔 추론으로 인한 사실이 아닌 정보, 즉 환각을 생성하는 경우가 있습니다. 의사 결정에 영향을 미치는 오류를 최소화하는 것이 중요하지만, 자율 시스템은 잠재적인 오류에 강건해야 합니다. 특히, 결정적인 LLM 추론을 기반으로 하는 안전하지 않은 결정을 실행하는 것을 제한하는 유효성 검사 프로세스를 유지하는 것이 중요합니다. 또한, 외부로부터 제공된 어떠한 입력이든(예: 인간 상호작용을 통해) LLM으로 공급되는 것을 매우 제어된 방식으로 전달하는 보안 조치를 개발해야 합니다.</li>
</ul>
<p>도전이 있지만, 우리는 다중 모달 LLM이 자율 주행 차량이 결정을 내리는 방식을 혁신할 잠재력을 가지고 있다고 믿습니다. 저희는 세계적인 4단계 주행 소프트웨어를 계속 발전시키는 한, 람다(LAMBDA)의 미래에 대한 더 많은 활용을 보여주기를 기대합니다.</p>
<p>만약 우리의 미션을 믿고, 자율 주행의 미래를 만드는 데 도울 수 있다면, 함께 해주세요! <a href="https://www.nuro.ai/careers">링크</a></p>
<p>저자: 아리안 아르바비, 브라이언 요, 하오환 왕, 우밍 장, 조지 매튜스, 매튜 한초르, 알렉산드르 페티우쇼</p>
<p>또한 도움과 지원을 제공해준 아론 웰디, 브랜던 버클리, 에린 그레이시, 존 레리포드, 카이 앙, 막스 시겔, 멩션 리우, 산티아고 시니스테라, 우리 질린스키, 이페이 셴, 그 외 여기에 언급되지 않은 누로 팀 멤버들에게도 저자들이 고마움을 전합니다.</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"상태 및 행동 이유론","description":"","date":"2024-05-15 23:57","slug":"2024-05-15-StateandActionReasoning","content":"\n\n![image](/assets/img/2024-05-15-StateandActionReasoning_0.png)\n\n안녕하세요! 이번 블로그 포스트에서는 Nuro의 다중 모달 대형 언어 모델 (MLLM)인 LAMBDA를 소개합니다. LAMBDA는 Nuro 운전자의 자율 주행 시스템인 The Nuro Driver’s™ 내장 자율성 스택의 일부로 질문에 답하고, 저희의 자율 주행 차량 플랫폼 내부 하드웨어에서 실시간으로 실행됩니다. LAMBDA는 L4 드라이버리스 시스템이 다뤄야 하는 다양한 어려운 상황에 대해 추론하는 데 매우 뛰어나다는 것을 입증했습니다. 자율 주행 차량에서 이 시스템을 실시간으로 실행하는 것은 The Nuro Driver’s™ 자율성 결정에 이 추론을 활용하는 중요한 이정표입니다.\n\n대규모 배포 시 자율 주행은 다양한 상황을 대면해야 하기 때문에 어려운 과제입니다. 인간들은 세계 지식과 삶의 경험으로 배운 상식 추론을 사용하여 \"long-tail\" 도전 과제에 대해 추론할 수 있습니다. 대형 언어 모델 (LLMs)은 방대한 양의 데이터와 일련의 과제에 대해 훈련되었으며, 그 중 일부는 운전에 직접적인 이점을 제공해주진 않지만 운전 데이터만을 사용하는 것보다 넓은 인간 경험에 더 가까운 일반적인 의미론적 관계가 포함됩니다. 이러한 일반적인 언어 모델을 활용함으로써 자율 시스템이 방대한 운전 훈련 말뭉치에도 보이지 않을 수도 있는 시나리오에 대해 더 나은 추론을 할 수 있다고 믿습니다.\n\n추론 및 상식 능력 외에도, LLMs와 MLLMs는 구체적이거나 서면 언어를 통해 구현된 AI 시스템과 자연스럽게 상호 작용하는 방법을 제공합니다. 이는 MLLMs와 통합된 자율 시스템이 실시간 지침을 받거나 수행된 작업에 대해 설명을 작성할 수 있게 해줍니다. 또한 이것은 텍스트 설명 형태의 교육 데이터를 확보하여 자율 시스템을 개선하는 새로운 방법을 제공합니다. 이는 도로 주행 데이터 수집에 비해 더 확장 가능하고 몇 가지 측면에서 더 풍부한 보완이 될 수 있습니다.\n\n\n\nNuro에서는 언어 기반 자율 주행 스택에는 많은 잠재적인 사용 사례가 있다고 믿습니다. 그래서 우리는 LAMBDA를 구축했으며, 이는 차량 내 경험, 자율 결정 및 그 외 여러 가지에 이점을 제공할 다목적 언어 모델로서 개발되었습니다.\n\n이 블로그 포스트에서는 우리가 LAMBDA의 첫 도로 시승 시연을 공유하며, 이를 통해 승객들에게 세계 상황 및 자율 결정에 대한 관찰을 설명할 수 있는 코멘터리 시스템으로 어떻게 활용할 수 있는지 확인하겠습니다.\n\n# 상태 및 조치 추론\n\nLAMBDA는 다양한 작업을 수행할 수 있는 능력을 갖추고 있으며, 다양한 질문에 응답할 수 있습니다. 복잡한 도로 상황에서 실시간 결정을 내리는 데 LAMBDA를 활용하고, 상황에 맞는 최선의 조치를 고려하기 위해서는 자율 주행 차량의 현재 상태와 그 주변 환경을 깊이 이해하도록 가르쳐야 합니다. 우리는 LAMBDA를 이해력 깊은 훈련을 통해 자율 주행 차량의 현재 상황과 환경 사이의 관련성을 설명하는 자연어 질문에 응답할 수 있도록 했습니다. 구체적으로, LAMBDA는 기본 질문에 대답합니다:\n\n\n\n무슨 일을 하고 있고 왜그래요?\n\n일반적인 위치 및 상황에 관한 일반적인 설명을 제외하고도, LAMBDA는 Nuro의 인식 스택에서 할당된 고유한 ID를 사용하여 특정 도로 사용자를 가리킬 수 있습니다. 이 ID를 통해 LAMBDA는 개별 도로 사용자에 대해 명확하고 모호하지 않은 방식으로 추론할 수 있으며, 특정 도로 사용자에 관한 후속 질문도 가능합니다. 다음 예에서 자율 주행 차량은 좌측 장면에서 두 명의 자전거 타는 사람에 양보하고, 우측 장면에서 오는 차량에도 양보하고 있습니다. 양 케이스 모두, LAMBDA는 그들의 고유 ID를 올바르게 응답에 사용합니다.\n\nLAMBDA는 Nuro의 인식 스택에서 할당된 고유한 ID에 따라 도로 사용자를 가리킬 수 있습니다.\n\nLAMBDA는 현재 시나리오의 컨텍스트, 다른 에이전트들의 잠재적 사고에 관한 질문, 그리고 그들이 Nuro의 자율 주행 차량과 어떻게 상호 작용하는지에 대해 추론할 필요가 있는 지능적인 운전자가 해야 할 다양한 질문에 적응할 수 있습니다.\n\n\n\n# 람다(LAMBDA)의 아키텍처\n\n람다는 우리의 자율 주행 스택과 통합된 다중 모달 LLM으로, 자율 주행 차량 및 그 환경인 세계 상태에 접근할 수 있습니다. 이는 Nuro 차량에 대한 정보(차량의 이력, 경로 및 운동학을 포함), 에이전트 기능(주변 도로 사용자에 대한 정보) 및 맵 및 인식 모듈에서 제공되는 장면 수준 정보를 포함한 다른 맥락 기능을 포함합니다. 행동 기반 모델은 세계 상태 특징을 연속 토큰 표현으로 인코딩하여 LLM이 효율적으로 처리할 수 있도록 합니다.\n\nLLM과 행동 기반 모델 모두 사전 훈련된 기본 모델을 사용하며, 후자는 수억 개의 주행 예시를 포함한 데이터셋에서 사전 훈련됩니다. 결합된 람다 모델은 자동 및 수동 라벨링을 통해 수집된 다양한 데이터 및 작업에 대해 세밀하게 조정됩니다.\n\n람다는 자율 주행 차량의 기내 하드웨어 플랫폼에서 최적화되어 배포되며 운영에는 원격 연결이 필요하지 않습니다. 승객을 위한 상호 작용 인터페이스를 제공하기 위해 태블릿이 기내 플랫폼에 연결되어 사용자 질문과 람다의 응답을 소통합니다.\n\n\n\n![image](/assets/img/2024-05-15-StateandActionReasoning_1.png)\n\n# LAMBDA를 향한 실시간 결정 제어\n\nLLM과 MLLM의 탁월한 특성은 자율 시스템을 새로운 환경과 일반적이지 않은 도로 사건(롱테일 사건)에 적용하여 확장시키는 데 뛰어난 후보로 만듭니다. 그러나, 이러한 모델들이 롱테일 운전 상황에서의 의사 결정에 효과적으로 활용되기 위해서는 극복해야 할 여러 가지 도전 과제가 있습니다.\n\n- 의사 결정에 필수적인 요소들에 대해 신뢰할 수 있는 추론을 진행해야 합니다. 기본적인 MLLM은 운전 의사 결정에까지 이어지는 강력한 추론과 상식 능력을 갖추고 있지만, 롱테일 주행 배포에 필요한 안전성과 범위를 보장하기 위해서는 추가적인 적응이 필요합니다. 롱테일 의사 결정에 필요한 모든 중요한 요소들이 효과적이고 정확하게 입력에서 포착되도록 강력한 장면 이해가 중요합니다. 현재 LAMBDA는 다양한 도로 상황에서 고급 이해와 추론을 보여주며, 확장 가능한 데이터 수집, 모델 교육 및 평가 파이프라인을 구축함으로써 정확성을 향상시키고 있습니다.\n- 운전 결정 시 LLM의 인터넷 규모의 지식과 추론을 활용해야 합니다. LLM은 운전 계획을 직접적으로 생성하여 자율 시스템의 제어 시스템이 행동으로 실행할 수 있도록 훈련될 수 있지만, 핵심 과제는 LLM 내부에 내재된 지식 및 추론 능력을 활용하는 것입니다. 고수준 운전 계획의 형태로 자연어 생성을 통해 이러한 능력을 명시적으로 활용할 수 있을 수 있습니다. 그러나, 이러한 시스템의 성공적인 실현은 고수준 계획 구성에서 여러 디자인 요소의 균형에 크게 의존합니다. 이는 롱테일 의사 결정을 허용하기 위한 유연성, 신뢰할 수 있는 하위 계층 변환을 위한 구체성, 하위 계획의 미묘한 뉘앙스를 제어하기 위한 세분성 및 실시간 의사 결정에 필요한 계산 제한을 포함합니다.\n- 통합 자율 시스템의 안전성과 보안을 보장해야 합니다. LLM은 가끔 추론으로 인한 사실이 아닌 정보, 즉 환각을 생성하는 경우가 있습니다. 의사 결정에 영향을 미치는 오류를 최소화하는 것이 중요하지만, 자율 시스템은 잠재적인 오류에 강건해야 합니다. 특히, 결정적인 LLM 추론을 기반으로 하는 안전하지 않은 결정을 실행하는 것을 제한하는 유효성 검사 프로세스를 유지하는 것이 중요합니다. 또한, 외부로부터 제공된 어떠한 입력이든(예: 인간 상호작용을 통해) LLM으로 공급되는 것을 매우 제어된 방식으로 전달하는 보안 조치를 개발해야 합니다.\n\n\n\n도전이 있지만, 우리는 다중 모달 LLM이 자율 주행 차량이 결정을 내리는 방식을 혁신할 잠재력을 가지고 있다고 믿습니다. 저희는 세계적인 4단계 주행 소프트웨어를 계속 발전시키는 한, 람다(LAMBDA)의 미래에 대한 더 많은 활용을 보여주기를 기대합니다.\n\n만약 우리의 미션을 믿고, 자율 주행의 미래를 만드는 데 도울 수 있다면, 함께 해주세요! [링크](https://www.nuro.ai/careers)\n\n저자: 아리안 아르바비, 브라이언 요, 하오환 왕, 우밍 장, 조지 매튜스, 매튜 한초르, 알렉산드르 페티우쇼\n\n또한 도움과 지원을 제공해준 아론 웰디, 브랜던 버클리, 에린 그레이시, 존 레리포드, 카이 앙, 막스 시겔, 멩션 리우, 산티아고 시니스테라, 우리 질린스키, 이페이 셴, 그 외 여기에 언급되지 않은 누로 팀 멤버들에게도 저자들이 고마움을 전합니다.","ogImage":{"url":"/assets/img/2024-05-15-StateandActionReasoning_0.png"},"coverImage":"/assets/img/2024-05-15-StateandActionReasoning_0.png","tag":["Tech"],"readingTime":5},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    h1: \"h1\",\n    ul: \"ul\",\n    li: \"li\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-StateandActionReasoning_0.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"안녕하세요! 이번 블로그 포스트에서는 Nuro의 다중 모달 대형 언어 모델 (MLLM)인 LAMBDA를 소개합니다. LAMBDA는 Nuro 운전자의 자율 주행 시스템인 The Nuro Driver’s™ 내장 자율성 스택의 일부로 질문에 답하고, 저희의 자율 주행 차량 플랫폼 내부 하드웨어에서 실시간으로 실행됩니다. LAMBDA는 L4 드라이버리스 시스템이 다뤄야 하는 다양한 어려운 상황에 대해 추론하는 데 매우 뛰어나다는 것을 입증했습니다. 자율 주행 차량에서 이 시스템을 실시간으로 실행하는 것은 The Nuro Driver’s™ 자율성 결정에 이 추론을 활용하는 중요한 이정표입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"대규모 배포 시 자율 주행은 다양한 상황을 대면해야 하기 때문에 어려운 과제입니다. 인간들은 세계 지식과 삶의 경험으로 배운 상식 추론을 사용하여 \\\"long-tail\\\" 도전 과제에 대해 추론할 수 있습니다. 대형 언어 모델 (LLMs)은 방대한 양의 데이터와 일련의 과제에 대해 훈련되었으며, 그 중 일부는 운전에 직접적인 이점을 제공해주진 않지만 운전 데이터만을 사용하는 것보다 넓은 인간 경험에 더 가까운 일반적인 의미론적 관계가 포함됩니다. 이러한 일반적인 언어 모델을 활용함으로써 자율 시스템이 방대한 운전 훈련 말뭉치에도 보이지 않을 수도 있는 시나리오에 대해 더 나은 추론을 할 수 있다고 믿습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"추론 및 상식 능력 외에도, LLMs와 MLLMs는 구체적이거나 서면 언어를 통해 구현된 AI 시스템과 자연스럽게 상호 작용하는 방법을 제공합니다. 이는 MLLMs와 통합된 자율 시스템이 실시간 지침을 받거나 수행된 작업에 대해 설명을 작성할 수 있게 해줍니다. 또한 이것은 텍스트 설명 형태의 교육 데이터를 확보하여 자율 시스템을 개선하는 새로운 방법을 제공합니다. 이는 도로 주행 데이터 수집에 비해 더 확장 가능하고 몇 가지 측면에서 더 풍부한 보완이 될 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Nuro에서는 언어 기반 자율 주행 스택에는 많은 잠재적인 사용 사례가 있다고 믿습니다. 그래서 우리는 LAMBDA를 구축했으며, 이는 차량 내 경험, 자율 결정 및 그 외 여러 가지에 이점을 제공할 다목적 언어 모델로서 개발되었습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 블로그 포스트에서는 우리가 LAMBDA의 첫 도로 시승 시연을 공유하며, 이를 통해 승객들에게 세계 상황 및 자율 결정에 대한 관찰을 설명할 수 있는 코멘터리 시스템으로 어떻게 활용할 수 있는지 확인하겠습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"상태 및 조치 추론\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LAMBDA는 다양한 작업을 수행할 수 있는 능력을 갖추고 있으며, 다양한 질문에 응답할 수 있습니다. 복잡한 도로 상황에서 실시간 결정을 내리는 데 LAMBDA를 활용하고, 상황에 맞는 최선의 조치를 고려하기 위해서는 자율 주행 차량의 현재 상태와 그 주변 환경을 깊이 이해하도록 가르쳐야 합니다. 우리는 LAMBDA를 이해력 깊은 훈련을 통해 자율 주행 차량의 현재 상황과 환경 사이의 관련성을 설명하는 자연어 질문에 응답할 수 있도록 했습니다. 구체적으로, LAMBDA는 기본 질문에 대답합니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"무슨 일을 하고 있고 왜그래요?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"일반적인 위치 및 상황에 관한 일반적인 설명을 제외하고도, LAMBDA는 Nuro의 인식 스택에서 할당된 고유한 ID를 사용하여 특정 도로 사용자를 가리킬 수 있습니다. 이 ID를 통해 LAMBDA는 개별 도로 사용자에 대해 명확하고 모호하지 않은 방식으로 추론할 수 있으며, 특정 도로 사용자에 관한 후속 질문도 가능합니다. 다음 예에서 자율 주행 차량은 좌측 장면에서 두 명의 자전거 타는 사람에 양보하고, 우측 장면에서 오는 차량에도 양보하고 있습니다. 양 케이스 모두, LAMBDA는 그들의 고유 ID를 올바르게 응답에 사용합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LAMBDA는 Nuro의 인식 스택에서 할당된 고유한 ID에 따라 도로 사용자를 가리킬 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LAMBDA는 현재 시나리오의 컨텍스트, 다른 에이전트들의 잠재적 사고에 관한 질문, 그리고 그들이 Nuro의 자율 주행 차량과 어떻게 상호 작용하는지에 대해 추론할 필요가 있는 지능적인 운전자가 해야 할 다양한 질문에 적응할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"람다(LAMBDA)의 아키텍처\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"람다는 우리의 자율 주행 스택과 통합된 다중 모달 LLM으로, 자율 주행 차량 및 그 환경인 세계 상태에 접근할 수 있습니다. 이는 Nuro 차량에 대한 정보(차량의 이력, 경로 및 운동학을 포함), 에이전트 기능(주변 도로 사용자에 대한 정보) 및 맵 및 인식 모듈에서 제공되는 장면 수준 정보를 포함한 다른 맥락 기능을 포함합니다. 행동 기반 모델은 세계 상태 특징을 연속 토큰 표현으로 인코딩하여 LLM이 효율적으로 처리할 수 있도록 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LLM과 행동 기반 모델 모두 사전 훈련된 기본 모델을 사용하며, 후자는 수억 개의 주행 예시를 포함한 데이터셋에서 사전 훈련됩니다. 결합된 람다 모델은 자동 및 수동 라벨링을 통해 수집된 다양한 데이터 및 작업에 대해 세밀하게 조정됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"람다는 자율 주행 차량의 기내 하드웨어 플랫폼에서 최적화되어 배포되며 운영에는 원격 연결이 필요하지 않습니다. 승객을 위한 상호 작용 인터페이스를 제공하기 위해 태블릿이 기내 플랫폼에 연결되어 사용자 질문과 람다의 응답을 소통합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-StateandActionReasoning_1.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"LAMBDA를 향한 실시간 결정 제어\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LLM과 MLLM의 탁월한 특성은 자율 시스템을 새로운 환경과 일반적이지 않은 도로 사건(롱테일 사건)에 적용하여 확장시키는 데 뛰어난 후보로 만듭니다. 그러나, 이러한 모델들이 롱테일 운전 상황에서의 의사 결정에 효과적으로 활용되기 위해서는 극복해야 할 여러 가지 도전 과제가 있습니다.\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"의사 결정에 필수적인 요소들에 대해 신뢰할 수 있는 추론을 진행해야 합니다. 기본적인 MLLM은 운전 의사 결정에까지 이어지는 강력한 추론과 상식 능력을 갖추고 있지만, 롱테일 주행 배포에 필요한 안전성과 범위를 보장하기 위해서는 추가적인 적응이 필요합니다. 롱테일 의사 결정에 필요한 모든 중요한 요소들이 효과적이고 정확하게 입력에서 포착되도록 강력한 장면 이해가 중요합니다. 현재 LAMBDA는 다양한 도로 상황에서 고급 이해와 추론을 보여주며, 확장 가능한 데이터 수집, 모델 교육 및 평가 파이프라인을 구축함으로써 정확성을 향상시키고 있습니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"운전 결정 시 LLM의 인터넷 규모의 지식과 추론을 활용해야 합니다. LLM은 운전 계획을 직접적으로 생성하여 자율 시스템의 제어 시스템이 행동으로 실행할 수 있도록 훈련될 수 있지만, 핵심 과제는 LLM 내부에 내재된 지식 및 추론 능력을 활용하는 것입니다. 고수준 운전 계획의 형태로 자연어 생성을 통해 이러한 능력을 명시적으로 활용할 수 있을 수 있습니다. 그러나, 이러한 시스템의 성공적인 실현은 고수준 계획 구성에서 여러 디자인 요소의 균형에 크게 의존합니다. 이는 롱테일 의사 결정을 허용하기 위한 유연성, 신뢰할 수 있는 하위 계층 변환을 위한 구체성, 하위 계획의 미묘한 뉘앙스를 제어하기 위한 세분성 및 실시간 의사 결정에 필요한 계산 제한을 포함합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"통합 자율 시스템의 안전성과 보안을 보장해야 합니다. LLM은 가끔 추론으로 인한 사실이 아닌 정보, 즉 환각을 생성하는 경우가 있습니다. 의사 결정에 영향을 미치는 오류를 최소화하는 것이 중요하지만, 자율 시스템은 잠재적인 오류에 강건해야 합니다. 특히, 결정적인 LLM 추론을 기반으로 하는 안전하지 않은 결정을 실행하는 것을 제한하는 유효성 검사 프로세스를 유지하는 것이 중요합니다. 또한, 외부로부터 제공된 어떠한 입력이든(예: 인간 상호작용을 통해) LLM으로 공급되는 것을 매우 제어된 방식으로 전달하는 보안 조치를 개발해야 합니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"도전이 있지만, 우리는 다중 모달 LLM이 자율 주행 차량이 결정을 내리는 방식을 혁신할 잠재력을 가지고 있다고 믿습니다. 저희는 세계적인 4단계 주행 소프트웨어를 계속 발전시키는 한, 람다(LAMBDA)의 미래에 대한 더 많은 활용을 보여주기를 기대합니다.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"만약 우리의 미션을 믿고, 자율 주행의 미래를 만드는 데 도울 수 있다면, 함께 해주세요! \", _jsx(_components.a, {\n        href: \"https://www.nuro.ai/careers\",\n        children: \"링크\"\n      })]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"저자: 아리안 아르바비, 브라이언 요, 하오환 왕, 우밍 장, 조지 매튜스, 매튜 한초르, 알렉산드르 페티우쇼\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"또한 도움과 지원을 제공해준 아론 웰디, 브랜던 버클리, 에린 그레이시, 존 레리포드, 카이 앙, 막스 시겔, 멩션 리우, 산티아고 시니스테라, 우리 질린스키, 이페이 셴, 그 외 여기에 언급되지 않은 누로 팀 멤버들에게도 저자들이 고마움을 전합니다.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-15-StateandActionReasoning"},"buildId":"ZCLw62NtQD8-xdhHOoU4Q","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>