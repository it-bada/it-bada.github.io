<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>동일한 인공 지능  다른 배치 계획  다른 윤리적 문제 | it-bada</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://it-bada.github.io///post/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="동일한 인공 지능  다른 배치 계획  다른 윤리적 문제 | it-bada" data-gatsby-head="true"/><meta property="og:title" content="동일한 인공 지능  다른 배치 계획  다른 윤리적 문제 | it-bada" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://it-bada.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://it-bada.github.io///post/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics" data-gatsby-head="true"/><meta name="twitter:title" content="동일한 인공 지능  다른 배치 계획  다른 윤리적 문제 | it-bada" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | it-bada" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-15 19:46" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-1b0cb1352029e0fa.js" defer=""></script><script src="/_next/static/ZCLw62NtQD8-xdhHOoU4Q/_buildManifest.js" defer=""></script><script src="/_next/static/ZCLw62NtQD8-xdhHOoU4Q/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Bada</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">동일한 인공 지능  다른 배치 계획  다른 윤리적 문제</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="동일한 인공 지능  다른 배치 계획  다른 윤리적 문제" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Bada</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 15, 2024</span><span class="posts_reading_time__f7YPP">3<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p>이번 달에는 인공지능(AI) 및 분석의 윤리적 측면 중 하나에 대해 다뤄보려고 해요. 많은 사람들이 제대로 이해하지 못하는 부분이 있답니다. 특정한 알고리즘의 윤리성은 제안된 특정 범위와 맥락에 따라 다를 수 있어요. 한 범위와 맥락에서 부적절하다고 여기는 것이 다른 곳에서는 완전히 괜찮을 수도 있어요. 예를 통해 설명하고, AI 배치가 윤리적으로 유지될 수 있는 단계를 제시할 거예요.</p>
<p><img src="/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png" alt="img"/></p>
<p>왜 자율 주행 자동차가 아직 광범위한 배치에 윤리적이지 않은 이유</p>
<p>오늘날 전 세계에서 완전히 자율 주행, 운전자 없는 자동차의 제한된 테스트가 진행 중이에요. 하지만 이 자동차들은 주로 급격한 일이 발생할 때 빠르게 정지할 수 있는 저속 도시 거리로 제한되어 있어요. 물론, 이러한 저속 자동차들도 문제가 없는 건 아니에요. 예를 들어, 자율 주행 자동차가 필요 없는 상황에서 혼란스러워져 정지하고 다시 움직이지 않아 교통 체증을 일으키는 보고가 있어요.</p>
<p>고속도로와 복잡한 교통에서 완전 자율 주행 차량을 아직 보지 못했습니다. 그 이유 중 하나는 차가 빠르게 이동하고 잘 정의된 도로 그리드에 없을 때 많은 문제가 발생할 수 있다는 것입니다. 자율 주행 차량이 15마일의 속도로 움직일 때 처리하지 못하는 상황을 만나면 안전하게 브레이크를 밟을 수 있습니다. 그러나 65마일의 고속도로 교통에서 이를 하게 되면 대형 사고를 일으킬 수 있습니다. 따라서 우리가 자율 주행 차량이 신속하게 안전하게 대응할 수 있다고 확신할 때까지, 새롭고 다채로운 시나리오를 포함하여 거의 모든 상황에 안전하게 대처할 것이라는 확신이 없다면, 도로에서 대규모로 자율 주행 차량을 풀어주는 것은 윤리적으로 적절하지 않을 것입니다.</p>
<p>일부 거대 차량은 이미 완전 자율 주행 - 그리고 윤리적!</p>
<p>오늘날 차량이 완전히 자율 주행될 수 없다면, 회전하는 날카로운 칼날과 거대한 크기를 가진 거대 농업 장비 또한 완전 자율 주행될 수 없을 것이라고 생각할 수 있을까요? 아니요! John Deere와 같은 제조사들은 이미 농경지에서 완전 자율 주행되는 농업 장비를 사용하고 있습니다. 아래 사진에서 한 예시를 확인할 수 있습니다. 이 거대한 기계는 자유롭게 농경지를 이동하는데, 그럼에도 불구하고 윤리적입니다. 이는 어째서 그럴까요?</p>
<p><img src="/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_1.png" alt="이미지"/></p>
<p>이 경우에는 장비가 거대하고 위험하지만 외딴 곳에서 상대적으로 낮은 속도로 움직이고 있습니다. 피할 다른 차량이 없으며 장애물도 거의 없습니다. 트랙터가 처리 방법을 모르는 것을 발견하면 그냥 멈추고 소유주인 농부에게 앱을 통해 알립니다. 농부는 이미지를 확인하고 결정을 내립니다. 사진에 담긴 것이 이상하게 구름을 반사하고 있는 웅덩이인 경우, 장비한테 전진할 수 있도록 할 수 있습니다. 그러나 부상을 입은 소가 보이면, 소가 돌봐지기 전까지 장비를 멈출 수 있습니다.</p>
<p>이 자율 주행 차량은 윤리적으로 사용하기에 적합합니다. 장비는 특정 환경에 있어서 안전하게 빠르게 멈출 수 있고, 혼란스러울 때 빠르게 멈출 수 있으며, 이상한 상황을 다루는 데 도와줄 인간 동료인 농부가 있기 때문입니다. 자율 농장 장비의 범위와 문맥은 일반 자동차와는 다르기 때문에 윤리적 판단이 다른 결론으로 이끌어집니다.</p>
<p>범위와 문맥 개념을 실천에 적용하는 방법</p>
<p>이 예시로부터 얻을 수 있는 중요한 점이 몇 가지 있습니다. 먼저, 특정 유형의 AI 알고리즘이나 응용 프로그램을 그냥 &quot;윤리적&quot;이거나 &quot;비윤리적&quot;으로 레이블하면 안 됩니다. 또한, 제안된 각 배치의 특정 범위와 문맥을 고려해야 하며, 모든 개별 사례에 대해 새로운 평가를 수행해야 합니다.</p>
<p>두 번째로, 주기적으로 과거의 결정을 재방문하는 것이 중요합니다. 예를 들어, 자율 주행차 기술이 발전함에 따라 더 많은 종류의 자율 주행차 배치가 윤리적 영역으로 진입할 것입니다. 비슷하게 기업 환경에서도, 업데이트된 거버넌스와 법적 제약 조건으로 인해 어떤 것이 비윤리적에서 윤리적으로 변할 수 있습니다. 윤리에 기반한 결정은 특정 시점에서 유효하며, 모든 시간에 유효한 것은 아닙니다.</p>
<p>마지막으로, 각 상황에 적용되는 모든 위험과 완화 조치를 연구하고 고려해야 합니다. 예를 들어, 상세한 현실을 고려하지 않고 초안 설명에 따른 자율 대형 기계를 큰 위험이라고 가정하는 사람들이 많을 것입니다.</p>
<p>이 모든 것은 AI 및 다른 분석 프로세스의 윤리적 배치를 보증하는 것이 계속되는 노력이라는 것을 강조합니다. 각 제안된 배치를 고려해야 하며, 모든 식별 가능한 위험과 이점을 고려해야 합니다. 이는 앞서 언급했듯이, 계획, 구축 및 배포하는 동안의 모든 단계에서 윤리를 고려하는 데 의도적이고 근면해야 한다는 것을 의미합니다.</p>
<p>LinkedIn Analytics Matters 뉴스레터에 최초로 게시됨</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"동일한 인공 지능  다른 배치 계획  다른 윤리적 문제","description":"","date":"2024-05-15 19:46","slug":"2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics","content":"\n\n이번 달에는 인공지능(AI) 및 분석의 윤리적 측면 중 하나에 대해 다뤄보려고 해요. 많은 사람들이 제대로 이해하지 못하는 부분이 있답니다. 특정한 알고리즘의 윤리성은 제안된 특정 범위와 맥락에 따라 다를 수 있어요. 한 범위와 맥락에서 부적절하다고 여기는 것이 다른 곳에서는 완전히 괜찮을 수도 있어요. 예를 통해 설명하고, AI 배치가 윤리적으로 유지될 수 있는 단계를 제시할 거예요.\n\n![img](/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png)\n\n왜 자율 주행 자동차가 아직 광범위한 배치에 윤리적이지 않은 이유\n\n오늘날 전 세계에서 완전히 자율 주행, 운전자 없는 자동차의 제한된 테스트가 진행 중이에요. 하지만 이 자동차들은 주로 급격한 일이 발생할 때 빠르게 정지할 수 있는 저속 도시 거리로 제한되어 있어요. 물론, 이러한 저속 자동차들도 문제가 없는 건 아니에요. 예를 들어, 자율 주행 자동차가 필요 없는 상황에서 혼란스러워져 정지하고 다시 움직이지 않아 교통 체증을 일으키는 보고가 있어요.\n\n\n\n고속도로와 복잡한 교통에서 완전 자율 주행 차량을 아직 보지 못했습니다. 그 이유 중 하나는 차가 빠르게 이동하고 잘 정의된 도로 그리드에 없을 때 많은 문제가 발생할 수 있다는 것입니다. 자율 주행 차량이 15마일의 속도로 움직일 때 처리하지 못하는 상황을 만나면 안전하게 브레이크를 밟을 수 있습니다. 그러나 65마일의 고속도로 교통에서 이를 하게 되면 대형 사고를 일으킬 수 있습니다. 따라서 우리가 자율 주행 차량이 신속하게 안전하게 대응할 수 있다고 확신할 때까지, 새롭고 다채로운 시나리오를 포함하여 거의 모든 상황에 안전하게 대처할 것이라는 확신이 없다면, 도로에서 대규모로 자율 주행 차량을 풀어주는 것은 윤리적으로 적절하지 않을 것입니다.\n\n일부 거대 차량은 이미 완전 자율 주행 - 그리고 윤리적!\n\n오늘날 차량이 완전히 자율 주행될 수 없다면, 회전하는 날카로운 칼날과 거대한 크기를 가진 거대 농업 장비 또한 완전 자율 주행될 수 없을 것이라고 생각할 수 있을까요? 아니요! John Deere와 같은 제조사들은 이미 농경지에서 완전 자율 주행되는 농업 장비를 사용하고 있습니다. 아래 사진에서 한 예시를 확인할 수 있습니다. 이 거대한 기계는 자유롭게 농경지를 이동하는데, 그럼에도 불구하고 윤리적입니다. 이는 어째서 그럴까요?\n\n![이미지](/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_1.png)\n\n\n\n이 경우에는 장비가 거대하고 위험하지만 외딴 곳에서 상대적으로 낮은 속도로 움직이고 있습니다. 피할 다른 차량이 없으며 장애물도 거의 없습니다. 트랙터가 처리 방법을 모르는 것을 발견하면 그냥 멈추고 소유주인 농부에게 앱을 통해 알립니다. 농부는 이미지를 확인하고 결정을 내립니다. 사진에 담긴 것이 이상하게 구름을 반사하고 있는 웅덩이인 경우, 장비한테 전진할 수 있도록 할 수 있습니다. 그러나 부상을 입은 소가 보이면, 소가 돌봐지기 전까지 장비를 멈출 수 있습니다.\n\n이 자율 주행 차량은 윤리적으로 사용하기에 적합합니다. 장비는 특정 환경에 있어서 안전하게 빠르게 멈출 수 있고, 혼란스러울 때 빠르게 멈출 수 있으며, 이상한 상황을 다루는 데 도와줄 인간 동료인 농부가 있기 때문입니다. 자율 농장 장비의 범위와 문맥은 일반 자동차와는 다르기 때문에 윤리적 판단이 다른 결론으로 이끌어집니다.\n\n범위와 문맥 개념을 실천에 적용하는 방법\n\n이 예시로부터 얻을 수 있는 중요한 점이 몇 가지 있습니다. 먼저, 특정 유형의 AI 알고리즘이나 응용 프로그램을 그냥 \"윤리적\"이거나 \"비윤리적\"으로 레이블하면 안 됩니다. 또한, 제안된 각 배치의 특정 범위와 문맥을 고려해야 하며, 모든 개별 사례에 대해 새로운 평가를 수행해야 합니다.\n\n\n\n두 번째로, 주기적으로 과거의 결정을 재방문하는 것이 중요합니다. 예를 들어, 자율 주행차 기술이 발전함에 따라 더 많은 종류의 자율 주행차 배치가 윤리적 영역으로 진입할 것입니다. 비슷하게 기업 환경에서도, 업데이트된 거버넌스와 법적 제약 조건으로 인해 어떤 것이 비윤리적에서 윤리적으로 변할 수 있습니다. 윤리에 기반한 결정은 특정 시점에서 유효하며, 모든 시간에 유효한 것은 아닙니다.\n\n마지막으로, 각 상황에 적용되는 모든 위험과 완화 조치를 연구하고 고려해야 합니다. 예를 들어, 상세한 현실을 고려하지 않고 초안 설명에 따른 자율 대형 기계를 큰 위험이라고 가정하는 사람들이 많을 것입니다.\n\n이 모든 것은 AI 및 다른 분석 프로세스의 윤리적 배치를 보증하는 것이 계속되는 노력이라는 것을 강조합니다. 각 제안된 배치를 고려해야 하며, 모든 식별 가능한 위험과 이점을 고려해야 합니다. 이는 앞서 언급했듯이, 계획, 구축 및 배포하는 동안의 모든 단계에서 윤리를 고려하는 데 의도적이고 근면해야 한다는 것을 의미합니다.\n\nLinkedIn Analytics Matters 뉴스레터에 최초로 게시됨","ogImage":{"url":"/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png"},"coverImage":"/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png","tag":["Tech"],"readingTime":3},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"이번 달에는 인공지능(AI) 및 분석의 윤리적 측면 중 하나에 대해 다뤄보려고 해요. 많은 사람들이 제대로 이해하지 못하는 부분이 있답니다. 특정한 알고리즘의 윤리성은 제안된 특정 범위와 맥락에 따라 다를 수 있어요. 한 범위와 맥락에서 부적절하다고 여기는 것이 다른 곳에서는 완전히 괜찮을 수도 있어요. 예를 통해 설명하고, AI 배치가 윤리적으로 유지될 수 있는 단계를 제시할 거예요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_0.png\",\n        alt: \"img\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"왜 자율 주행 자동차가 아직 광범위한 배치에 윤리적이지 않은 이유\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"오늘날 전 세계에서 완전히 자율 주행, 운전자 없는 자동차의 제한된 테스트가 진행 중이에요. 하지만 이 자동차들은 주로 급격한 일이 발생할 때 빠르게 정지할 수 있는 저속 도시 거리로 제한되어 있어요. 물론, 이러한 저속 자동차들도 문제가 없는 건 아니에요. 예를 들어, 자율 주행 자동차가 필요 없는 상황에서 혼란스러워져 정지하고 다시 움직이지 않아 교통 체증을 일으키는 보고가 있어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"고속도로와 복잡한 교통에서 완전 자율 주행 차량을 아직 보지 못했습니다. 그 이유 중 하나는 차가 빠르게 이동하고 잘 정의된 도로 그리드에 없을 때 많은 문제가 발생할 수 있다는 것입니다. 자율 주행 차량이 15마일의 속도로 움직일 때 처리하지 못하는 상황을 만나면 안전하게 브레이크를 밟을 수 있습니다. 그러나 65마일의 고속도로 교통에서 이를 하게 되면 대형 사고를 일으킬 수 있습니다. 따라서 우리가 자율 주행 차량이 신속하게 안전하게 대응할 수 있다고 확신할 때까지, 새롭고 다채로운 시나리오를 포함하여 거의 모든 상황에 안전하게 대처할 것이라는 확신이 없다면, 도로에서 대규모로 자율 주행 차량을 풀어주는 것은 윤리적으로 적절하지 않을 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"일부 거대 차량은 이미 완전 자율 주행 - 그리고 윤리적!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"오늘날 차량이 완전히 자율 주행될 수 없다면, 회전하는 날카로운 칼날과 거대한 크기를 가진 거대 농업 장비 또한 완전 자율 주행될 수 없을 것이라고 생각할 수 있을까요? 아니요! John Deere와 같은 제조사들은 이미 농경지에서 완전 자율 주행되는 농업 장비를 사용하고 있습니다. 아래 사진에서 한 예시를 확인할 수 있습니다. 이 거대한 기계는 자유롭게 농경지를 이동하는데, 그럼에도 불구하고 윤리적입니다. 이는 어째서 그럴까요?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics_1.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 경우에는 장비가 거대하고 위험하지만 외딴 곳에서 상대적으로 낮은 속도로 움직이고 있습니다. 피할 다른 차량이 없으며 장애물도 거의 없습니다. 트랙터가 처리 방법을 모르는 것을 발견하면 그냥 멈추고 소유주인 농부에게 앱을 통해 알립니다. 농부는 이미지를 확인하고 결정을 내립니다. 사진에 담긴 것이 이상하게 구름을 반사하고 있는 웅덩이인 경우, 장비한테 전진할 수 있도록 할 수 있습니다. 그러나 부상을 입은 소가 보이면, 소가 돌봐지기 전까지 장비를 멈출 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 자율 주행 차량은 윤리적으로 사용하기에 적합합니다. 장비는 특정 환경에 있어서 안전하게 빠르게 멈출 수 있고, 혼란스러울 때 빠르게 멈출 수 있으며, 이상한 상황을 다루는 데 도와줄 인간 동료인 농부가 있기 때문입니다. 자율 농장 장비의 범위와 문맥은 일반 자동차와는 다르기 때문에 윤리적 판단이 다른 결론으로 이끌어집니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"범위와 문맥 개념을 실천에 적용하는 방법\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 예시로부터 얻을 수 있는 중요한 점이 몇 가지 있습니다. 먼저, 특정 유형의 AI 알고리즘이나 응용 프로그램을 그냥 \\\"윤리적\\\"이거나 \\\"비윤리적\\\"으로 레이블하면 안 됩니다. 또한, 제안된 각 배치의 특정 범위와 문맥을 고려해야 하며, 모든 개별 사례에 대해 새로운 평가를 수행해야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"두 번째로, 주기적으로 과거의 결정을 재방문하는 것이 중요합니다. 예를 들어, 자율 주행차 기술이 발전함에 따라 더 많은 종류의 자율 주행차 배치가 윤리적 영역으로 진입할 것입니다. 비슷하게 기업 환경에서도, 업데이트된 거버넌스와 법적 제약 조건으로 인해 어떤 것이 비윤리적에서 윤리적으로 변할 수 있습니다. 윤리에 기반한 결정은 특정 시점에서 유효하며, 모든 시간에 유효한 것은 아닙니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"마지막으로, 각 상황에 적용되는 모든 위험과 완화 조치를 연구하고 고려해야 합니다. 예를 들어, 상세한 현실을 고려하지 않고 초안 설명에 따른 자율 대형 기계를 큰 위험이라고 가정하는 사람들이 많을 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 모든 것은 AI 및 다른 분석 프로세스의 윤리적 배치를 보증하는 것이 계속되는 노력이라는 것을 강조합니다. 각 제안된 배치를 고려해야 하며, 모든 식별 가능한 위험과 이점을 고려해야 합니다. 이는 앞서 언급했듯이, 계획, 구축 및 배포하는 동안의 모든 단계에서 윤리를 고려하는 데 의도적이고 근면해야 한다는 것을 의미합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"LinkedIn Analytics Matters 뉴스레터에 최초로 게시됨\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-15-SameAIDifferentDeploymentPlansDifferentEthics"},"buildId":"ZCLw62NtQD8-xdhHOoU4Q","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>