---
title: "GPT 모델에 베르니케 실어증이 있을까"
description: ""
coverImage: "/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_0.png"
date: 2024-06-30 23:57
ogImage: 
  url: /assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_0.png
tag: Tech
originalTitle: "Do GPT Models Have Wernicke’s Aphasia?"
link: "https://medium.com/ai-advances/do-gpt-models-have-wernickes-aphasia-e9f1efbdb99b"
---


## 신경과학, 창조적 AI 및 윤리

## 이해 없는 유창한 대화

네 친구가 당신을 돌아보며 "파란 말이 거기서 텔레비전을 마셨어. 어제 거기 있었고 그 말을 봤어." 라고 말합니다.

그들의 말은 유창하게 흘러나가고, 복잡한 문장들이 능숙하게 말려나갑니다. 그들은 화려한 단어를 사용하고 적절한 문법을 사용하지만 그들의 메시지는 극도로 무의미합니다. 당신의 친구는 웨르니케 유창 장애라는 상태일 수 있습니다.

<div class="content-ad"></div>

![Do GPT Models Have Wernicke's Aphasia?](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_0.png)

운니케 실어증을 앓는 사람들은 길고 무의미한 문장으로 말하거나, 흔한 단어와 구문을 반복하며 자신의 말이 무해하다는 것을 모르는 경우가 있습니다. 종종 오해를 받아 당혹스러워 할 수도 있죠.

이러한 연결이 강조하는 핵심은 언어생산과 이해는 같지 않다는 것입니다.

ChatGPT 뒤의 모델과 같이 생성 모델에서도 비슷한 도전이 관찰됩니다. GPT 모델은 자연어 처리에서 놀라운 진전을 이루었지만, 인간의 인식을 특징 짓는 문맥적인 인식 부족으로 실제 응용에서 위험을 야기할 수 있고 실제로 야기해 왔습니다.

<div class="content-ad"></div>

## 생각과 언어 생산 사이의 간극

‘생각’과 ‘언어 생산’ 사이에는 구분이 존재합니다. 두 가지는 서로 연결되어 있지만, 별도의 인지과정을 나타냅니다. 생각은 이해와 추론을 포함하며, 언어는 이러한 생각을 표현하는 매개체입니다. 언어 생산은 생각을 반영하지만 생각 자체와는 동일하지는 않습니다.

![이미지](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_1.png)

우리의 교육 여정 어딘가에서, 우리는 고립된 사실을 암기하는 대신 근본적인 개념을 이해할 것을 권장받았습니다. 이러한 기본적인 접근은 결론을 도출하고 연결점을 인식하는 능력을 우리에게 부여합니다. 이는 단순히 정보를 소화하는 것과 대조적으로 나타나며, 개념을 탄탄히 이해하지 않으면 우리가 알지 못하는 잘못된 정보를 나오게 할 수 있다는 경고가 있었습니다.

<div class="content-ad"></div>

## 정보 재구성 대진단 이해

Wernicke 치매와 GPT 모델의 비교는 GPT-3 이후의 발전을 고려할 때 일대일 대비 관계가 아닙니다. 이 비교는 초기 GPT 모델로 더 적절할 수 있습니다. 그러나 현대 언어 모델은 문법적으로 올바른 문장을 생성하는 뿐만 아니라 일관된 내용 및 종종 사실적인 콘텐츠를 생성합니다. 그러나 진정한 이해력이 부족해 오류 정보나 의사소통 오류를 일으킬 수 있습니다.

![image](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_2.png)

GPT 모델은 근본적으로 방대한 데이터셋에서 훈련된 통계 도구로, 유도된 확률을 기반으로 현실적인 텍스트를 생성합니다. 그러나 사람들이 하는 것처럼 내부 컨텍스트나 세계의 이해력을 보유하고 있지 않습니다. 인간 수준의 텍스트를 생성할 수 있지만 진정으로 그들이 묘사하는 세계를 "이해"할 수 있는지 의문이 남습니다.

<div class="content-ad"></div>

AI 언어 모델들이 던지는 질문들은 철학과 인지과학의 오래된 논쟁들을 연상시킵니다. 철학자 존 서얼이 제안한 '중국 방' 주장은 기호 조작을 통해 시스템이 진정한 이해를 가질 수 있다는 아이디어에 도전하는데, 이 비평은 현재 AI와 의식에 관한 토론에서 관련이 있습니다.

## AI 배치 시 윤리적 고려사항

여러 실제 예시들이 조심하지 않고 생성 모델들을 실행하는 위험을 보여줍니다. 2018년, AI 소프트웨어가 탑재된 아마존 알렉사 기기가 대화를 오인터프리테이션하고 녹음 내용을 무작위 연락처로 전송하는 사고가 발생했습니다. 2020년, Nabla 연구진은 의료 쿼리에 따른 GPT-3의 성능을 평가했습니다. 약물을 정확하게 제안했지만, 때로는 잘못된 용량을 제공하기도 했습니다. 다른 실험에서 GPT-3는 폐색전증 증상에 대한 사용자의 설명을 틀리게 이해하여 응급실 대신 몸을 펴는 것을 권장했습니다.

![이미지](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_3.png)

<div class="content-ad"></div>

2023년, 미국 국립 식이장애 협회(NEDA)가 인간 스태프로 운영되던 도움말 전화 서비스를 '테사'라는 챗봇으로 대체했다고 합니다. 그러나 테사는 식이장애를 가진 사용자들에게 체중 감소 팁과 같은 부적절한 조언을 제공했다고 전해졌습니다. 이 사건으로 인해 NEDA는 그 챗봇을 중단시켰다고 합니다. 이는 적절한 안전장치 없이 AI 시스템을 도입하면 발생하는 현실적인 결과입니다.

## 구체화된 인지 및 AI에 대한 함의

구체화된 인지 이론은 이해가 우리의 신체적 경험과 감정에 깊게 뿌리를 둔다는 주장을 합니다. 현재의 AI 모델에서는 이 차원이 부족합니다. Jean Piaget의 인지 발달 단계는 인간이 환경과의 직접적 상호작용을 통해 인지 능력과 추상적 사고력을 향상시킨다는 것을 보여줍니다.

물리적 형태가 없는 AI는 이런 감각 기반 학습이 부족합니다. 이를 이해하기 위해 매운 맛에 대한 개념을 매운 것을 맛보지 않은 사람에게 설명하려고 한다고 상상해봅시다. 신체적 경험에 의존하지 않고 어떻게 그 감각을 전달할 수 있을까요? 이것은 인간처럼 세상과 상호작용하며 체험으로 이해되는 개념을 이해하는 데 어려움을 강조합니다.

<div class="content-ad"></div>

![DoGPTModelsHaveWernickesAphasia_4](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_4.png)

## 사르침과 아이러니에 대한 뉘앙스를 이해하기

AI 모델인 GPT-3와 같은 것들이 겪는 가장 큰 어려움 중 하나는 사르침과 아이러니 등 언어의 뉘앙스를 파악하는 것입니다—심지어 인간들도 이에 어려움을 겪습니다. 이러한 언어 요소들은 맥락, 어조, 종종 공유된 문화적 또는 상황적 이해력에 많이 의존합니다.

사르침은 말하는 의도와 반대되는 것을 말하는 것을 포함하며, 이것은 발화자의 의도, 배경, 그 밖에 이 문장이 만들어진 맥락의 적절한 해석 없이 혼란스러울 수 있습니다. 비슷하게, 아이러니는 언어 단서 교환과 현실 세계적 지식의 교환이 통해 보통 이해되는 뉘앙스를 포함합니다.

<div class="content-ad"></div>

상호작용을 살펴보면:

- 사람: '오늘 날씨가 정말 좋네요!' (천둥 번개가 치는 중에)
- AI: '날씨를 즐기시는 것 같아서 기쁩니다! 햇빛이 내리쬐는 것은 항상 즐거운 일이에요.'

![Do GPT 모델에 베르니케 아파지아가 있나요?](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_5.png)

이 상호작용에서는 AI가 발언과 실제 날씨 상황 사이의 불일치를 인식하는 것이 불가능합니다. AI 언어 이해의 챌린지는 문화 간 소통을 고려할 때 더욱 복잡해집니다.

<div class="content-ad"></div>

## 문화 간 의사 소통에서 미묘함을 이해하기

각 언어와 문화에는 관용구, 문화적 참조 및 문맥에 따라 의미가 크게 달라집니다. 주로 영어 데이터로 훈련된 AI 시스템은 일본어 존칭이나 아랍 속담의 맥락적 함의를 이해하는 데 어려움을 겪을 수 있습니다. 참으로 세계적인 AI 시스템을 만들기 위해서는 언어 능력뿐만 아니라 깊이 있는 문화적 이해가 필요합니다.

## 이해 간격을 줄이기 위한 AI의 미래 방향

연구자들은 AI 시스템이 보다 깊은 문맥적 이해를 갖도록 다양한 방법을 탐구하고 있습니다. 한 가지 방향은 멀티모달 학습의 통합입니다. 여기서 AI 시스템은 텍스트뿐만 아니라 이미지, 소리 및 다른 감각적 입력을 처리하여 보다 통합적인 세계 이해를 구축합니다. 또 다른 접근 방식은 신경 기호론적 AI의 개발입니다. 이것은 신경망의 패턴 인식 능력과 상징적 AI의 논리 추론을 결합합니다. 이 조합은 AI가 이미지나 문장에서 물체나 단어를 인식하는 것 뿐만 아니라 그들의 관계와 나타나는 폭 넓은 맥락을 이해할 수 있게 합니다.

<div class="content-ad"></div>

## 결론

이 글은 말 공장 증후군 환자와 GPT 모델 사이의 유사성을 드로잉하여 시작했습니다. 완벽한 일대일 비교는 아니지만, 언어를 단순히 생성하는 것과 진정한 이해 사이의 구분을 효과적으로 보여 주었습니다.

GPT 모델과 같은 AI 시스템도 인간 인지에 내재된 심층적인 이해를 달성하지 못하는 것이 점점 더 명백해지고 있습니다. 비꼬기, 비어, 문화적 섬세함과 같은 뉘앙스를 포함한 복잡성을 이해하는 데 제한 사항이 있어서, 공감, 감성 지능, 섬세한 이해가 필요한 응용 분야에서 중요한 도전이 드러납니다.

![이미지](/assets/img/2024-06-30-DoGPTModelsHaveWernickesAphasia_6.png)

<div class="content-ad"></div>

이를 고려할 때, '인간 중심' 방식을 통합하는 것이 꼭 필요합니다. 특히 건강의료, 법률 서비스 및 개인 소통과 같이 위험성이 높은 분야에서는 더욱 중요합니다. 인간은 AI가 현재 갖고 있지 않은 판단력, 윤리적 고려사항 및 문화적 통찰력을 제공할 수 있습니다. 이 방식은 AI가 인간의 전문 지식을 대체하기보다 도울 수 있도록 하여, AI 기술의 신뢰성과 윤리적 전개를 향상시키고 위험을 줄입니다.

## 개인적인 반성

저는 종종 현재 AI 시스템과 신경과학 문헌 간의 연결지점을 찾으려 노력합니다. AI 주변의 윤리적 딜레마와 실세계 적용 시의 트레이드 오프도 제 관심사입니다. 이 글은 이러한 관심과 생각들이 교차되는 부분이며, 제가 쓰는 만큼 여러분이 읽는 데 흥미로웠으면 좋겠습니다.

## 참고문헌

<div class="content-ad"></div>

- Arnaud, A. (2024, February 19). Neuro-symbolic AI Emerges as Powerful New Approach. Retrieved from Sun Location
- Lavars, N. (2021, February 10). AI chatbots could help provide therapy, but caution is needed. Scientific American. Retrieved from Scientific American
- National Aphasia Association. (n.d.). Wernicke’s (Receptive) Aphasia. Retrieved from National Aphasia Association
- Nabla. (2020, October 27). Understanding GPT-3: Capabilities, Limitations, and Implications. Retrieved from Nabla
- Palmer, A. (2018, May 24). Amazon Echo recorded a conversation and sent it to a random person, report says. CNBC. Retrieved from [CNBC]([invalid URL removed] a-random-person-report.html)
- Searle, J. (n.d.). The Chinese Room Argument. In Internet Encyclopedia of Philosophy. Retrieved from Stanford University
- Srivastava, S., Mu, T., Choi, E., Băroiu, C., & Trăuşan-Matu, S. (2022). On Sarcasm Detection with OpenAI GPT-based Models. Retrieved from arXiv
- Suglia, A., Greco, C., Baker, K., Part, J. L., Papaioannou, I., Eshghi, A., Konstas, I., & Lemon, O. (2024). ALANAVLM: A multimodal embodied AI foundation model for egocentric video understanding. arXiv preprint arXiv:2406.13807
- Wilson, R. A., & Foglia, L. (2021). Embodied Cognition. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Spring 2021 Edition). Retrieved from Stanford University